{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36e4a3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from obspy.core import UTCDateTime\n",
    "from obspy import read\n",
    "from obspy.taup import TauPyModel\n",
    "from obspy.geodetics import locations2degrees\n",
    "from glob import glob\n",
    "import os\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50e56fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'newfault'\n",
    "GF_list = 'rc_gflist.gflist' # Station file used in fq gen code\n",
    "vel_mod = 'mojave'\n",
    "stas_name = GF_list.split('.')[0]\n",
    "fq_dir = '/hdd/rc_fq/fall24/' + project_name + '/'\n",
    "\n",
    "ruptures = np.load('/hdd/rc_fq/fall24/' + project_name + '_ruptures.npy')\n",
    "test_ruptures = ['newfault.000000', 'newfault.000001', 'newfault.000002']\n",
    "\n",
    "# Where to save arrival times\n",
    "\n",
    "arrival_save_dir = '/hdd/rc_fq/fall24/' + project_name + '_fq_parrivals/'\n",
    "if os.path.isdir(arrival_save_dir):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(arrival_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457a5ba7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rupture newfault.000000 (1/3300)\n"
     ]
    }
   ],
   "source": [
    "# w = open('/home/sdybing/rc_fq/test_p_arrivals.csv', 'w') # saves arrivals for every event in one csv. Not using currently\n",
    "counter = 0\n",
    "\n",
    "for rupture in ruptures:\n",
    "    \n",
    "    counter += 1\n",
    "    w = open(arrival_save_dir + stas_name + '_arrival_times_' + rupture + '.csv', 'w') # saves arrivals for each event in a separate csv\n",
    "    \n",
    "    print('Rupture ' + rupture + ' (' + str(counter) + '/' + str(len(ruptures)) + ')')\n",
    "    \n",
    "    log = glob(fq_dir + 'output/ruptures/' + rupture + '.log')\n",
    "    f = open(log[0],'r')\n",
    "    line = f.readlines()\n",
    "    \n",
    "    # getting hypocenter location\n",
    "    hyp_loc_junk = line[16]\n",
    "    hyp_loc_1 = float(hyp_loc_junk.split(' ')[2].split('(')[1].split(')')[0].split(',')[0])\n",
    "    hyp_loc_2 = float(hyp_loc_junk.split(' ')[2].split('(')[1].split(')')[0].split(',')[1])\n",
    "    hyp_loc_3 = float(hyp_loc_junk.split(' ')[2].split('(')[1].split(')')[0].split(',')[2])\n",
    "    \n",
    "    epicenter = []\n",
    "    epicenter.append(hyp_loc_1)\n",
    "    epicenter.append(hyp_loc_2)\n",
    "    epicenter.append(hyp_loc_3)\n",
    "#     print(epicenter)\n",
    "    \n",
    "    epi_lon = epicenter[0]\n",
    "    epi_lat = epicenter[1]\n",
    "    epi_depth = epicenter[2]\n",
    "    \n",
    "    # getting hypocenter time\n",
    "    hyp_time_junk = line[17]\n",
    "    hyp_time = hyp_time_junk.split(' ')[2].split('Z')[0]\n",
    "    time_epi = UTCDateTime(hyp_time)  \n",
    "    stations = np.load('/hdd/rc_fq/fall24/' + stas_name + '_station_names.npy')\n",
    "    Nsta = len(stations) # number of stations\n",
    "    \n",
    "    rootpath = fq_dir + '/output/waveforms/' + rupture + '/' # waveform file locations\n",
    "    lonlat_load = np.load('/hdd/rc_fq/fall24/' + stas_name + '_station_namesandlocs.npy') \n",
    "    lonlat = lonlat_load[:,0:2] # station locations\n",
    "    \n",
    "    station_catalogue_load = np.load('/hdd/rc_fq/fall24/' + stas_name + '_station_namesandlocs.npy')\n",
    "    station_catalogue = station_catalogue_load[:,2]\n",
    "    \n",
    "    velmod = TauPyModel(model = fq_dir + '/structure/' + vel_mod + '.npz') # velocity model\n",
    "    \n",
    "    predictedP = 9999 * np.ones(len(stations))\n",
    "    \n",
    "    # Get predicted arrivals\n",
    "    \n",
    "    for ksta in range(len(stations)):\n",
    "        \n",
    "        # Find station coordinates\n",
    "        i = np.where(station_catalogue == stations[ksta])[0]\n",
    "        lon_sta = float(lonlat[i,0])\n",
    "        lat_sta = float(lonlat[i,1])\n",
    "                        \n",
    "        deg = locations2degrees(lat_sta, lon_sta, epi_lat, epi_lon) # calculates distance between station loc and epicenter loc\n",
    "        arrivals = velmod.get_travel_times(source_depth_in_km = epi_depth, distance_in_degree = deg, phase_list = ['P','Pn','p'])\n",
    "        \n",
    "        # Determine P and S arrivals\n",
    "        for kphase in range(len(arrivals)):\n",
    "            if 'P' == arrivals[kphase].name or 'p' == arrivals[kphase].name or 'Pn' == arrivals[kphase].name:\n",
    "                if arrivals[kphase].time < predictedP[ksta]:\n",
    "                    predictedP[ksta] = arrivals[kphase].time\n",
    "                    \n",
    "#         print('Station ' + stations[ksta] + ': predicted arrival = ' + str(time_epi + predictedP[ksta]))\n",
    "        \n",
    "        line = '%s\\t%s\\t%s\\n'%(rupture, str(stations[ksta]), str(time_epi + predictedP[ksta]))\n",
    "        # print(line)\n",
    "        w.write(line)\n",
    "    \n",
    "    w.close()\n",
    "\n",
    "# w.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2e473d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
