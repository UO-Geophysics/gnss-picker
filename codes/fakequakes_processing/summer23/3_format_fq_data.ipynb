{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98e648c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import read, Stream, UTCDateTime\n",
    "import numpy as np\n",
    "from mudpy.hfsims import windowed_gaussian, apply_spectrum\n",
    "from mudpy.forward import gnss_psd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "860aa89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'newfault'\n",
    "GF_list = 'rc_gflist.gflist' # Station file used in fq gen code\n",
    "vel_mod = 'mojave'\n",
    "stas_name = GF_list.split('.')[0]\n",
    "fq_dir = '/hdd/rc_fq/fall24/' + project_name + '/'\n",
    "arrival_save_dir = '/hdd/rc_fq/fall24/' + project_name + '_fq_parrivals/'\n",
    "\n",
    "ruptures = np.load('/hdd/rc_fq/fall24/' + project_name + '_ruptures.npy')\n",
    "extra_second_rupts = ['newfault.000474', 'newfault.001647', 'newfault.001745', 'newfault.002078', 'newfault.002165', 'newfault.002607', 'newfault.002911', 'newfault.003012']\n",
    "\n",
    "stas = np.load('/hdd/rc_fq/fall24/' + stas_name + '_station_names.npy')\n",
    "test_stas = ['P595', 'P594', 'CCCC']\n",
    "# print(stas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6cfb19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rupture newfault.000009 (10/3300)\n",
      "Rupture newfault.000019 (20/3300)\n",
      "Rupture newfault.000029 (30/3300)\n",
      "Rupture newfault.000039 (40/3300)\n",
      "Rupture newfault.000049 (50/3300)\n",
      "Rupture newfault.000059 (60/3300)\n",
      "Rupture newfault.000069 (70/3300)\n",
      "Rupture newfault.000079 (80/3300)\n",
      "Rupture newfault.000089 (90/3300)\n",
      "Rupture newfault.000099 (100/3300)\n"
     ]
    }
   ],
   "source": [
    "new_data_array = np.zeros((len(ruptures)*278, 768))\n",
    "\n",
    "mag_list = []\n",
    "sta_list = []\n",
    "rupt_list = []\n",
    "\n",
    "data_list = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for idx in range(len(ruptures)):\n",
    "    \n",
    "    rupt = ruptures[idx]\n",
    "    \n",
    "    counter += 1\n",
    "    if counter % 10 == 0:\n",
    "        print('Rupture ' + rupt + ' (' + str(counter) + '/' + str(len(ruptures)) + ')')\n",
    "    \n",
    "    log = glob(fq_dir + 'output/ruptures/' + rupt + '.log')\n",
    "    log = open(log[0],'r')\n",
    "    line = log.readlines()\n",
    "    \n",
    "    mag = str(line[15][21:27])\n",
    "#     print(mag)\n",
    "    \n",
    "    for idx2 in range(len(stas)):\n",
    "        \n",
    "        sta = stas[idx2]\n",
    "        \n",
    "#         print(sta)\n",
    "        arrivals = np.genfromtxt(arrival_save_dir + stas_name + '_arrival_times_' + rupt + '.csv', dtype = 'U')\n",
    "#         print(arrivals)\n",
    "            \n",
    "        # Read in data \n",
    "        \n",
    "        stN = read(fq_dir + 'output/waveforms/' + rupt + '/' + sta + '.LYN.sac') \n",
    "        stE = read(fq_dir + 'output/waveforms/' + rupt + '/' + sta + '.LYE.sac') \n",
    "        stZ = read(fq_dir + 'output/waveforms/' + rupt + '/' + sta + '.LYZ.sac') \n",
    "        \n",
    "#         print(stN[0].stats.starttime)\n",
    "        \n",
    "#         stN.plot()\n",
    "        \n",
    "        N_data = stN[0].data\n",
    "        E_data = stE[0].data\n",
    "        Z_data = stZ[0].data\n",
    "        \n",
    "        ### Zero-pad this data ###\n",
    "        \n",
    "        N_data_padded = np.pad(N_data, 128, mode = 'constant')\n",
    "        E_data_padded = np.pad(E_data, 128, mode = 'constant')\n",
    "        Z_data_padded = np.pad(Z_data, 128, mode = 'constant')\n",
    "        \n",
    "        stN_pad = stN.copy()\n",
    "        stN_pad[0].data = N_data_padded\n",
    "        \n",
    "        stE_pad = stE.copy()\n",
    "        stE_pad[0].data = E_data_padded\n",
    "        \n",
    "        stZ_pad = stZ.copy()\n",
    "        stZ_pad[0].data = Z_data_padded\n",
    "        \n",
    "#         stN.plot()\n",
    "#         stN_pad.plot()\n",
    "#         print(stN_pad[0].stats.starttime)\n",
    "        \n",
    "        npts = stN_pad[0].stats.npts\n",
    "\n",
    "        ### Trim around the arrival time ###\n",
    "        \n",
    "        stas_arrival = arrivals[:,1] # Station list from arrivals file\n",
    "        \n",
    "        i = np.where(stas_arrival == sta)[0]\n",
    "        arrival = arrivals[i,2][0]\n",
    "#         print(arrival)\n",
    "\n",
    "        # Grab the arrival time\n",
    "\n",
    "        arr_time = UTCDateTime(arrival)\n",
    "        arr_time = arr_time + 128 # To account for padding at front\n",
    "        starttime = arr_time - 128\n",
    "        if sta == 'P284':\n",
    "            if rupt in extra_second_rupts:\n",
    "                endtime = arr_time + 128\n",
    "            else:\n",
    "                endtime = arr_time + 127\n",
    "        else:\n",
    "            endtime = arr_time + 127 # Needs to be 256 samples, not 256 seconds\n",
    "\n",
    "#         arr_time = arr_time + 3 # To account for padding at front\n",
    "#         starttime = arr_time - 3\n",
    "#         endtime = arr_time + 3\n",
    "        \n",
    "#         print(starttime)\n",
    "#         print(arr_time)\n",
    "#         print(endtime)\n",
    "        \n",
    "        stN_trim = stN_pad.trim(starttime, endtime)\n",
    "        stE_trim = stE_pad.trim(starttime, endtime)\n",
    "        stZ_trim = stZ_pad.trim(starttime, endtime)\n",
    "        \n",
    "        stN_trim_data = stN_trim[0].data # Middle sample is the (npts + 1)/2 sample, index is (npts + 1)/2 - 1\n",
    "        stE_trim_data = stE_trim[0].data\n",
    "        stZ_trim_data = stZ_trim[0].data\n",
    "        \n",
    "#         print(stN_trim[0].stats.starttime)\n",
    "#         print(stN_trim[0].stats.endtime)\n",
    "#         print(stN_trim[0].stats.npts) # Middle sample is the (npts + 1)/2 sample, index is (npts + 1)/2 - 1\n",
    "#         print(len(stN_trim_data))\n",
    "#         stN_trim[0].plot()\n",
    "\n",
    "        npts = stN_trim[0].stats.npts\n",
    "#         print(npts)\n",
    "        arrival_idx = int((npts + 1)/2 - 1)\n",
    "        \n",
    "        pick_N = stN_trim_data[arrival_idx]\n",
    "        pick_E = stE_trim_data[arrival_idx]   \n",
    "        pick_Z = stZ_trim_data[arrival_idx]\n",
    "        \n",
    "#         print(pick_N)\n",
    "\n",
    "        stN_norm = stN_trim_data - pick_N\n",
    "        stE_norm = stE_trim_data - pick_E\n",
    "        stZ_norm = stZ_trim_data - pick_Z    \n",
    "        \n",
    "        stN_zeroed = stN_norm\n",
    "        stN_zeroed[0:128] = 0 # Remember that the stop index is excluded\n",
    "        \n",
    "        stE_zeroed = stE_norm\n",
    "        stE_zeroed[0:128] = 0 \n",
    "        \n",
    "        stZ_zeroed = stZ_norm\n",
    "        stZ_zeroed[0:128] = 0 \n",
    "        \n",
    "        ### Combine N, E, and Z components into one array ###\n",
    "        \n",
    "        comb_data = np.append(stN_zeroed, stE_zeroed)\n",
    "        comb_data = np.append(comb_data, stZ_zeroed) # Order: N, E, Z\n",
    "        \n",
    "#         print(comb_data.shape)\n",
    "        \n",
    "        big_idx = idx*278 + idx2\n",
    "#         print(idx, idx2, big_idx)\n",
    "#         try:\n",
    "        new_data_array[big_idx] = comb_data\n",
    "#         except:\n",
    "#             print('Error: ' + str(rupt) + ', ' + str(sta))\n",
    "        \n",
    "        # N: indices 0 through 255 pick at index 128)\n",
    "        # E: indices 256 through 511 (pick at index 384)\n",
    "        # Z: indices 512 through 767 (pick at index 640)\n",
    "        \n",
    "#         plt.plot(comb_data) # Checking to make sure everything lines up\n",
    "#         plt.xlim(635,645)\n",
    "#         plt.ylim(-0.005, 0.005)\n",
    "# #         plt.ylim(-0.2, 0.2)\n",
    "#         plt.axvline(640)\n",
    "\n",
    "        ### Adding new data to an array - each row = new station ### \n",
    "    \n",
    "        data_list.append(comb_data) # Add clean data instead\n",
    "        \n",
    "        ### Add magnitude to list\n",
    "        \n",
    "        rupt_list.append(str(rupt))\n",
    "        sta_list.append(str(sta))\n",
    "        mag_list.append(str(mag))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6274061",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = np.array(data_list)\n",
    "print('Data array shape:')\n",
    "print(data_array.shape) # Arrivals at samples 128, 384, 640\n",
    "# print(data_array[0])\n",
    "\n",
    "print('New data array shape:')\n",
    "print(new_data_array.shape) # Arrivals at samples 128, 384, 640\n",
    "# print(data_array[0])\n",
    "\n",
    "rupt_array = np.array(rupt_list)\n",
    "# print(rupt_array.shape)\n",
    "\n",
    "sta_array = np.array(sta_list)\n",
    "# print(sta_array.shape)\n",
    "\n",
    "mag_array = np.array(mag_list)\n",
    "# print(mag_array.shape)\n",
    "\n",
    "info_array = np.column_stack((rupt_array, sta_array, mag_array))\n",
    "print('Info array shape:')\n",
    "print(info_array.shape)\n",
    "print(info_array[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753169d8-c92a-4dec-9fd8-74267628974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(new_data_array[567])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58bb177",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('/hdd/rc_fq/fall24/' + project_name + '_fq_wvfm_data_formatted.hdf5', 'w')\n",
    "h5f.create_dataset('data', data = data_array)\n",
    "h5f.close()\n",
    "\n",
    "h5f = h5py.File('/hdd/rc_fq/fall24/' + project_name + '_fq_wvfm_data_formatted_newversion.hdf5', 'w')\n",
    "h5f.create_dataset('data', data = new_data_array)\n",
    "h5f.close()\n",
    "\n",
    "np.save('/hdd/rc_fq/fall24/' + project_name + '_fq_wvfm_info.npy', info_array) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254cac5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
