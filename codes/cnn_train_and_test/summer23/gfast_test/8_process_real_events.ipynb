{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import read, Stream, UTCDateTime\n",
    "import numpy as np\n",
    "from mudpy.hfsims import windowed_gaussian, apply_spectrum\n",
    "from mudpy.forward import gnss_psd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89,)\n"
     ]
    }
   ],
   "source": [
    "gnss_arr_times = np.load('/hdd/Ridgecrest/summer23/minM4.3_gnss_arrival_times.npy')\n",
    "i = np.where(gnss_arr_times[:,3] != 'nan')[0]\n",
    "des_evts = np.unique(gnss_arr_times[i,0])\n",
    "print(des_evts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_file = '/hdd/Ridgecrest/summer23/minM4.3_event_catalog.txt'\n",
    "\n",
    "events = np.genfromtxt(events_file, dtype = 'str')\n",
    "\n",
    "# Columns: \n",
    "# 0. ID\n",
    "# 1. origin time\n",
    "# 2. lon\n",
    "# 3. lat\n",
    "# 4. depth\n",
    "# 5. mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(362,)\n"
     ]
    }
   ],
   "source": [
    "ids = events[:,0]\n",
    "print(ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_evt_idxs = []\n",
    "\n",
    "for idx in range(len(des_evts)):\n",
    "    des_evt = des_evts[idx]\n",
    "#     print(des_evt)\n",
    "    j = np.where(events[:,0] == des_evt)[0][0]\n",
    "#     print(des_evt, events[j,0])\n",
    "#     print(j)\n",
    "    des_evt_idxs.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_catalog = events[des_evt_idxs]\n",
    "stas = np.genfromtxt('/hdd/Ridgecrest/summer23/GNSS_stas.txt', usecols = [2], dtype = str)\n",
    "chans = ['e', 'n', 'u']\n",
    "eq_dates = np.genfromtxt('/hdd/Ridgecrest/summer23/GNSS_dates_w_eqs_only.txt', dtype = str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['20190704', '20190705', '20190706', '20190707', '20190712',\n",
       "       '20190716', '20190726', '20190822', '20190823', '20200604'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq_catalog_dates = selected_catalog[:,1]\n",
    "eq_catalog_dates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ot_days = []\n",
    "\n",
    "for idx in range(len(selected_catalog[:,1])):\n",
    "    ot_day_split = selected_catalog[idx,1][:10].split('-')\n",
    "    ot_day = ot_day_split[0] + ot_day_split[1] + ot_day_split[2]\n",
    "    ot_days.append(ot_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20190605' '20190704' '20190705' '20190706' '20190707' '20190711'\n",
      " '20190712' '20190716' '20190717' '20190718' '20190726' '20190822'\n",
      " '20190823' '20191015' '20191217' '20200125' '20200201' '20200318'\n",
      " '20200323' '20200404' '20200411' '20200510' '20200515' '20200516'\n",
      " '20200517' '20200518' '20200519' '20200520' '20200522' '20200530'\n",
      " '20200531' '20200604' '20200619' '20200623' '20200624' '20200630'\n",
      " '20200706']\n"
     ]
    }
   ],
   "source": [
    "new_dates = []\n",
    "\n",
    "for idx in range(len(eq_catalog_dates)):\n",
    "    date = eq_catalog_dates[idx]\n",
    "#     print(date)\n",
    "    new_date1 = date.split('-')\n",
    "    new_date2 = new_date1[2].split('T')[0]\n",
    "    new_date = new_date1[0] + new_date1[1] + new_date2\n",
    "#     print(new_date)\n",
    "    new_dates.append(new_date)\n",
    "    \n",
    "new_dates = np.unique(np.array(new_dates))\n",
    "print(new_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path, makedirs\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'summer23'\n",
    "project_dir = '/hdd/Ridgecrest/' + project + '/'\n",
    "daily_mseed_path = project_dir + 'daily_mseeds/' # Where are the daily mseeds?\n",
    "gfast_test_mseed_path = project_dir + 'gfast_test_mseeds/' # Where to save the split mseeds?\n",
    "\n",
    "if os.path.isdir(gfast_test_mseed_path):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(gfast_test_mseed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48]\n"
     ]
    }
   ],
   "source": [
    "date = '20190605'\n",
    "i = np.where(date == np.array(ot_days))[0]\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['37219156', '2019-07-06T03:22:48.300000Z', '-117.7365', '35.8910',\n",
       "        '9.10', '4.64'],\n",
       "       ['37219164', '2019-07-06T03:23:50.720000Z', '-117.6178', '35.8032',\n",
       "        '11.44', '4.84'],\n",
       "       ['37219172', '2019-07-06T03:25:27.970000Z', '-117.6708', '35.8607',\n",
       "        '10.32', '4.61'],\n",
       "       ['37219180', '2019-07-06T03:27:07.010000Z', '-117.7258', '35.9138',\n",
       "        '8.00', '4.50'],\n",
       "       ['37219484', '2019-07-06T03:22:17.100000Z', '-117.5457', '35.7480',\n",
       "        '3.90', '4.55'],\n",
       "       ['37219500', '2019-07-06T03:22:35.630000Z', '-117.4302', '35.6167',\n",
       "        '9.35', '4.73'],\n",
       "       ['37219564', '2019-07-06T03:27:11.370000Z', '-117.4313', '35.5303',\n",
       "        '3.84', '4.57'],\n",
       "       ['37224964', '2019-07-06T04:37:13.570000Z', '-117.7453', '35.9100',\n",
       "        '8.01', '4.33'],\n",
       "       ['37421229', '2019-07-06T03:57:50.900000Z', '-117.6613', '35.8690',\n",
       "        '7.16', '4.31'],\n",
       "       ['37445989', '2020-05-22T00:22:00.960000Z', '-117.7960', '38.2360',\n",
       "        '5.21', '5.30'],\n",
       "       ['38443183', '2019-07-04T17:33:49.000000Z', '-117.5038', '35.7053',\n",
       "        '10.50', '6.40'],\n",
       "       ['38443191', '2019-07-04T17:35:01.670000Z', '-117.5643', '35.6428',\n",
       "        '4.81', '4.49'],\n",
       "       ['38443535', '2019-07-04T18:27:59.440000Z', '-117.5522', '35.7450',\n",
       "        '6.64', '4.66'],\n",
       "       ['38443607', '2019-07-04T18:39:44.440000Z', '-117.5970', '35.6013',\n",
       "        '2.81', '4.59'],\n",
       "       ['38443647', '2019-07-04T18:47:06.590000Z', '-117.4853', '35.6758',\n",
       "        '8.53', '4.34'],\n",
       "       ['38443719', '2019-07-04T18:56:06.420000Z', '-117.5600', '35.7160',\n",
       "        '1.92', '4.58'],\n",
       "       ['38443871', '2019-07-04T19:21:32.090000Z', '-117.4788', '35.6715',\n",
       "        '5.16', '4.50'],\n",
       "       ['38445087', '2019-07-04T22:12:08.280000Z', '-117.5663', '35.7443',\n",
       "        '1.97', '4.43'],\n",
       "       ['38450263', '2019-07-05T11:07:53.040000Z', '-117.5750', '35.7603',\n",
       "        '6.95', '5.37'],\n",
       "       ['38457487', '2019-07-06T03:16:32.480000Z', '-117.5535', '35.7253',\n",
       "        '0.88', '4.97'],\n",
       "       ['38457511', '2019-07-06T03:19:53.040000Z', '-117.5993', '35.7695',\n",
       "        '8.00', '7.10'],\n",
       "       ['38457519', '2019-07-06T03:22:03.550000Z', '-117.7258', '35.9222',\n",
       "        '9.14', '4.64'],\n",
       "       ['38457591', '2019-07-06T03:30:25.050000Z', '-117.3582', '35.5567',\n",
       "        '8.71', '4.49'],\n",
       "       ['38457615', '2019-07-06T03:36:16.460000Z', '-117.7338', '35.9028',\n",
       "        '7.27', '4.35'],\n",
       "       ['38457687', '2019-07-06T03:47:53.420000Z', '-117.7495', '35.9012',\n",
       "        '5.04', '5.50'],\n",
       "       ['38457703', '2019-07-06T03:50:59.710000Z', '-117.7002', '35.9035',\n",
       "        '8.26', '4.97'],\n",
       "       ['38457775', '2019-07-06T04:07:04.570000Z', '-117.5217', '35.5552',\n",
       "        '5.64', '4.68'],\n",
       "       ['38457815', '2019-07-06T04:13:07.070000Z', '-117.6145', '35.5848',\n",
       "        '9.63', '4.80'],\n",
       "       ['38457847', '2019-07-06T04:18:55.790000Z', '-117.6848', '35.9102',\n",
       "        '7.41', '5.44'],\n",
       "       ['38457967', '2019-07-06T04:36:55.310000Z', '-117.7377', '35.9000',\n",
       "        '1.90', '4.85'],\n",
       "       ['38458071', '2019-07-06T04:52:04.010000Z', '-117.7323', '35.8895',\n",
       "        '5.37', '4.55'],\n",
       "       ['38458079', '2019-07-06T04:52:17.710000Z', '-117.6945', '35.8773',\n",
       "        '3.32', '4.47'],\n",
       "       ['38458679', '2019-07-06T06:01:51.800000Z', '-117.7385', '35.9110',\n",
       "        '4.99', '4.63'],\n",
       "       ['38460311', '2019-07-06T08:32:57.550000Z', '-117.4913', '35.6390',\n",
       "        '3.14', '4.56'],\n",
       "       ['38460967', '2019-07-06T09:28:28.980000Z', '-117.7272', '35.8980',\n",
       "        '3.95', '4.89'],\n",
       "       ['38460975', '2019-07-06T09:29:20.970000Z', '-117.7175', '35.8812',\n",
       "        '5.50', '4.41'],\n",
       "       ['38460983', '2019-07-06T09:30:41.240000Z', '-117.7323', '35.9098',\n",
       "        '4.15', '4.49'],\n",
       "       ['38463551', '2019-07-06T13:06:55.260000Z', '-117.7050', '35.9283',\n",
       "        '2.37', '4.50'],\n",
       "       ['38469375', '2019-07-06T23:50:41.990000Z', '-117.6630', '35.8235',\n",
       "        '6.51', '4.50'],\n",
       "       ['38472279', '2019-07-07T05:38:15.480000Z', '-117.5778', '35.7682',\n",
       "        '10.57', '4.53'],\n",
       "       ['38488354', '2020-05-10T22:07:40.370000Z', '-116.0202', '33.0183',\n",
       "        '10.16', '4.54'],\n",
       "       ['38525207', '2019-07-11T00:14:37.320000Z', '-117.8840', '36.1767',\n",
       "        '0.93', '4.52'],\n",
       "       ['38525215', '2019-07-11T00:15:39.220000Z', '-117.8763', '36.1537',\n",
       "        '2.11', '4.37'],\n",
       "       ['38527863', '2019-07-11T04:10:01.380000Z', '-117.8483', '36.0560',\n",
       "        '2.11', '4.30'],\n",
       "       ['38548295', '2019-07-12T13:11:37.990000Z', '-117.5862', '35.6368',\n",
       "        '9.48', '4.90'],\n",
       "       ['38583335', '2019-07-16T20:15:36.780000Z', '-117.6143', '35.7837',\n",
       "        '3.56', '4.47'],\n",
       "       ['38585023', '2019-07-17T02:29:07.380000Z', '-117.8840', '36.1160',\n",
       "        '5.30', '4.37'],\n",
       "       ['38593535', '2019-07-18T03:59:14.720000Z', '-117.8875', '36.1130',\n",
       "        '1.56', '4.64'],\n",
       "       ['38624424', '2019-06-05T14:32:09.580000Z', '-118.5032', '32.8377',\n",
       "        '8.40', '4.30'],\n",
       "       ['38644943', '2019-07-26T00:42:47.770000Z', '-117.7067', '35.9258',\n",
       "        '3.79', '4.74'],\n",
       "       ['38996632', '2019-08-22T20:49:50.180000Z', '-117.7090', '35.9077',\n",
       "        '4.93', '4.89'],\n",
       "       ['38999296', '2019-08-23T05:34:09.740000Z', '-117.7047', '35.9078',\n",
       "        '7.14', '4.33'],\n",
       "       ['39106919', '2020-03-18T22:08:20.900000Z', '-124.4560', '40.3470',\n",
       "        '28.28', '5.20'],\n",
       "       ['39111991', '2020-03-23T05:53:57.260000Z', '-117.3630', '35.9555',\n",
       "        '0.94', '4.32'],\n",
       "       ['39126079', '2020-04-04T01:53:18.920000Z', '-116.5063', '33.4895',\n",
       "        '10.45', '4.87'],\n",
       "       ['39133016', '2019-10-15T05:33:44.110000Z', '-122.0580', '37.9380',\n",
       "        '14.17', '4.50'],\n",
       "       ['39134160', '2019-10-15T19:42:30.790000Z', '-121.2740', '36.6490',\n",
       "        '9.18', '4.80'],\n",
       "       ['39201199', '2020-05-15T11:03:27.350000Z', '-117.8750', '38.1590',\n",
       "        '2.74', '6.50'],\n",
       "       ['39201215', '2020-05-15T11:18:12.390000Z', '-117.9600', '38.1600',\n",
       "        '3.80', '4.90'],\n",
       "       ['39201231', '2020-05-15T11:26:02.020000Z', '-117.8940', '38.1850',\n",
       "        '4.60', '5.10'],\n",
       "       ['39201263', '2020-05-15T11:52:07.180000Z', '-117.9830', '38.1470',\n",
       "        '3.64', '4.80'],\n",
       "       ['39201279', '2020-05-15T12:00:41.570000Z', '-117.8100', '38.1670',\n",
       "        '4.14', '4.50'],\n",
       "       ['39201407', '2020-05-15T13:51:37.150000Z', '-117.9540', '38.1730',\n",
       "        '4.70', '4.30'],\n",
       "       ['39201559', '2020-05-15T15:23:24.630000Z', '-117.8010', '38.1670',\n",
       "        '5.44', '4.80'],\n",
       "       ['39201767', '2020-05-15T17:50:16.940000Z', '-117.8300', '38.1730',\n",
       "        '3.64', '4.70'],\n",
       "       ['39202175', '2020-05-15T22:15:49.770000Z', '-118.0190', '38.1600',\n",
       "        '12.30', '4.50'],\n",
       "       ['39202623', '2020-05-16T04:12:21.430000Z', '-117.9760', '38.1310',\n",
       "        '5.00', '4.60'],\n",
       "       ['39203167', '2020-05-16T11:50:54.310000Z', '-117.7350', '38.2120',\n",
       "        '16.80', '4.60'],\n",
       "       ['39204599', '2020-05-17T11:53:53.340000Z', '-117.9550', '38.1500',\n",
       "        '9.60', '4.50'],\n",
       "       ['39205151', '2020-05-17T21:17:02.470000Z', '-117.8030', '38.1750',\n",
       "        '10.40', '4.70'],\n",
       "       ['39205383', '2020-05-18T02:19:08.410000Z', '-118.1103', '38.1853',\n",
       "        '-2.07', '4.30'],\n",
       "       ['39207503', '2020-05-19T22:12:45.640000Z', '-117.8540', '38.1760',\n",
       "        '8.10', '4.60'],\n",
       "       ['39208087', '2020-05-20T12:36:53.450000Z', '-117.7450', '38.2010',\n",
       "        '11.70', '5.00'],\n",
       "       ['39223527', '2020-05-30T18:13:48.000000Z', '143.8090', '42.4800',\n",
       "        '89.00', '5.60'],\n",
       "       ['39223791', '2020-05-31T01:07:15.780000Z', '-118.7620', '38.0450',\n",
       "        '5.81', '4.36'],\n",
       "       ['39223887', '2020-05-31T05:09:38.000000Z', '-70.7730', '-15.3260',\n",
       "        '185.80', '6.10'],\n",
       "       ['39233472', '2019-12-17T18:29:21.510000Z', '-120.3530', '35.8070',\n",
       "        '5.71', '4.30'],\n",
       "       ['39273567', '2020-06-30T09:24:23.020000Z', '-117.9460', '38.1788',\n",
       "        '-1.83', '4.47'],\n",
       "       ['39281127', '2020-07-06T06:12:55.800000Z', '-117.8910', '38.1860',\n",
       "        '2.86', '4.50'],\n",
       "       ['39281440', '2020-01-25T03:03:34.920000Z', '-116.9697', '35.0975',\n",
       "        '3.07', '4.62'],\n",
       "       ['39289104', '2020-02-01T18:36:54.490000Z', '-118.8342', '37.6000',\n",
       "        '10.99', '4.36'],\n",
       "       ['39382424', '2020-04-11T14:36:37.030000Z', '-118.7320', '38.0530',\n",
       "        '6.51', '5.24'],\n",
       "       ['39382736', '2020-04-11T16:22:50.940000Z', '-118.7580', '38.0420',\n",
       "        '6.61', '4.57'],\n",
       "       ['39462536', '2020-06-04T01:32:11.140000Z', '-117.4282', '35.6148',\n",
       "        '8.44', '5.51'],\n",
       "       ['39485504', '2020-06-19T10:26:44.770000Z', '-117.8180', '38.1720',\n",
       "        '9.61', '4.30'],\n",
       "       ['39486360', '2020-06-19T20:42:23.010000Z', '-117.8320', '38.1700',\n",
       "        '7.21', '5.00'],\n",
       "       ['39490952', '2020-06-23T00:25:46.390000Z', '-117.9840', '36.4467',\n",
       "        '2.26', '4.65'],\n",
       "       ['39493944', '2020-06-24T17:40:49.240000Z', '-117.9752', '36.4468',\n",
       "        '4.66', '5.80'],\n",
       "       ['39494008', '2020-06-24T17:59:19.960000Z', '-117.9312', '36.4560',\n",
       "        '9.62', '4.59']],\n",
       "      dtype='<U27')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(ot_days).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sta in stas:\n",
    "    \n",
    "#     if sta != 'BEPK':\n",
    "#         continue\n",
    "    \n",
    "    for chan in chans:\n",
    "        \n",
    "#         print(chan)\n",
    "        \n",
    "        for date in new_dates:\n",
    "            \n",
    "#             if date != '20190706':\n",
    "#                 continue\n",
    "#             print(date)\n",
    "\n",
    "            try:\n",
    "                \n",
    "#                 print(sta + '_' + chan + '_' + date)\n",
    "#                 tr = st_merge.copy()[0]\n",
    "#                 tr.plot()\n",
    "                \n",
    "                # Get the origin times for this date\n",
    "        \n",
    "#                 print(date)\n",
    "                i = np.where(date == np.array(ot_days))[0]\n",
    "                origin_times = selected_catalog[i,1]\n",
    "#                 print(origin_times)\n",
    "            \n",
    "                for idx in range(len(origin_times)):\n",
    "                    ot = UTCDateTime(origin_times[idx])\n",
    "#                     print(ot)\n",
    "                    \n",
    "                    st = read(daily_mseed_path + sta + '/' + sta + '.' + chan + '.' + date + '.mseed')\n",
    "#                     st.plot()\n",
    "                    st_copy = st.copy()\n",
    "                    st_merge = st_copy.merge(fill_value = 'interpolate')\n",
    "#                     st_merge.plot()\n",
    "                    \n",
    "                    starttime = ot\n",
    "                    endtime = ot + 127\n",
    "#                     print(starttime)\n",
    "#                     print(endtime)\n",
    "                    \n",
    "                    st_trim = st_merge.trim(starttime, endtime)\n",
    "#                     st_trim.plot()\n",
    "\n",
    "                    gfast_test_mseed_sta_path = gfast_test_mseed_path + sta + '/'\n",
    "                    gfast_test_mseed_chan_path = gfast_test_mseed_sta_path + chan + '_gfast_test_mseeds/'\n",
    "                    gfast_test_mseed_date_path = gfast_test_mseed_chan_path + date + '/'\n",
    "\n",
    "                    if os.path.isdir(gfast_test_mseed_sta_path):\n",
    "                        pass\n",
    "                    else:\n",
    "                        os.makedirs(gfast_test_mseed_sta_path)\n",
    "\n",
    "                    if os.path.isdir(gfast_test_mseed_chan_path):\n",
    "                        pass\n",
    "                    else:   \n",
    "                        os.makedirs(gfast_test_mseed_chan_path)\n",
    "\n",
    "                    if os.path.isdir(gfast_test_mseed_date_path):\n",
    "                        pass\n",
    "                    else:\n",
    "                        os.makedirs(gfast_test_mseed_date_path)\n",
    "\n",
    "                    st_trim.write(gfast_test_mseed_date_path + sta + '.' + chan + '.' + date + '.' + str(ot) + '.mseed', format = 'MSEED')\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "#                 print('Missing station, channel, or date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "event_id_list = []\n",
    "sta_list = []\n",
    "date_list = []\n",
    "starttime_list = []\n",
    "endtime_list = []\n",
    "\n",
    "for sta in stas:\n",
    "    \n",
    "#     print(sta)\n",
    "        \n",
    "    for date in new_dates:\n",
    "        \n",
    "#         print(date)\n",
    "\n",
    "        try:\n",
    "            \n",
    "            i = np.where(date == np.array(ot_days))[0]\n",
    "            origin_times = selected_catalog[i,1]\n",
    "            event_ids = selected_catalog[i,0]\n",
    "#             print(origin_times)\n",
    "\n",
    "            for idx in range(len(origin_times)):\n",
    "                \n",
    "                ot = UTCDateTime(origin_times[idx])\n",
    "                event_id = event_ids[idx]\n",
    "#                 print(sta, date, ot)\n",
    "\n",
    "                stN = read(gfast_test_mseed_path + sta + '/n_gfast_test_mseeds/' + date + '/' + sta + '.n.' + date + '.' + str(ot) + '.mseed')\n",
    "                stE = read(gfast_test_mseed_path + sta + '/e_gfast_test_mseeds/' + date + '/' + sta + '.e.' + date + '.' + str(ot) + '.mseed')\n",
    "                stZ = read(gfast_test_mseed_path + sta + '/u_gfast_test_mseeds/' + date + '/' + sta + '.u.' + date + '.' + str(ot) + '.mseed')\n",
    "                \n",
    "#                 stN.plot()\n",
    "                \n",
    "                N_data = stN[0].data\n",
    "                E_data = stE[0].data\n",
    "                Z_data = stZ[0].data\n",
    "                \n",
    "                comb_data = np.append(N_data, E_data)\n",
    "                comb_data = np.append(comb_data, Z_data) # Order: N, E, Z\n",
    "                \n",
    "#                 print(comb_data.shape)\n",
    "                if comb_data.shape != (384,):\n",
    "                    continue\n",
    "\n",
    "                data_list.append(comb_data)\n",
    "                \n",
    "                starttime = stN[0].stats.starttime\n",
    "#                 print(starttime)\n",
    "                endtime = stN[0].stats.endtime\n",
    "#                 print(endtime)\n",
    "                \n",
    "                event_id_list.append(event_id)\n",
    "                sta_list.append(sta)\n",
    "                date_list.append(date)\n",
    "                starttime_list.append(str(starttime))\n",
    "                endtime_list.append(str(endtime))\n",
    "            \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14676, 384)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data_list).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data array shape:\n",
      "(14676, 384)\n",
      "Info array shape:\n",
      "(14676, 5)\n"
     ]
    }
   ],
   "source": [
    "data_array = np.array(data_list)\n",
    "print('Data array shape:')\n",
    "print(data_array.shape) # should be something by 384\n",
    "\n",
    "info_array = np.column_stack((np.array(event_id_list), np.array(sta_list), np.array(date_list), np.array(starttime_list), np.array(endtime_list)))\n",
    "print('Info array shape:')\n",
    "print(info_array.shape)\n",
    "\n",
    "# h5f = h5py.File(project_dir + 'gfast_test_realdata_data.hdf5', 'w') \n",
    "# h5f.create_dataset('realdata_data', data = data_array)\n",
    "# h5f.close()\n",
    "\n",
    "np.save(project_dir + 'gfast_test_realdata_info.npy', info_array) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['38624424', 'ACSB', '20190605', '2019-06-05T14:32:10.000000Z',\n",
       "       '2019-06-05T14:34:17.000000Z'],\n",
       "      dtype='<U27')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "project = 'summer23'\n",
    "project_dir = '/hdd/Ridgecrest/' + project + '/' # For Tunguska\n",
    "# project_dir = '/home/sdybing/gnss-picker/data/realdata/' + project + '/' # For Valdivia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = h5py.File(project_dir + 'gfast_test_realdata_data.hdf5', 'r')\n",
    "real_data = real_data['realdata_data'][:,:] # shape: (1061760, 384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_test = False\n",
    "\n",
    "if small_test:\n",
    "    \n",
    "    real_data = real_data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nlen = 128\n",
    "\n",
    "comp1 = real_data[:, :nlen]\n",
    "comp2 = real_data[:, nlen:2*nlen]\n",
    "comp3 = real_data[:, 2*nlen:]\n",
    "\n",
    "stack_data = np.zeros((len(real_data), nlen, 3))\n",
    "\n",
    "for idx, row in enumerate(stack_data):\n",
    "            \n",
    "    # Grabbing out the new batch of data using the shifted timespans\n",
    "    stack_data[idx, :, 0] = comp1[idx, :]\n",
    "    stack_data[idx, :, 1] = comp2[idx, :]\n",
    "    stack_data[idx, :, 2] = comp3[idx, :]\n",
    "    \n",
    "# print(stack_data.shape)\n",
    "\n",
    "norm_data = np.zeros((len(stack_data), 128*3))\n",
    "print(norm_data.shape)\n",
    "\n",
    "for krow in range(len(stack_data)):\n",
    "    \n",
    "#     print(krow)\n",
    "    \n",
    "    N_data = stack_data[krow, :, 0]\n",
    "    E_data = stack_data[krow, :, 1]\n",
    "    Z_data = stack_data[krow, :, 2]\n",
    "        \n",
    "    mean_N = np.mean(N_data)\n",
    "    mean_E = np.mean(E_data)\n",
    "    mean_Z = np.mean(Z_data)\n",
    "    \n",
    "    norm_N_data = N_data - mean_N\n",
    "    norm_E_data = E_data - mean_E\n",
    "    norm_Z_data = Z_data - mean_Z\n",
    "    \n",
    "    # plt.plot(N_data, label = 'original')\n",
    "    # plt.plot(norm_N_data, label = 'norm')\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "    \n",
    "    comb_data = np.append(norm_N_data, norm_E_data)\n",
    "    comb_data = np.append(comb_data, norm_Z_data)\n",
    "    \n",
    "    norm_data[krow,:] = comb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(norm_data.shape)\n",
    "\n",
    "h5f = h5py.File(project_dir + 'gfast_test_demean_data.hdf5', 'w') \n",
    "h5f.create_dataset('gfast_test_demean_data', data = norm_data)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
