{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01575fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "project = 'july6'\n",
    "traindate = '2023-07-27'\n",
    "testdate = '2023-07-28'\n",
    "traindate_path = '/Users/sydneydybing/gnss-picker/cnn_models_outputs/' + project + '_fq_train/models/traindate_' + traindate + '/'\n",
    "test_outputs_path = traindate_path + 'data/'\n",
    "figure_save_dir = traindate_path + 'figures/'\n",
    "\n",
    "fqtest_data = np.load(test_outputs_path + testdate + '_fqtest_data.npy')\n",
    "fqtest_metadata = np.load(test_outputs_path + testdate + '_fqtest_metadata.npy')\n",
    "fqtest_target = np.load(test_outputs_path + testdate + '_fqtest_target.npy')\n",
    "fqtest_predictions = np.load(test_outputs_path + testdate + '_fqtest_predictions.npy')\n",
    "\n",
    "num_fqtest = len(fqtest_predictions)\n",
    "best_thresh = 0.13 # From code 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8c55d636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91738,)\n"
     ]
    }
   ],
   "source": [
    "# Calculating PGDs from the waveforms\n",
    "\n",
    "pgds = []\n",
    "\n",
    "for i in range(len(fqtest_data)):\n",
    "    n_data = fqtest_data[i,:,0]\n",
    "    e_data = fqtest_data[i,:,1]\n",
    "    z_data = fqtest_data[i,:,2]\n",
    "    pgd = np.max(np.sqrt((n_data)**2+(e_data)**2+(z_data)**2))\n",
    "    pgds.append(pgd)\n",
    "\n",
    "print(np.array(pgds).shape)\n",
    "np.save(test_outputs_path + 'fqtest_data_pgds.npy', np.array(pgds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "313de8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating SNRs from the waveforms using the target Gaussian peak as the arrival time\n",
    "\n",
    "targets_count = []\n",
    "\n",
    "SNRs_N = []\n",
    "SNRs_E = []\n",
    "SNRs_Z = []\n",
    "\n",
    "for idx in range(len(fqtest_target)):\n",
    "    \n",
    "    target_min = min(fqtest_target[idx,:])\n",
    "    target_max = max(fqtest_target[idx,:])\n",
    "    target_range = target_max - target_min\n",
    "    \n",
    "    if target_range != 0:\n",
    "        target_max_idx = np.argmax(fqtest_target[idx,:])\n",
    "        targets_count.append(target_max_idx)\n",
    "    \n",
    "        p_arrival_index = int(target_max_idx) # The index in the sample that the P-wave arrives at\n",
    "        \n",
    "        '''\n",
    "        In this section, I calculate the signal-to-noise ratio of the data. I \n",
    "        aim to use a window of 20 seconds before the P-wave arrival time as the \n",
    "        noise, and a window of 20 seconds after the P-wave arrival time as the \n",
    "        signal. I take the standard deviation of these segments and divide \n",
    "        signal/noise (or after/before) to get the SNR.\n",
    "        \n",
    "        Sometimes the P-wave arrival time is too close to the start or end of the\n",
    "        sample, and this causes issues. I've added conditions for these cases.\n",
    "        '''\n",
    "        \n",
    "        preeq_std_end = p_arrival_index # The end of the 20 second 'noise' section before the earthquake is the P-wave arrival index\n",
    "        \n",
    "        if preeq_std_end <= 10: # Ask Diego if this is reasonable # Try 10\n",
    "        \n",
    "            # If P-wave pick is at zero - can't calculate a pre-eq standard deviation. \n",
    "            # OR the P-wave pick is too close to zero, it throws off the SNR values by a LOT.\n",
    "            \n",
    "            SNR_N = 'nan' # Just skip it (at least 10 cases for Z component with weird SNRs - one over 10,000!)\n",
    "            SNR_E = 'nan'\n",
    "            SNR_Z = 'nan'\n",
    "        \n",
    "        elif preeq_std_end > 10 and preeq_std_end <= 20: # If the pre-earthquake noise window is smaller than 20 seconds...\n",
    "            \n",
    "            preeq_std_start = 0\n",
    "            \n",
    "            posteq_std_start = p_arrival_index # Start the section for the \"signal\" at the P-wave arrival index\n",
    "            posteq_std_end = posteq_std_start + 20\n",
    "            # posteq_std_end = posteq_std_start + p_arrival_index # If the window before is less than 20 because the arrival time is less than 20, this makes the window after that same length\n",
    "            \n",
    "            std_before_N = np.std(fqtest_data[idx,preeq_std_start:preeq_std_end,0]) # Take the standard deviation of the sections for each component\n",
    "            std_after_N = np.std(fqtest_data[idx,posteq_std_start:posteq_std_end,0])\n",
    "            std_before_E = np.std(fqtest_data[idx,preeq_std_start:preeq_std_end,1])\n",
    "            std_after_E = np.std(fqtest_data[idx,posteq_std_start:posteq_std_end,1])\n",
    "            std_before_Z = np.std(fqtest_data[idx,preeq_std_start:preeq_std_end,2])\n",
    "            std_after_Z = np.std(fqtest_data[idx,posteq_std_start:posteq_std_end,2])\n",
    "            \n",
    "            if std_before_N == 0 or std_before_E == 0 or std_before_Z == 0: # If any of the denominators are zeros, we get 'inf' in the results\n",
    "                \n",
    "                SNR_N = 'nan' # Skip 'em\n",
    "                SNR_E = 'nan'\n",
    "                SNR_Z = 'nan'\n",
    "                \n",
    "            else: # Calculate the SNR\n",
    "                \n",
    "                SNR_N = std_after_N / std_before_N\n",
    "                SNR_E = std_after_E / std_before_E\n",
    "                SNR_Z = std_after_Z / std_before_Z\n",
    "        \n",
    "        elif preeq_std_end > 20 and preeq_std_end <= 108: # Standard case where the P-wave arrival is nicely in the middle somewhere\n",
    "            \n",
    "            preeq_std_start = preeq_std_end - 20\n",
    "            \n",
    "            posteq_std_start = p_arrival_index\n",
    "            posteq_std_end = posteq_std_start + 20\n",
    "        \n",
    "            std_before_N = np.std(fqtest_data[idx,preeq_std_start:preeq_std_end,0]) # Take the standard deviation of the sections for each component\n",
    "            std_after_N = np.std(fqtest_data[idx,posteq_std_start:posteq_std_end,0])\n",
    "            std_before_E = np.std(fqtest_data[idx,preeq_std_start:preeq_std_end,1])\n",
    "            std_after_E = np.std(fqtest_data[idx,posteq_std_start:posteq_std_end,1])\n",
    "            std_before_Z = np.std(fqtest_data[idx,preeq_std_start:preeq_std_end,2])\n",
    "            std_after_Z = np.std(fqtest_data[idx,posteq_std_start:posteq_std_end,2])\n",
    "            \n",
    "            if std_before_N == 0 or std_before_E == 0 or std_before_Z == 0:\n",
    "                \n",
    "                SNR_N = 'nan'\n",
    "                SNR_E = 'nan'\n",
    "                SNR_Z = 'nan'\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                SNR_N = std_after_N / std_before_N\n",
    "                SNR_E = std_after_E / std_before_E\n",
    "                SNR_Z = std_after_Z / std_before_Z\n",
    "            \n",
    "        elif preeq_std_end > 108 and preeq_std_end < 128: # End edge case - the \"signal\" period is less than 20 seconds long\n",
    "            \n",
    "            preeq_std_start = preeq_std_end - 20\n",
    "            \n",
    "            posteq_std_start = p_arrival_index # Should the below be 127 instead??\n",
    "            posteq_std_end = posteq_std_start + (128 - p_arrival_index) # Make the signal period end at the end of the sample at 128 to avoid errors\n",
    "        \n",
    "            std_before_N = np.std(fqtest_data[idx,preeq_std_start:preeq_std_end,0]) # Take the standard deviation of the sections for each component\n",
    "            std_after_N = np.std(fqtest_data[idx,posteq_std_start:posteq_std_end,0])\n",
    "            std_before_E = np.std(fqtest_data[idx,preeq_std_start:preeq_std_end,1])\n",
    "            std_after_E = np.std(fqtest_data[idx,posteq_std_start:posteq_std_end,1])\n",
    "            std_before_Z = np.std(fqtest_data[idx,preeq_std_start:preeq_std_end,2])\n",
    "            std_after_Z = np.std(fqtest_data[idx,posteq_std_start:posteq_std_end,2])\n",
    "            \n",
    "            if std_before_N == 0 or std_before_E == 0 or std_before_Z == 0:\n",
    "                \n",
    "                SNR_N = 'nan'\n",
    "                SNR_E = 'nan'\n",
    "                SNR_Z = 'nan'\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                SNR_N = std_after_N / std_before_N\n",
    "                SNR_E = std_after_E / std_before_E\n",
    "                SNR_Z = std_after_Z / std_before_Z\n",
    "            \n",
    "        else: # Covers if the pick is exactly at 128, the end of the sample.\n",
    "            \n",
    "            # Can't get a post-eq std because the earthquake arrives at the end of the sample\n",
    "            \n",
    "            SNR_N = 'nan' # Skip 'em (5 cases)\n",
    "            SNR_E = 'nan'\n",
    "            SNR_Z = 'nan'\n",
    "            \n",
    "        '''\n",
    "        Add the calculated SNRs (or 'nan's for issues) to the lists.\n",
    "        '''\n",
    "        \n",
    "        # if SNR_N == 0:\n",
    "            \n",
    "        #     print(idx)\n",
    "            \n",
    "        SNRs_N.append(SNR_N)\n",
    "        SNRs_E.append(SNR_E)\n",
    "        SNRs_Z.append(SNR_Z)\n",
    "        \n",
    "    elif target_range == 0:\n",
    "        \n",
    "        SNRs_N.append('nan')\n",
    "        SNRs_E.append('nan')\n",
    "        SNRs_Z.append('nan')\n",
    "\n",
    "print(len(SNRs_N))\n",
    "print(len(SNRs_E))\n",
    "print(len(SNRs_Z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab33eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(test_outputs_path + 'fqtest_data_SNRs_N.npy', np.array(SNRs_N))\n",
    "np.save(test_outputs_path + 'fqtest_data_SNRs_E.npy', np.array(SNRs_E))\n",
    "np.save(test_outputs_path + 'fqtest_data_SNRs_Z.npy', np.array(SNRs_Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e768d603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/s8qp7lfs59g_tbwsx_wxkdx80000gn/T/ipykernel_12876/4125904483.py:21: RuntimeWarning: divide by zero encountered in log10\n",
      "  logsnrs = np.log10(testsnrs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaNs removed: 50161\n",
      "Number of good SNRs left: 41577\n"
     ]
    }
   ],
   "source": [
    "# Plots to check and make sure stuff looks right\n",
    "\n",
    "testmags = []\n",
    "\n",
    "for ii in range(len(fqtest_metadata)):\n",
    "    mag = fqtest_metadata[ii,2]\n",
    "    if mag == 'nan':\n",
    "        testmags.append(np.nan)\n",
    "    else:\n",
    "        testmags.append(float(mag))\n",
    "        \n",
    "testsnrs = []\n",
    "        \n",
    "for iii in range(len(SNRs_N)):\n",
    "    snr = SNRs_N[iii]\n",
    "    if snr == 'nan':\n",
    "        testsnrs.append(np.nan)\n",
    "    else:\n",
    "        testsnrs.append(float(snr))\n",
    "\n",
    "logsnrs = np.log10(testsnrs)\n",
    "logpgds = np.log10(pgds)\n",
    "\n",
    "fig = plt.subplots(nrows = 2, ncols = 2, figsize = (15,10), dpi = 300, facecolor = 'white')\n",
    "plt.suptitle('PGD and SNR distribution in FQ testing dataset', fontsize = 20)\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.hist(logpgds, bins = 50, color = 'deepskyblue', edgecolor = 'black')\n",
    "plt.xlabel('Log PGD (m)', fontsize = 16)\n",
    "plt.ylabel('Count', fontsize = 16)\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.scatter(testmags, logpgds, s = 0.5, color = 'deepskyblue')\n",
    "plt.xlabel('Magnitude', fontsize = 16)\n",
    "plt.ylabel('Log PGD (m)', fontsize = 16)\n",
    "\n",
    "# Remove NaN SNRs to be able to make this quick plot\n",
    "fixsnrs = []\n",
    "numremoved = []\n",
    "for iv in range(len(logsnrs)):\n",
    "    snr = logsnrs[iv]\n",
    "    if np.isnan(snr):\n",
    "        numremoved.append(1)\n",
    "    elif np.isinf(snr):\n",
    "        numremoved.append(1)\n",
    "    else:\n",
    "        fixsnrs.append(snr)\n",
    "        \n",
    "print('Number of NaNs removed: ' + str(len(numremoved)))\n",
    "print('Number of good SNRs left: ' + str(len(fixsnrs)))\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.hist(fixsnrs, bins = 50, color = 'limegreen', edgecolor = 'black')\n",
    "plt.xlabel('Log SNR (N-S component)', fontsize = 16)\n",
    "plt.ylabel('Count', fontsize = 16)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.scatter(testmags, logsnrs, s = 0.5, color = 'limegreen')\n",
    "plt.xlabel('Magnitude', fontsize = 16)\n",
    "plt.ylabel('Log SNR (N-S component)', fontsize = 16)\n",
    "\n",
    "# plt.show();\n",
    "plt.savefig(figure_save_dir + '9_pgd_and_snr_distribution_fqtest_data.png', format = 'PNG')\n",
    "plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "13e3ed60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45869\n"
     ]
    }
   ],
   "source": [
    "# Make a list of indices for rows in the testing dataset that actually have earthquakes\n",
    "\n",
    "rows_w_eqs = []\n",
    "\n",
    "for idx in range(len(fqtest_metadata)):\n",
    "    \n",
    "    if fqtest_metadata[idx,0] == 'nan':\n",
    "        pass\n",
    "#         print('nan row: ' + str(idx))\n",
    "    else:\n",
    "#         print('eq row: '+ str(idx) + ', rupture ' + fqtest_metadata[idx,0])\n",
    "        rows_w_eqs.append(idx)\n",
    "\n",
    "print(len(rows_w_eqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb38e4e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5bc28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This next section deals with calculating the averages for the entire set of \n",
    "# earthquakes and the set of earthquakes which the CNN got correct in testing.\n",
    "\n",
    "pgds_vector = np.array(pgds).reshape(len(pgds),1) # Turn the list of PGDs we made into a vector...\n",
    "\n",
    "\n",
    "rows_w_eqs = np.load('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/More_RealData/rowsweqs.npy') # Rows that have earthquakes\n",
    "correct_eq_inds = np.genfromtxt('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/newtrain_march/more_realdata_norm_testing/correct_indices.txt', dtype = 'int') # Rows that the CNN found earthquakes in\n",
    "\n",
    "'''\n",
    "Calculating average PGDs for the groups.\n",
    "'''\n",
    "\n",
    "all_eq_pgds = np.asfarray(new_meta_array[rows_w_eqs, 6]) # The PGDs of all of the earthquakes\n",
    "correct_eq_pgds = np.asfarray(new_meta_array[correct_eq_inds, 6]) # The PGDs of all the earthquakes the CNN found\n",
    "\n",
    "all_eq_avg_PGD = np.mean(all_eq_pgds)\n",
    "correct_eq_avg_PGD = np.mean(correct_eq_pgds)\n",
    "\n",
    "print('Average PGD of all earthquakes: ' + str(round((all_eq_avg_PGD * 100),2)) + ' cm')\n",
    "print('Average PGD of earthquakes the CNN correctly found: ' + str(round((correct_eq_avg_PGD * 100),2)) + ' cm')\n",
    "print('-------------------------------------------------------------------')\n",
    "\n",
    "'''\n",
    "Calculating average SNRs for all three components of both groups.\n",
    "'''\n",
    "\n",
    "SNR_N_vector = np.array(SNRs_N).reshape(len(SNRs_N),1) # Turns the lists of SNRs into vectors...\n",
    "SNR_E_vector = np.array(SNRs_E).reshape(len(SNRs_E),1)\n",
    "SNR_Z_vector = np.array(SNRs_Z).reshape(len(SNRs_Z),1)\n",
    "\n",
    "new_meta_array_a = np.append(new_meta_array, SNR_N_vector, axis = 1) # ...And adds these to make another new metadata array\n",
    "new_meta_array_b = np.append(new_meta_array_a, SNR_E_vector, axis = 1)\n",
    "new_meta_array_2 = np.append(new_meta_array_b, SNR_Z_vector, axis = 1)\n",
    "\n",
    "# print(new_meta_array_2[0]) # Columns: station, date, start time, end time, counter, gauss position, pgd, SNR N component, SNR E, SNR Z\n",
    "\n",
    "np.save('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/More_RealData/real_metadata_w_gauss_pgd_snr.npy', new_meta_array_2)\n",
    "\n",
    "'''\n",
    "Because of the edge cases in the loop above, there are some nans in our SNR vectors.\n",
    "We can't calculate averages with nans, so we need to find the rows with nans and\n",
    "just remove them for the sake of this calculation.\n",
    "'''\n",
    "\n",
    "h = np.where(new_meta_array_2[rows_w_eqs,7] == 'nan') # Finds nans for all earthquakes\n",
    "non_nan_rows_w_eqs = np.delete(rows_w_eqs, h) # Removes those rows\n",
    "\n",
    "j = np.where(new_meta_array_2[correct_eq_inds,7] == 'nan') # Finds nans for the earthquakes the CNN found\n",
    "non_nan_correct_eq_inds = np.delete(correct_eq_inds, j) # Removes those rows\n",
    "\n",
    "'''\n",
    "Now I just grab the good SNRs out of the new metadata array and calculate the averages.\n",
    "'''\n",
    "\n",
    "all_eq_SNR_N = np.asfarray(new_meta_array_2[non_nan_rows_w_eqs, 7])\n",
    "all_eq_SNR_E = np.asfarray(new_meta_array_2[non_nan_rows_w_eqs, 8])\n",
    "all_eq_SNR_Z = np.asfarray(new_meta_array_2[non_nan_rows_w_eqs, 9])\n",
    "\n",
    "correct_eq_SNR_N = np.asfarray(new_meta_array_2[non_nan_correct_eq_inds, 7])\n",
    "correct_eq_SNR_E = np.asfarray(new_meta_array_2[non_nan_correct_eq_inds, 8])\n",
    "correct_eq_SNR_Z = np.asfarray(new_meta_array_2[non_nan_correct_eq_inds, 9])\n",
    "\n",
    "all_eq_SNR_N_avg = np.mean(all_eq_SNR_N)\n",
    "all_eq_SNR_E_avg = np.mean(all_eq_SNR_E)\n",
    "all_eq_SNR_Z_avg = np.mean(all_eq_SNR_Z)\n",
    "\n",
    "correct_eq_SNR_N_avg = np.mean(correct_eq_SNR_N)\n",
    "correct_eq_SNR_E_avg = np.mean(correct_eq_SNR_E)\n",
    "correct_eq_SNR_Z_avg = np.mean(correct_eq_SNR_Z)\n",
    "\n",
    "print(len(all_eq_SNR_N))\n",
    "print(len(correct_eq_SNR_N))\n",
    "\n",
    "print('Average N-S component SNR of all earthquakes: ' + str(round(all_eq_SNR_N_avg,2)))\n",
    "print('Average N-S component SNR of earthquakes the CNN correctly found: ' + str(round(correct_eq_SNR_N_avg,2)))\n",
    "print('-------------------------------------------------------------------')\n",
    "\n",
    "print('Average E-W component SNR of all earthquakes: ' + str(round(all_eq_SNR_E_avg,2)))\n",
    "print('Average E-W component SNR of earthquakes the CNN correctly found: ' + str(round(correct_eq_SNR_E_avg,2)))\n",
    "print('-------------------------------------------------------------------')\n",
    "\n",
    "print('Average Z component SNR of all earthquakes: ' + str(round(all_eq_SNR_Z_avg,2)))\n",
    "print('Average Z component SNR of earthquakes the CNN correctly found: ' + str(round(correct_eq_SNR_Z_avg,2)))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
