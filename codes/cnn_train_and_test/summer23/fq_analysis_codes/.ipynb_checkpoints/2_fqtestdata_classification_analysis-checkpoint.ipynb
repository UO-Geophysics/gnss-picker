{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "539ce257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "140daa4f-56dd-42d4-861d-2d8e92558411",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'newfault'\n",
    "traindate = '2024-10-01'\n",
    "testdate = '2024-10-02'\n",
    "traindate_path = '/home/sdybing/gnss-picker/cnn_models_outputs/' + project + '_fq_train/models/traindate_' + traindate + '/'\n",
    "test_outputs_path = traindate_path + 'data/fakequakes_testing/classification_stats/'\n",
    "figure_save_dir = traindate_path + 'figures/fakequakes_testing/classification_stats/'\n",
    "\n",
    "fqtest_data = np.load(traindate_path + 'data/' + testdate + '_fqtest_norm_data.npy')\n",
    "fqtest_metadata = np.load(traindate_path + 'data/' + testdate + '_fqtest_metadata.npy')\n",
    "fqtest_target = np.load(traindate_path + 'data/' + testdate + '_fqtest_target.npy')\n",
    "fqtest_predictions = np.load(traindate_path + 'data/' + testdate + '_fqtest_predictions.npy')\n",
    "\n",
    "num_fqtest = len(fqtest_predictions)\n",
    "thresholds = np.arange(0, 1.005, 0.005)\n",
    "test_thresholds = [0, 0.005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7fa30d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n",
      "Threshold: 0.0\n",
      "Accuracy: 50.0%\n",
      "-------------------------------------------------------------\n",
      "Threshold: 0.005\n",
      "Accuracy: 50.0%\n",
      "-------------------------------------------------------------\n",
      "Threshold: 0.01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m targ_binary \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(fqtest_target))\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m iterate:\n\u001b[0;32m---> 35\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfqtest_target\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(i) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     37\u001b[0m         targ_binary[k] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36mwhere\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "accuracies_per = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "F1s = []\n",
    "\n",
    "for ind in range(len(thresholds)):\n",
    "    \n",
    "    threshold = np.round(thresholds[ind],3)\n",
    "    \n",
    "    print('-------------------------------------------------------------')\n",
    "    print('Threshold: ' + str(threshold))\n",
    "    \n",
    "    iterate = np.arange(0,num_fqtest,1)\n",
    "    \n",
    "    # Convert the prediction arrays to 1s and 0s if the prediction Gaussian exceeded the threshold or not\n",
    "        \n",
    "    pred_binary = np.zeros(len(fqtest_predictions)) # Initialize the array with all zeros\n",
    "    for k in iterate:\n",
    "#         plt.plot(fqtest_predictions[k]) # The output \"Gaussian\" or straight line prediction\n",
    "#         plt.ylim(0,1)\n",
    "#         plt.show()\n",
    "        i = np.where(fqtest_predictions[k] >= threshold)[0]\n",
    "        if len(i) == 0: \n",
    "            pred_binary[k] = 0\n",
    "        elif len(i) > 0: # If anywhere in the prediction the Gaussian exceeds the threadshold, add a 1 to the pred_binary array for this prediction\n",
    "            pred_binary[k] = 1\n",
    "#     print('Predictions: ')\n",
    "#     print(pred_binary) \n",
    "    \n",
    "    # Convert the target arrays to 1s and 0s if the Gaussian exceeded the threshold or not (signal or noise)\n",
    "    \n",
    "    targ_binary = np.zeros(len(fqtest_target))\n",
    "    for k in iterate:\n",
    "        i = np.where(fqtest_target[k] > 0)[0]\n",
    "        if len(i) == 0:\n",
    "            targ_binary[k] = 0\n",
    "        elif len(i) > 0:\n",
    "            targ_binary[k] = 1\n",
    "#     print('Targets: ')\n",
    "#     print(targ_binary)\n",
    "    \n",
    "    # Calculating the accuracy, precision, recall, and F1\n",
    "    \n",
    "    num_preds = num_fqtest # Total number of predictions\n",
    "    correct_preds = []\n",
    "    wrong_preds = []\n",
    "    true_pos = []\n",
    "    true_neg = []\n",
    "    false_pos = []\n",
    "    false_neg = []\n",
    "    \n",
    "    for i in iterate:\n",
    "        \n",
    "        pred = pred_binary[i]\n",
    "        targ = targ_binary[i]\n",
    "        \n",
    "        if pred == targ: # Add one to list of correct predictions if matching\n",
    "            correct_preds.append(1)\n",
    "            \n",
    "            if pred == 1 and targ == 1: # True positive: there is an earthquake, and the model found it\n",
    "                true_pos.append(1)\n",
    "            elif pred == 0 and targ == 0: # True negative: there isn't an earthquake, and the model found just noise\n",
    "                true_neg.append(1)\n",
    "            \n",
    "        elif pred != targ: # Add ones to list of incorrect predictions if not matching\n",
    "            wrong_preds.append(1)\n",
    "            \n",
    "            if pred == 1 and targ == 0: # False positive: there isn't an earthquake, and the model thought it found one\n",
    "                false_pos.append(1)\n",
    "            elif pred == 0 and targ == 1: # False negative: there is an earthquake, and the model missed it\n",
    "                false_neg.append(1)\n",
    "    \n",
    "    num_correct_preds = len(correct_preds)\n",
    "    num_wrong_preds = len(wrong_preds)\n",
    "    num_true_pos = len(true_pos)\n",
    "    num_true_neg = len(true_neg)\n",
    "    num_false_pos = len(false_pos)\n",
    "    num_false_neg = len(false_neg)\n",
    "    \n",
    "    # print('Threshold: ' + str(threshold))\n",
    "    # print('Correct preds: ' + str(num_correct_preds))\n",
    "    # print('Wrong preds: ' + str(num_wrong_preds))\n",
    "    # print('True pos: ' + str(num_true_pos))\n",
    "    # print('True neg: ' + str(num_true_neg))\n",
    "    # print('False pos: ' + str(num_false_pos))\n",
    "    # print('False neg: ' + str(num_false_neg))\n",
    "    \n",
    "    accuracy = num_correct_preds / num_preds\n",
    "    accuracy_per = (num_correct_preds / num_preds) * 100\n",
    "    print('Accuracy: ' + str(accuracy_per) + '%')\n",
    "    \n",
    "    if num_true_pos == 0  and num_false_pos == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = num_true_pos / (num_true_pos + num_false_pos)\n",
    "    \n",
    "    if num_true_pos == 0 and num_false_neg == 0:\n",
    "        recall = 0\n",
    "    else:\n",
    "        recall = num_true_pos / (num_true_pos + num_false_neg)\n",
    "    \n",
    "    if precision + recall == 0:\n",
    "        F1 = 0\n",
    "    else:\n",
    "        F1 = 2 * ((precision * recall) / (precision + recall))\n",
    "    \n",
    "    accuracies.append(accuracy)\n",
    "    accuracies_per.append(accuracy_per)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    F1s.append(F1)\n",
    "\n",
    "# print('Accuracies')\n",
    "# print(accuracies)\n",
    "# print('Precisions')\n",
    "# print(precisions)\n",
    "# print('Recalls')\n",
    "# print(recalls)\n",
    "# print('F1s')\n",
    "# print(F1s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6b40096",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(test_outputs_path + 'thresholds.npy', thresholds)\n",
    "np.save(test_outputs_path + 'accuracies.npy', accuracies)\n",
    "np.save(test_outputs_path + 'precisions.npy', precisions)\n",
    "np.save(test_outputs_path + 'recalls.npy', recalls)\n",
    "np.save(test_outputs_path + 'F1s.npy', F1s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01212a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.135\n"
     ]
    }
   ],
   "source": [
    "# Find threshold with highest accuracy\n",
    "\n",
    "acc0 = 0\n",
    "\n",
    "for idx in range(len(accuracies_per)):\n",
    "    acc = accuracies_per[idx]\n",
    "    if acc > acc0:\n",
    "        acc0 = acc\n",
    "        best_thresh = thresholds[idx] # Only updates when it hits a higher accuracy\n",
    "        \n",
    "print(best_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa1ceb7b-bbfa-45b2-834a-f1d9bd62a898",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_thresh = 0.135"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac535dc4-1f0b-4089-93d6-0972ac8afda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.load(test_outputs_path + 'thresholds.npy')\n",
    "accuracies = np.load(test_outputs_path + 'accuracies.npy')\n",
    "precisions = np.load(test_outputs_path + 'precisions.npy')\n",
    "recalls = np.load(test_outputs_path + 'recalls.npy')\n",
    "F1s = np.load(test_outputs_path + 'F1s.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46bb5c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,5), dpi = 300)\n",
    "plt.plot(thresholds, accuracies, linewidth = 2)\n",
    "plt.xlabel('Threshold', fontsize = 18)\n",
    "plt.ylabel('Accuracy', fontsize = 18)\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,100)\n",
    "plt.axvline(best_thresh, color = 'red', linestyle = '--', alpha = 0.6, label = 'Max accuracy at\\nthreshold of ' + str(best_thresh))\n",
    "plt.xticks(fontsize = 15)\n",
    "plt.yticks(fontsize = 15)\n",
    "plt.title('Accuracy', fontsize = 18)\n",
    "plt.legend()\n",
    "# plt.show();\n",
    "plt.savefig(figure_save_dir + 'accuracy_by_threshold.png', format = 'PNG', facecolor = 'white')\n",
    "plt.close();\n",
    "\n",
    "plt.figure(figsize = (8,5), dpi = 300)\n",
    "plt.plot(thresholds, precisions, linewidth = 2)\n",
    "plt.xlabel('Threshold', fontsize = 18)\n",
    "plt.ylabel('Precision', fontsize = 18)\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.xticks(fontsize = 15)\n",
    "plt.yticks(fontsize = 15)\n",
    "plt.title('Precision', fontsize = 18)\n",
    "# plt.show();\n",
    "plt.savefig(figure_save_dir + 'precision_by_threshold.png', format = 'PNG', facecolor = 'white')\n",
    "plt.close();\n",
    "\n",
    "plt.figure(figsize = (8,5), dpi = 300)\n",
    "plt.plot(thresholds, recalls, linewidth = 2)\n",
    "plt.xlabel('Threshold', fontsize = 18)\n",
    "plt.ylabel('Recall', fontsize = 18)\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.xticks(fontsize = 15)\n",
    "plt.yticks(fontsize = 15)\n",
    "plt.title('Recall', fontsize = 18)\n",
    "# plt.show();\n",
    "plt.savefig(figure_save_dir + 'recall_by_threshold.png', format = 'PNG', facecolor = 'white')\n",
    "plt.close();\n",
    "\n",
    "plt.figure(figsize = (8,5), dpi = 300)\n",
    "plt.plot(thresholds, F1s, linewidth = 2)\n",
    "plt.xlabel('Threshold', fontsize = 18)\n",
    "plt.ylabel('F1', fontsize = 18)\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.xticks(fontsize = 15)\n",
    "plt.yticks(fontsize = 15)\n",
    "plt.title('F1', fontsize = 18)\n",
    "# plt.show();\n",
    "plt.savefig(figure_save_dir + 'F1_by_threshold.png', format = 'PNG', facecolor = 'white')\n",
    "plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2471559-fb46-4727-a40d-0847b932ae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subplot version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fae06cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,5), dpi = 400)\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.text(x = -0.3, y = 0.9, s = '(a)', fontsize = 22)\n",
    "plt.grid(lw = 0.5, zorder = 0)\n",
    "plt.plot(thresholds, accuracies, linewidth = 2)\n",
    "plt.ylabel('Accuracy', fontsize = 12)\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.axvline(best_thresh, color = 'red', linestyle = '--', alpha = 0.6, label = 'Max accuracy at threshold of ' + str(best_thresh))\n",
    "plt.tick_params(axis = 'both', bottom = False, labelbottom = False)\n",
    "plt.yticks(fontsize = 11)\n",
    "plt.legend(loc = (0.55,-1.45))\n",
    "\n",
    "# plt.legend()\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.text(x = -0.3, y = 0.9, s = '(b)', fontsize = 22)\n",
    "plt.grid(lw = 0.5, zorder = 0)\n",
    "plt.plot(thresholds, precisions, linewidth = 2)\n",
    "plt.ylabel('Precision', fontsize = 12)\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.tick_params(axis = 'both', bottom = False, labelbottom = False)\n",
    "plt.axvline(best_thresh, color = 'red', linestyle = '--', alpha = 0.6)\n",
    "plt.yticks(fontsize = 11)\n",
    "\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.text(x = -0.3, y = 0.9, s = '(c)', fontsize = 22)\n",
    "plt.grid(lw = 0.5, zorder = 0)\n",
    "plt.plot(thresholds, recalls, linewidth = 2)\n",
    "plt.xlabel('Threshold', fontsize = 12)\n",
    "plt.ylabel('Recall', fontsize = 12)\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.xticks(fontsize = 11)\n",
    "plt.yticks([0, 0.2, 0.4, 0.6, 0.8], fontsize = 11)\n",
    "plt.axvline(best_thresh, color = 'red', linestyle = '--', alpha = 0.6)\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.text(x = -0.3, y = 0.9, s = '(d)', fontsize = 22)\n",
    "plt.grid(lw = 0.5, zorder = 0)\n",
    "plt.plot(thresholds, F1s, linewidth = 2)\n",
    "plt.xlabel('Threshold', fontsize = 12)\n",
    "plt.ylabel('F1', fontsize = 12)\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.xticks(fontsize = 11)\n",
    "plt.yticks([0, 0.2, 0.4, 0.6, 0.8], fontsize = 11)\n",
    "plt.axvline(best_thresh, color = 'red', linestyle = '--', alpha = 0.6)\n",
    "\n",
    "plt.subplots_adjust(hspace = 0, wspace = 0.32, bottom = 0.2)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "plt.savefig('/home/sdybing/gnss-picker/manuscript_figures/fq_testdata_classification.jpg', format = 'JPG')\n",
    "plt.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9371ac-1263-4cda-8ce2-70c81338e1f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
