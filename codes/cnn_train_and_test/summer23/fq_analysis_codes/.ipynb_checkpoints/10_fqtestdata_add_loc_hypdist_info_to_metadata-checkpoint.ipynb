{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa972930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from obspy.geodetics import gps2dist_azimuth\n",
    "\n",
    "project = 'newfault'\n",
    "traindate = '2024-10-01'\n",
    "testdate = '2024-10-02'\n",
    "traindate_path = '/home/sdybing/gnss-picker/cnn_models_outputs/' + project + '_fq_train/models/traindate_' + traindate + '/'\n",
    "test_outputs_path = traindate_path + 'data/'\n",
    "figure_save_dir = traindate_path + 'figures/'\n",
    "best_thresh = 0.135 # From code 2\n",
    "\n",
    "results = np.load(test_outputs_path + 'fakequakes_testing/fqtest_metadata_with_results_pgd_snr.npy')\n",
    "\n",
    "# Columns:\n",
    "\n",
    "# 0: FQ rupture name\n",
    "# 1: station name\n",
    "# 2: magnitude\n",
    "# 3: result (true pos, etc.)\n",
    "# 4: PGD\n",
    "# 5: SNR_N\n",
    "# 6: SNR_E\n",
    "# 7: SNR_Z\n",
    "\n",
    "waveforms = np.load(test_outputs_path + testdate + '_fqtest_orig_data.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57fff6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_lats = []\n",
    "eq_lons = []\n",
    "eq_depths = []\n",
    "sta_lats = []\n",
    "sta_lons = []\n",
    "dist_ms = []\n",
    "\n",
    "for i in range(len(results)):\n",
    "    \n",
    "    if results[i][0] == 'nan':\n",
    "        rupture = 'nan'\n",
    "        station = 'nan'\n",
    "        mag = 'nan'\n",
    "        pgd = 'nan'\n",
    "        \n",
    "        if results[i][3] == 'true pos': # predicted 1, target 1\n",
    "            result = 'true_pos'\n",
    "        \n",
    "        elif results[i][3] == 'true neg': # predicted 0, target 0\n",
    "            result = 'true_neg'\n",
    "            \n",
    "        elif results[i][3] == 'false pos': # predicted 1, target 0\n",
    "            result = 'false_pos'\n",
    "        \n",
    "        elif results[i][3] == 'false neg': # predicted 0, target 1\n",
    "            result = 'false_neg'\n",
    "        \n",
    "        eq_lat = 'nan'\n",
    "        eq_lon = 'nan'\n",
    "        eq_depth = 'nan'\n",
    "        sta_lat = 'nan'\n",
    "        sta_lon = 'nan'\n",
    "        dist_m = 'nan'\n",
    "        \n",
    "        eq_lats.append(eq_lat)\n",
    "        eq_lons.append(eq_lon)\n",
    "        eq_depths.append(eq_depth)\n",
    "        sta_lats.append(sta_lat)\n",
    "        sta_lons.append(sta_lon)\n",
    "        dist_ms.append(dist_m)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        # Getting rupture name and calculating hypocentral distance\n",
    "        \n",
    "        rupture = results[i][0]\n",
    "#         print(rupture)\n",
    "\n",
    "        log = glob('/hdd/rc_fq/fall24/newfault/output/ruptures/' + rupture + '.log') # for Valdivia\n",
    "#         print(log)\n",
    "    \n",
    "        f = open(log[0],'r')\n",
    "        line = f.readlines()\n",
    "        \n",
    "        # Getting hypocenter location\n",
    "        hyp_loc_junk = line[16]\n",
    "#         print(hyp_loc_junk)\n",
    "        eq_lon = float(hyp_loc_junk.split(' ')[2].split('(')[1].split(')')[0].split(',')[0])\n",
    "        eq_lat = float(hyp_loc_junk.split(' ')[2].split('(')[1].split(')')[0].split(',')[1])\n",
    "        eq_depth = float(hyp_loc_junk.split(' ')[2].split('(')[1].split(')')[0].split(',')[2])\n",
    "        eq_depth_m = eq_depth * 1000\n",
    "        \n",
    "        station = results[i][1]\n",
    "        \n",
    "        station_info = np.genfromtxt('/hdd/rc_fq/fall24/newfault/data/station_info/rc_gflist.gflist', dtype = 'U')\n",
    "#         print(station)\n",
    "        \n",
    "        k = np.where(station_info[:,0] == station)[0]\n",
    "#         print(station_info[k][0])\n",
    "        \n",
    "        # Getting station location\n",
    "        \n",
    "        sta_lon = float(station_info[k][0][1])\n",
    "        sta_lat = float(station_info[k][0][2])\n",
    "#         print(sta_lon)\n",
    "#         print(sta_lat)\n",
    "\n",
    "        # Calculating hypocentral distance\n",
    "\n",
    "        distaz = gps2dist_azimuth(eq_lat, eq_lon, sta_lat, sta_lon)\n",
    "        dist_m = distaz[0]\n",
    "#         print(dist_m)\n",
    "        \n",
    "        # Adding info about result of training\n",
    "        \n",
    "        if results[i][3] == 'true pos': # predicted 1, target 1\n",
    "            mag = float(results[i][2])\n",
    "            dot = 2\n",
    "            result = 'true_pos'\n",
    "        \n",
    "        elif results[i][3] == 'true neg': # predicted 0, target 0\n",
    "            mag = float(results[i][2])\n",
    "            dot = 1\n",
    "            result = 'true_neg'\n",
    "            \n",
    "        elif results[i][3] == 'false pos': # predicted 1, target 0\n",
    "            mag = float(results[i][2])\n",
    "            dot = 0\n",
    "            result = 'false_pos'\n",
    "        \n",
    "        elif results[i][3] == 'false neg': # predicted 0, target 1\n",
    "            mag = float(results[i][2])\n",
    "            dot = -1\n",
    "            result = 'false_neg'\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        eq_lats.append(eq_lat)\n",
    "        eq_lons.append(eq_lon)\n",
    "        eq_depths.append(eq_depth)\n",
    "        sta_lats.append(sta_lat)\n",
    "        sta_lons.append(sta_lon)\n",
    "        dist_ms.append(dist_m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "634ef28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to the results metadata array\n",
    "\n",
    "eqlats_vector = np.array(eq_lats).reshape(len(eq_lats),1) \n",
    "eqlons_vector = np.array(eq_lons).reshape(len(eq_lons),1) \n",
    "eqdepths_vector = np.array(eq_depths).reshape(len(eq_depths),1) \n",
    "stalats_vector = np.array(sta_lats).reshape(len(sta_lats),1) \n",
    "stalons_vector = np.array(sta_lons).reshape(len(sta_lons),1) \n",
    "distms_vector = np.array(dist_ms).reshape(len(dist_ms),1) \n",
    "\n",
    "a = np.append(results, eqlats_vector, axis = 1) \n",
    "b = np.append(a, eqlons_vector, axis = 1)\n",
    "c = np.append(b, eqdepths_vector, axis = 1)\n",
    "d = np.append(c, stalats_vector, axis = 1)\n",
    "e = np.append(d, stalons_vector, axis = 1)\n",
    "new_meta_array = np.append(e, distms_vector, axis = 1)\n",
    "\n",
    "# New metadata array columns:\n",
    "\n",
    "# 0: FQ rupture name\n",
    "# 1: station name\n",
    "# 2: magnitude\n",
    "# 3: result (true pos, etc.)\n",
    "# 4: PGD\n",
    "# 5: SNR_N\n",
    "# 6: SNR_E\n",
    "# 7: SNR_Z\n",
    "# 8: FQ rupture hypocenter lat\n",
    "# 9: FQ rupture hypocenter lon\n",
    "# 10: FQ rupture hypocenter depth\n",
    "# 11: station lat\n",
    "# 12: station lon\n",
    "# 13: hypocentral distance (m)\n",
    "\n",
    "np.save(test_outputs_path + 'fakequakes_testing/fqtest_metadata_with_results_pgd_snr_locs_hypdists.npy', new_meta_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87d31058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91740, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_meta_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187eb681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cde6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
