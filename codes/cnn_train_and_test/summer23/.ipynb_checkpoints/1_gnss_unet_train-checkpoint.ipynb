{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47688b33",
   "metadata": {},
   "source": [
    "## Imports and Path/Variable Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153a368c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from scipy import signal\n",
    "import argparse\n",
    "import seaborn as sns\n",
    "from datetime import date\n",
    "import os\n",
    "import X_gnss_unet_datagen_fn22 # Module with CNN/data generator code\n",
    "\n",
    "sns.set_style('white')\n",
    "\n",
    "project_name = 'newfault' # Based on the name of the FakeQuakes project\n",
    "fq_dir = '/hdd/rc_fq/fall24/' # Where are the FakeQuakes stored? (The final .hdf5 file)\n",
    "noise_dir = '/home/sdybing/gnss-picker/data/noisedata/' # Where is the noise data stored?\n",
    "realdata_dir = '/home/sdybing/gnss-picker/data/realdata/summer23/' # Where is the real data stored?\n",
    "\n",
    "cnn_save_dir = '/home/sdybing/gnss-picker/cnn_models_outputs/' # Where do you want to save this code's outputs?\n",
    "project_save_dir = cnn_save_dir + project_name + '_fq_train/'\n",
    "base_figure_save_dir = project_save_dir + 'base_data_figures/' # Where to save the figures of just the data/generator tests\n",
    "models_path = project_save_dir + 'models/'\n",
    "if os.path.isdir(project_save_dir):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(project_save_dir)\n",
    "    os.makedirs(base_figure_save_dir)\n",
    "    os.makedirs(models_path)\n",
    "    \n",
    "train = False # Do you want to train?\n",
    "drop = 1 # Drop?\n",
    "resume = 0 # Resume training\n",
    "large = 0.5 # Large unet\n",
    "fac = large\n",
    "epochs = 100 # How many epochs?\n",
    "std = 3 # How long do you want the Gaussian STD to be?\n",
    "sr = 1 # Sample rate (Hz)\n",
    "epsilon = 1e-6\n",
    "batch_size = 32\n",
    "load = True # Loading an old trained model?\n",
    "small_train = False # Train with a smaller amount of data to make sure code works?\n",
    "small_test = False # Test with a smaller amount of data to make sure code works?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cab514d",
   "metadata": {},
   "source": [
    "## Data Loading and Formatting\n",
    "\n",
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcd4d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FakeQuakes waveform data\n",
    "print('Loading FakeQuakes...')\n",
    "fq_data = h5py.File(fq_dir + 'newfault_fq_wvfm_data_formatted.hdf5', 'r')\n",
    "fq_data = fq_data['data'][:,:]\n",
    "# old_fq_data = h5py.File(fq_dir + 'july6_128samps_fq_wvfm_data_formatted.hdf5', 'r')\n",
    "# old_fq_data = old_fq_data['data'][:,:]\n",
    "\n",
    "# FakeQuakes metadata\n",
    "print('Loading FakeQuakes metadata...')\n",
    "fq_metadata = np.load(fq_dir + 'newfault_fq_wvfm_info.npy')\n",
    "\n",
    "# Noise data\n",
    "print('Loading noise...')\n",
    "all_noise_data = h5py.File(noise_dir + 'summer23_128samps_all_noise_samples.hdf5', 'r')\n",
    "all_noise_data = all_noise_data['all_noise_samples'][:,:]\n",
    "\n",
    "# Demeaned real waveform data\n",
    "print('Loading real data...')\n",
    "real_data = h5py.File(realdata_dir + 'demean_realdata_rembad.hdf5', 'r')\n",
    "real_data = real_data['demean_realdata_rembad'][:,:]\n",
    "\n",
    "# Real metadata\n",
    "print('Loading real metadata...')\n",
    "real_metadata = np.load(realdata_dir + 'real_metadata_rembad_w_gauss_pos_mag.npy')\n",
    "\n",
    "# Trim noise data to match length of FakeQuakes data\n",
    "noise_data = all_noise_data[:len(fq_data)]\n",
    "\n",
    "# Array of NaNs to use to match added noise in concatenation later\n",
    "nan_array = np.empty((len(fq_data), 3))\n",
    "nan_array[:] = np.NaN\n",
    "\n",
    "# Real data\n",
    "\n",
    "# Check shapes\n",
    "print('FakeQuakes shape: ' + str(fq_data.shape))\n",
    "print('Noise data shape: ' + str(noise_data.shape))\n",
    "print('Real data shape: ' + str(real_data.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725b7948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Finding bad ruptures (data all zeros) - uses normalized fq_data file\n",
    "# No bad ruptures in july6 data\n",
    "\n",
    "# inf_idxs = []\n",
    "\n",
    "# for idx in range(len(fq_data)):\n",
    "#     row = fq_data[idx]\n",
    "#     check_nan = np.isnan(row)\n",
    "#     check_inf = np.isinf(row)\n",
    "#     l = np.where(check_nan == True)[0]\n",
    "#     m = np.where(check_inf == True)[0]\n",
    "    \n",
    "#     if len(l) > 0 or len(m) > 0:\n",
    "#         inf_idxs.append(idx)\n",
    "\n",
    "# bad_rupts = []\n",
    "\n",
    "# for i in inf_idxs:\n",
    "# #     plt.plot(old_fq_data[i]) # Need to go back to 3a code and remove things that are all zero\n",
    "# #     print(fq_metadata[i][0])\n",
    "#     if fq_metadata[i][0] in bad_rupts:\n",
    "#         pass\n",
    "#     else:\n",
    "#         bad_rupts.append(fq_metadata[i][0])\n",
    "\n",
    "# # np.save('/hdd/rc_fq/summer23/july6_bad_rupts.npy', np.array(bad_rupts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5a5a0f",
   "metadata": {},
   "source": [
    "### Format and Split Training, Validation, and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2910c76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(27)\n",
    "\n",
    "# Earthquake/signal data\n",
    "fqinds = np.arange(fq_data.shape[0]) # Signal indices\n",
    "np.random.shuffle(fqinds) # Shuffles the indices\n",
    "train_fqinds = fqinds[:int(0.8*len(fqinds))] # Training data separation: grabs the front 80% of the numbers\n",
    "valid_fqinds = fqinds[int(0.8*len(fqinds)):int(0.9*len(fqinds)):] # Grabs the next 10% (80-90%)\n",
    "test_fqinds = fqinds[int(0.9*len(fqinds)):] # Grabs the last 10% (90%-end)\n",
    "\n",
    "# Noise data\n",
    "noiseinds = np.arange(noise_data.shape[0]) # Noise indices\n",
    "np.random.shuffle(noiseinds) # Shuffles the indices\n",
    "train_noiseinds = noiseinds[:int(0.8*len(noiseinds))] # Data separation as above\n",
    "valid_noiseinds = noiseinds[int(0.8*len(noiseinds)):int(0.9*len(noiseinds))]\n",
    "test_noiseinds = noiseinds[int(0.9*len(noiseinds)):]\n",
    "\n",
    "# Check shapes to confirm compatability\n",
    "print('Full FakeQuakes data shape: ' + str(fqinds.shape))\n",
    "print('FakeQuakes training data shape: ' + str(train_fqinds.shape))\n",
    "print('FakeQuakes validation data shape: ' + str(valid_fqinds.shape))\n",
    "print('FakeQuakes testing data shape: ' + str(test_fqinds.shape))\n",
    "print('Full noise data shape: ' + str(noiseinds.shape))\n",
    "print('Noise training data shape: ' + str(train_noiseinds.shape))\n",
    "print('Noise validation data shape: ' + str(valid_noiseinds.shape))\n",
    "print('Noise testing data shape: ' + str(test_noiseinds.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ce024b",
   "metadata": {},
   "source": [
    "### Check Loaded Data with Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba1d929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the FakeQuakes data\n",
    "plt.figure(figsize = (8,5))   \n",
    "plt.title('Earthquake test', fontsize = 14)\n",
    "for idx in range(10): # plot 10 of them\n",
    "    plt.plot(fq_data[idx,:] / np.max(np.abs(fq_data[idx,:])) + idx) # Normalized and offset for each idx\n",
    "plt.axvline(256.5, linestyle = '--', color = 'lightgray')\n",
    "plt.axvline(513.5, linestyle = '--', color = 'lightgray')\n",
    "plt.xlabel('Time (s)', fontsize = 12)\n",
    "plt.ylabel('Normalized amplitude', fontsize = 12)\n",
    "plt.xlim(0,770)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.text(x = 5, y = -0.75, s = 'N', fontsize = 20)\n",
    "plt.text(x = 261, y = -0.75, s = 'E', fontsize = 20)\n",
    "plt.text(x = 518, y = -0.75, s = 'Z', fontsize = 20)\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig(base_figure_save_dir + '1_plot_raw_eq_data.png', format = 'PNG')\n",
    "# plt.close()\n",
    "\n",
    "# Plot noise to check\n",
    "plt.figure(figsize = (8,5))\n",
    "plt.title('Noise test', fontsize = 14)\n",
    "for idx in range(10):\n",
    "    plt.plot(noise_data[idx,:] / np.max(np.abs(noise_data[idx,:])) + idx)\n",
    "plt.axvline(256.5, linestyle = '--', color = 'lightgray')\n",
    "plt.axvline(513.5, linestyle = '--', color = 'lightgray')\n",
    "plt.xlabel('Time (s)', fontsize = 12)\n",
    "plt.ylabel('Normalized amplitude', fontsize = 12)\n",
    "plt.xlim(0,770)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.text(x = 5, y = -1.25, s = 'N', fontsize = 20)\n",
    "plt.text(x = 261, y = -1.25, s = 'E', fontsize = 20)\n",
    "plt.text(x = 518, y = -1.25, s = 'Z', fontsize = 20)\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig(base_figure_save_dir + '2_plot_noise_data.png', format = 'PNG')\n",
    "# plt.close()\n",
    "\n",
    "# Check the PGD distribution\n",
    "\n",
    "# testing_data = fq_data[test_fqinds]\n",
    "\n",
    "# pgd = np.zeros(testing_data.shape[0]) # Reminder - FQ data is in meters\n",
    "# for idx in range(testing_data.shape[0]):\n",
    "#     pgd[idx] = np.max(np.sqrt((testing_data[idx,:257])**2 + (testing_data[idx,257:514])**2 + (testing_data[idx,514:])**2))\n",
    "\n",
    "# plt.figure(figsize = (8,5))\n",
    "# plt.hist(pgd, bins = 30, alpha = 0.5, edgecolor = 'black')\n",
    "# plt.ylim(0,10000)\n",
    "# plt.show()\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c113ec",
   "metadata": {},
   "source": [
    "## Test of Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b594ed8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkgen = X_gnss_unet_datagen_fn22.my_3comp_data_generator(32, fq_data, noise_data, fq_metadata, nan_array, train_fqinds, train_noiseinds, sr, std, valid = True) # Valid = True to get original data back\n",
    "checkgen_orig_data, checkgen_norm_data, checkgen_target, checkgen_metadata = next(checkgen) \n",
    "\n",
    "print('Data generator check original data shape: ' + str(checkgen_orig_data.shape))\n",
    "print('Data generator check normalized data shape: ' + str(checkgen_norm_data.shape))\n",
    "print('Data generator check target shape: ' + str(checkgen_target.shape))\n",
    "print('Data generator check metadata shape: ' + str(checkgen_metadata.shape))\n",
    "\n",
    "# Shapes:\n",
    "    # data: (batch_size, 128, 3) # N, E, Z\n",
    "    # target: (batch_size, 128)\n",
    "    # metadata: (batch_size, 3) Rupt name, station name, magnitude\n",
    "\n",
    "# Plot generator results\n",
    "\n",
    "nexamples = 10 # Number of examples to look at \n",
    "  \n",
    "for ind in range(nexamples): \n",
    "    \n",
    "#     print('Magnitude: ' + str(metadata[ind,2]))\n",
    "\n",
    "    fig = plt.subplots(nrows = 1, ncols = 3, figsize = (26,4), dpi = 300) # shoter for AGU talk\n",
    "    plt.subplots_adjust(wspace = 0.4)\n",
    "    t = 1/sr * np.arange(checkgen_orig_data.shape[1])\n",
    "    \n",
    "    ax1 = plt.subplot(131)\n",
    "    ax1.plot(t, checkgen_orig_data[ind,:,0]*100, label = 'N original data', color = 'C0')\n",
    "    ax1.plot(t, checkgen_norm_data[ind,:,0]*100, label = 'N normalized data', color = 'C0', linestyle = '--')\n",
    "    ax1.set_ylabel('Displacement (cm)')\n",
    "    ax1.set_xlabel('Time (s)')\n",
    "    ax1.legend(loc = 'upper right')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(t, checkgen_target[ind,:], color = 'black', linestyle = '--', label = 'Target')\n",
    "    ax2.set_ylabel('Confidence')\n",
    "    ax2.legend(loc = 'lower right')\n",
    "    \n",
    "    ax3 = plt.subplot(132)\n",
    "    ax3.plot(t, checkgen_orig_data[ind,:,1]*100, label = 'E original data', color = 'C1')\n",
    "    ax3.plot(t, checkgen_norm_data[ind,:,1]*100, label = 'E normalized data', color = 'C1', linestyle = '--')\n",
    "    ax3.set_ylabel('Displacement (cm)')\n",
    "    ax3.legend(loc = 'upper right')\n",
    "    ax4 = ax3.twinx()\n",
    "    ax4.plot(t, checkgen_target[ind,:], color = 'black', linestyle = '--', label = 'Target')\n",
    "    ax4.legend(loc = 'lower right')\n",
    "    \n",
    "    ax5 = plt.subplot(133)\n",
    "    ax5.plot(t, checkgen_orig_data[ind,:,2]*100, label = 'Z original data', color = 'C2')\n",
    "    ax5.plot(t, checkgen_norm_data[ind,:,2]*100, label = 'Z normalized data', color = 'C2', linestyle = '--')\n",
    "    ax5.set_ylabel('Displacement (cm)')\n",
    "    ax5.legend(loc = 'upper right')\n",
    "    ax6 = ax5.twinx()\n",
    "    ax6.plot(t, checkgen_target[ind,:], color = 'black', linestyle = '--', label = 'Target')\n",
    "    ax6.legend(loc = 'lower right')\n",
    "    \n",
    "    plt.show()\n",
    "#     plt.savefig(base_figure_save_dir + '3_ex' + str(ind) + '_plot_generator_pass.png', format = 'PNG')\n",
    "#     plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6b12f7",
   "metadata": {},
   "source": [
    "## Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b91607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if drop: # Use a model with a dropout layer\n",
    "    model = X_gnss_unet_datagen_fn22.make_large_unet_drop(fac, sr, ncomps = 3)\n",
    "    print('Using model with dropout')\n",
    "else:\n",
    "    model = X_gnss_unet_datagen_fn22.make_large_unet(fac, sr, ncomps = 3)  \n",
    "    print('Using large model')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aff619",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552a6c69",
   "metadata": {},
   "source": [
    "### See how training works with a smaller dataset (faster)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffea016",
   "metadata": {},
   "outputs": [],
   "source": [
    "if small_train:\n",
    "    train_fqinds = train_fqinds[:10000]\n",
    "    train_noiseinds = train_noiseinds[:10000]\n",
    "    valid_fqinds = valid_fqinds[:10000]\n",
    "    valid_noiseinds = valid_noiseinds[:10000]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0915f6a0",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33537b5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if train:\n",
    "    \n",
    "    traindate = date.today()\n",
    "    \n",
    "    model_save_dir = models_path + 'traindate_' + str(traindate) + '/' # Where to save the trained model\n",
    "    data_save_dir = model_save_dir + 'data/' # Where to save the outputted testing data and predictions\n",
    "    figure_save_dir = model_save_dir + 'figures/' # Where to save the figures\n",
    "    \n",
    "    if os.path.isdir(model_save_dir):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(model_save_dir)\n",
    "        os.makedirs(data_save_dir)\n",
    "        os.makedirs(figure_save_dir)\n",
    "    \n",
    "    model_save_file = model_save_dir + 'bestmodel_traindate_' + str(traindate) + '.h5'\n",
    "    \n",
    "    print('Training model and saving results to ' + model_save_file)\n",
    "    \n",
    "    lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(factor = np.sqrt(0.1), cooldown = 0, patience = 4, min_lr = 0.5e-6)\n",
    "    early_stopping_monitor = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 10)\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath = model_save_file, monitor = 'val_loss', mode = 'auto', verbose = 1, save_best_only = True)\n",
    "    callbacks = [lr_reducer, early_stopping_monitor, checkpoint]\n",
    "    \n",
    "    # Is it training from the normalized data or the original data? \n",
    "    # Answer - normalized. That's what's in the yield statement in the .py\n",
    "    \n",
    "    history = model.fit(X_gnss_unet_datagen_fn22.my_3comp_data_generator(batch_size, fq_data, noise_data, fq_metadata, nan_array, train_fqinds, train_noiseinds, sr, std), # Valid = False for training; implied\n",
    "                        steps_per_epoch = (len(train_fqinds) + len(train_noiseinds))//batch_size,\n",
    "                        validation_data = X_gnss_unet_datagen_fn22.my_3comp_data_generator(batch_size, fq_data, noise_data, fq_metadata, nan_array, valid_fqinds, valid_noiseinds, sr, std),\n",
    "                        validation_steps = (len(valid_fqinds) + len(valid_noiseinds))//batch_size,\n",
    "                        epochs = epochs, callbacks = callbacks)\n",
    "    \n",
    "    model.save_weights(model_save_file)\n",
    "    np.save(model_save_dir + 'training_history.npy', history.history)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e1ea2d",
   "metadata": {},
   "source": [
    "### Check Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd64ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    \n",
    "    history = np.load(model_save_dir + 'training_history.npy', allow_pickle = 'TRUE').item()\n",
    "\n",
    "    fig = plt.subplots(nrows = 2, ncols = 1, figsize = (6,8))\n",
    "\n",
    "    ax1 = plt.subplot(211)\n",
    "    ax1.plot(history['loss'], label = 'Training loss')\n",
    "    ax1.plot(history['val_loss'], label = 'Validation loss') \n",
    "    ax1.legend(loc = 'upper right')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Model: traindate_' + str(traindate) + '.h5')\n",
    "\n",
    "    ax2 = plt.subplot(212)\n",
    "    ax2.plot(history['accuracy'], label = 'Training accuracy') \n",
    "    ax2.plot(history['val_accuracy'], label = 'Validation accuracy') \n",
    "    ax2.legend(loc = 'lower right')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "\n",
    "    plt.subplots_adjust(hspace = 0)\n",
    "\n",
    "#     plt.show()\n",
    "    plt.savefig(figure_save_dir + '4_training_curves.png', format = 'PNG')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d756c8d",
   "metadata": {},
   "source": [
    "## Load an old trained model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2358f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load:\n",
    "    loaddate = '2024-10-01' # Format: YYYY-MM-DD\n",
    "    model_load_file = project_save_dir + 'models/traindate_' + str(loaddate) + '/bestmodel_traindate_' + str(loaddate) + '.h5'\n",
    "    data_save_dir = models_path + 'traindate_' + str(loaddate) + '/data/' # Where to save the outputted testing data and predictions\n",
    "    figure_save_dir = models_path + 'traindate_' + str(loaddate) + '/figures/'\n",
    "    print('Loading training results from ' + model_load_file)\n",
    "    \n",
    "    model.load_weights(model_load_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e6eadb",
   "metadata": {},
   "source": [
    "## Test the Model with Remaining FakeQuakes Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642828f8",
   "metadata": {},
   "source": [
    "### See how testing works with a smaller dataset (faster)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ca4a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if small_test:\n",
    "    test_fqinds = test_fqinds[:100]\n",
    "    test_noiseinds = test_noiseinds[:100]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a838dd",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731f4e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "fqtestdate = date.today()\n",
    "num_fqtest = len(test_fqinds) - 3 # Number of samples to test with\n",
    "# print(num_fqtest)\n",
    "\n",
    "fqtestmodel = X_gnss_unet_datagen_fn22.my_3comp_data_generator(num_fqtest, fq_data, noise_data, fq_metadata, nan_array, test_fqinds, test_noiseinds, sr, std, valid = True)\n",
    "fqtest_orig_data, fqtest_norm_data, fqtest_target, fqtest_metadata = next(fqtestmodel)\n",
    "print('Predicting...')\n",
    "fqtest_predictions = model.predict(fqtest_norm_data)\n",
    "\n",
    "print('FQ test original data shape: ' + str(fqtest_orig_data.shape))\n",
    "print('FQ test normalized data shape: ' + str(fqtest_norm_data.shape))\n",
    "print('FQ test metadata shape: ' + str(fqtest_metadata.shape))\n",
    "print('FQ test target shape: ' + str(fqtest_target.shape))\n",
    "print('FQ test predictions shape: ' + str(fqtest_predictions.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f45e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing with validation data\n",
    "\n",
    "# fqtestdate = date.today()\n",
    "# num_fqtest = len(valid_fqinds) - 2 # Number of samples to test with\n",
    "# # print(num_fqtest)\n",
    "\n",
    "# fqtestmodel = X_gnss_unet_datagen_fn9.my_3comp_data_generator(num_fqtest, fq_data, noise_data, fq_metadata, nan_array, valid_fqinds, valid_noiseinds, sr, std, valid = True)\n",
    "# fqtest_data, fqtest_target, fqtest_metadata = next(fqtestmodel)\n",
    "# print('Predicting...')\n",
    "# fqtest_predictions = model.predict(fqtest_data)\n",
    "\n",
    "# print('FQ test data shape: ' + str(fqtest_data.shape))\n",
    "# print('FQ test metadata shape: ' + str(fqtest_metadata.shape))\n",
    "# print('FQ test target shape: ' + str(fqtest_target.shape))\n",
    "# print('FQ test predictions shape: ' + str(fqtest_predictions.shape))\n",
    "\n",
    "# np.save(data_save_dir + str(fqtestdate) + '_fqvalid_data.npy', fqtest_data)\n",
    "# np.save(data_save_dir + str(fqtestdate) + '_fqvalid_metadata.npy', fqtest_metadata)\n",
    "# np.save(data_save_dir + str(fqtestdate) + '_fqvalid_target.npy', fqtest_target)\n",
    "# np.save(data_save_dir + str(fqtestdate) + '_fqvalid_predictions.npy', fqtest_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fc4ad6",
   "metadata": {},
   "source": [
    "### Save the FQ testing data, targets, metadata, and predictions as .npys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46376868",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(data_save_dir + str(fqtestdate) + '_fqtest_orig_data.npy', fqtest_orig_data)\n",
    "np.save(data_save_dir + str(fqtestdate) + '_fqtest_norm_data.npy', fqtest_norm_data)\n",
    "np.save(data_save_dir + str(fqtestdate) + '_fqtest_metadata.npy', fqtest_metadata)\n",
    "np.save(data_save_dir + str(fqtestdate) + '_fqtest_target.npy', fqtest_target)\n",
    "np.save(data_save_dir + str(fqtestdate) + '_fqtest_predictions.npy', fqtest_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceba3e5",
   "metadata": {},
   "source": [
    "### Check PGD distribution of FQ testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f96efa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fqtest_pgd = np.zeros(fqtest_orig_data.shape[0])\n",
    "for idx in range(fqtest_orig_data.shape[0]):\n",
    "    fqtest_pgd[idx] = np.max(np.sqrt((fqtest_orig_data[idx,:,0])**2 + (fqtest_orig_data[idx,:,1])**2 + (fqtest_orig_data[idx,:,2])**2))\n",
    "\n",
    "plt.figure(figsize = (8,5), dpi = 300)\n",
    "plt.hist(np.log10(fqtest_pgd), bins = 30, alpha = 0.5, edgecolor = 'black')\n",
    "# plt.ylim(0,4000)\n",
    "\n",
    "# plt.show()\n",
    "plt.savefig(figure_save_dir + '5a_fqtestdata_pgd_distrib.png', format = 'PNG')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff594f2",
   "metadata": {},
   "source": [
    "### Plot checks of FQ testing data and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e81e955",
   "metadata": {},
   "outputs": [],
   "source": [
    "nexamples = 5 # Number of examples to look at \n",
    "  \n",
    "for ind in range(nexamples): \n",
    "    \n",
    "    fig = plt.subplots(nrows = 1, ncols = 3, figsize = (18,4), dpi = 300)\n",
    "    plt.subplots_adjust(wspace = 0.4)\n",
    "    t = 1/sr * np.arange(fqtest_orig_data.shape[1])\n",
    "    # print(t)\n",
    "    \n",
    "    ax1 = plt.subplot(131)\n",
    "    ax1.plot(t, fqtest_norm_data[ind,:,0], label = 'N test data', color = 'C0')\n",
    "    ax1.set_ylabel('Displacement (m)')\n",
    "    ax1.set_xlabel('Time (s)')\n",
    "    ax1.legend(loc = 'upper right')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(t, fqtest_target[ind,:], color = 'black', linestyle = '--', label = 'Target')\n",
    "    ax2.plot(t, fqtest_predictions[ind,:], color = 'red', linestyle = '--', label = 'Prediction')\n",
    "    ax2.set_ylabel('Confidence')\n",
    "    ax2.set_ylim(-0.05,1.05)\n",
    "    ax2.legend(loc = 'upper left')\n",
    "    \n",
    "    ax3 = plt.subplot(132)\n",
    "    ax3.plot(t, fqtest_norm_data[ind,:,1], label = 'E test data', color = 'C1')\n",
    "    ax3.set_ylabel('Displacement (m)')\n",
    "    ax3.legend(loc = 'upper right')\n",
    "    ax4 = ax3.twinx()\n",
    "    ax4.plot(t, fqtest_target[ind,:], color = 'black', linestyle = '--', label = 'Target')\n",
    "    ax4.plot(t, fqtest_predictions[ind,:], color = 'red', linestyle = '--', label = 'Prediction')\n",
    "    ax4.set_ylim(-0.05,1.05)\n",
    "    ax4.legend(loc = 'upper left')\n",
    "    \n",
    "    ax5 = plt.subplot(133)\n",
    "    ax5.plot(t, fqtest_norm_data[ind,:,2], label = 'Z test data', color = 'C2')\n",
    "    ax5.set_ylabel('Displacement (m)')\n",
    "    ax5.legend(loc = 'upper right')\n",
    "    ax6 = ax5.twinx()\n",
    "    ax6.plot(t, fqtest_target[ind,:], color = 'black', linestyle = '--', label = 'Target')\n",
    "    ax6.plot(t, fqtest_predictions[ind,:], color = 'red', linestyle = '--', label = 'Prediction')\n",
    "    ax6.set_ylim(-0.05,1.05)\n",
    "    ax6.legend(loc = 'upper left')\n",
    "    \n",
    "#     plt.show()\n",
    "    plt.savefig(figure_save_dir + '6_fqtestdata_ex' + str(ind) + '_plot_test_predictions.png', format = 'PNG')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4337289e",
   "metadata": {},
   "source": [
    "## Test the Model with Real Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778674e4",
   "metadata": {},
   "source": [
    "### Run Real Data through Data Generator and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c0dabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "realtestdate = date.today()\n",
    "\n",
    "if small_test:\n",
    "    realtest_data = real_data[:100]\n",
    "    realtest_metadata = real_metadata[:100]\n",
    "    num_realtest = len(realtest_data)\n",
    "    realtestmodel = X_gnss_unet_datagen_fn22.real_data_generator(batch_size = num_realtest, data = realtest_data, meta_data = realtest_metadata, sr = 1, std = 3, nlen = 128)\n",
    "    realtest_orig_data, realtest_norm_data, realtest_target = next(realtestmodel)\n",
    "    \n",
    "else:\n",
    "    num_realtest = len(real_data) # Number of samples to test with\n",
    "    realtestmodel = X_gnss_unet_datagen_fn22.real_data_generator(batch_size = num_realtest, data = real_data, meta_data = real_metadata, sr = 1, std = 3, nlen = 128)\n",
    "    realtest_orig_data, realtest_norm_data, realtest_target = next(realtestmodel)\n",
    "    realtest_metadata = real_metadata\n",
    "\n",
    "print('Predicting...')\n",
    "realtest_predictions = model.predict(realtest_norm_data)\n",
    "\n",
    "print('Real test original data shape: ' + str(realtest_orig_data.shape))\n",
    "print('Real test normalize data shape: ' + str(realtest_norm_data.shape))\n",
    "print('Real test metadata shape: ' + str(realtest_metadata.shape))\n",
    "print('Real test target shape: ' + str(realtest_target.shape))\n",
    "print('Real test predictions shape: ' + str(realtest_predictions.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffcb465",
   "metadata": {},
   "source": [
    "### Save the real testing data, targets, metadata, and predictions as .npys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9801cc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(data_save_dir + str(realtestdate) + '_realtest_orig_data.npy', realtest_orig_data)\n",
    "np.save(data_save_dir + str(realtestdate) + '_realtest_norm_data.npy', realtest_norm_data)\n",
    "np.save(data_save_dir + str(realtestdate) + '_realtest_metadata.npy', realtest_metadata)\n",
    "np.save(data_save_dir + str(realtestdate) + '_realtest_target.npy', realtest_target)\n",
    "np.save(data_save_dir + str(realtestdate) + '_realtest_predictions.npy', realtest_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177c3535",
   "metadata": {},
   "source": [
    "### Check PGD distribution of real testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a023eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "realtest_pgd = np.zeros(realtest_orig_data.shape[0])\n",
    "for idx in range(realtest_orig_data.shape[0]):\n",
    "    realtest_pgd[idx] = np.max(np.sqrt((realtest_orig_data[idx,:,0])**2 + (realtest_orig_data[idx,:,1])**2 + (realtest_orig_data[idx,:,2])**2))\n",
    "\n",
    "max(realtest_pgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99271bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,5), dpi = 300)\n",
    "plt.hist(np.log10(realtest_pgd), bins = 30, alpha = 0.5, edgecolor = 'black')\n",
    "plt.xlabel('Log PGD (m)')\n",
    "plt.ylabel('Count')\n",
    "# plt.ylim(0,1000)\n",
    "\n",
    "# plt.show();\n",
    "plt.savefig(figure_save_dir + '15_realtestdata_pgd_distrib.png', format = 'PNG')\n",
    "plt.close();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a222cbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_w_eqs = np.load(realdata_dir + 'real_metadata_rembad_rows_w_eqs.npy')\n",
    "print(rows_w_eqs)\n",
    "\n",
    "print(realtest_metadata[rows_w_eqs][:,6])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846b287c",
   "metadata": {},
   "source": [
    "### Plot checks of real testing data and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a083b67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nexamples = 5 # Number of examples to look at \n",
    "  \n",
    "# for ind in range(nexamples):\n",
    "# for ind in rows_w_eqs[:5]:\n",
    "counter = 0\n",
    "for ind in rows_w_eqs: # To save all earthquake examples\n",
    "#     print(ind)\n",
    "    counter += 1\n",
    "    print('Real earthquake ' + str(counter) + '/' + str(len(rows_w_eqs)))\n",
    "    \n",
    "    fig = plt.subplots(nrows = 1, ncols = 3, figsize = (18,4), dpi = 300)\n",
    "    plt.subplots_adjust(wspace = 0.4)\n",
    "    t = 1/sr * np.arange(realtest_orig_data.shape[1])\n",
    "    # print(t)\n",
    "    \n",
    "    ax1 = plt.subplot(131)\n",
    "    ax1.plot(t, realtest_norm_data[ind,:,0]*100, label = 'N test data', color = 'C0')\n",
    "    ax1.set_ylabel('Displacement (cm)')\n",
    "    ax1.set_xlabel('Time (s)')\n",
    "    ax1.legend(loc = 'upper right')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(t, realtest_target[ind,:], color = 'black', linestyle = '--', label = 'Target')\n",
    "    ax2.plot(t, realtest_predictions[ind,:], color = 'red', linestyle = '--', label = 'Prediction')\n",
    "    ax2.set_ylabel('Confidence')\n",
    "    ax2.set_ylim(-0.05,1.05)\n",
    "    ax2.legend(loc = 'upper left')\n",
    "    \n",
    "    ax3 = plt.subplot(132)\n",
    "    ax3.set_title('Row with earthquake ' + str(ind), fontsize = 16)\n",
    "    ax3.plot(t, realtest_norm_data[ind,:,1]*100, label = 'E test data', color = 'C1')\n",
    "    ax3.set_ylabel('Displacement (cm)')\n",
    "    ax3.legend(loc = 'upper right')\n",
    "    ax4 = ax3.twinx()\n",
    "    ax4.plot(t, realtest_target[ind,:], color = 'black', linestyle = '--', label = 'Target')\n",
    "    ax4.plot(t, realtest_predictions[ind,:], color = 'red', linestyle = '--', label = 'Prediction')\n",
    "    ax4.set_ylim(-0.05,1.05)\n",
    "    ax4.legend(loc = 'upper left')\n",
    "    \n",
    "    ax5 = plt.subplot(133)\n",
    "    ax5.plot(t, realtest_norm_data[ind,:,2]*100, label = 'Z test data', color = 'C2')\n",
    "    ax5.set_ylabel('Displacement (cm)')\n",
    "    ax5.legend(loc = 'upper right')\n",
    "    ax6 = ax5.twinx()\n",
    "    ax6.plot(t, realtest_target[ind,:], color = 'black', linestyle = '--', label = 'Target')\n",
    "    ax6.plot(t, realtest_predictions[ind,:], color = 'red', linestyle = '--', label = 'Prediction')\n",
    "    ax6.set_ylim(-0.05,1.05)\n",
    "    ax6.legend(loc = 'upper left')\n",
    "    \n",
    "#     plt.show()\n",
    "#     plt.savefig(figure_save_dir + '16_realtestdata_ex' + str(ind) + '_plot_predictions.png', format = 'PNG')\n",
    "    plt.savefig(figure_save_dir + 'realtestdata_alltrueeq_wfvplots/row_' + str(ind) + '_plot_predictions.png', format = 'PNG')\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed5fa93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nexamples = 5 # Number of examples to look at \n",
    "  \n",
    "# for ind in range(nexamples):\n",
    "# for ind in rows_w_eqs[:5]:\n",
    "\n",
    "for ind in rows_w_eqs: # To save all earthquake examples\n",
    "#     print(ind)\n",
    "    \n",
    "#     if max(realtest_predictions[ind,:]) > 0.7:\n",
    "    if max(realtest_predictions[ind,:]) > 0.1:\n",
    "        \n",
    "        print(ind)\n",
    "        n_data = realtest_orig_data[ind,:,0]\n",
    "        e_data = realtest_orig_data[ind,:,1]\n",
    "        z_data = realtest_orig_data[ind,:,2]\n",
    "        pgd = np.max(np.sqrt((n_data)**2+(e_data)**2+(z_data)**2))\n",
    "    \n",
    "        fig = plt.subplots(nrows = 1, ncols = 3, figsize = (18,4), dpi = 300)\n",
    "        plt.subplots_adjust(wspace = 0.4)\n",
    "        t = 1/sr * np.arange(realtest_orig_data.shape[1])\n",
    "        # print(t)\n",
    "\n",
    "        ax1 = plt.subplot(131)\n",
    "        ax1.plot(t, realtest_orig_data[ind,:,0], label = 'N test data', color = 'C0')\n",
    "        ax1.set_ylabel('Displacement (m)')\n",
    "        ax1.set_xlabel('Time (s)')\n",
    "        ax1.legend(loc = 'upper right')\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.plot(t, realtest_target[ind,:], color = 'black', linestyle = '--', label = 'Target')\n",
    "        ax2.plot(t, realtest_predictions[ind,:], color = 'red', linestyle = '--', label = 'Prediction')\n",
    "        ax2.set_ylabel('Confidence')\n",
    "        ax2.set_ylim(-0.05,1.05)\n",
    "        ax2.legend(loc = 'upper left')\n",
    "\n",
    "        ax3 = plt.subplot(132)\n",
    "        ax3.set_title('Row with earthquake ' + str(ind) + ': station ' + str(realtest_metadata[ind,0]) + ', magnitude ' + str(realtest_metadata[ind,6]) + ', PGD ' + str(np.round(pgd,3)) + ' m', fontsize = 16)\n",
    "        ax3.plot(t, realtest_orig_data[ind,:,1], label = 'E test data', color = 'C1')\n",
    "        ax3.set_ylabel('Displacement (m)')\n",
    "        ax3.legend(loc = 'upper right')\n",
    "        ax4 = ax3.twinx()\n",
    "        ax4.plot(t, realtest_target[ind,:], color = 'black', linestyle = '--', label = 'Target')\n",
    "        ax4.plot(t, realtest_predictions[ind,:], color = 'red', linestyle = '--', label = 'Prediction')\n",
    "        ax4.set_ylim(-0.05,1.05)\n",
    "        ax4.legend(loc = 'upper left')\n",
    "\n",
    "        ax5 = plt.subplot(133)\n",
    "        ax5.plot(t, realtest_orig_data[ind,:,2], label = 'Z test data', color = 'C2')\n",
    "        ax5.set_ylabel('Displacement (m)')\n",
    "        ax5.legend(loc = 'upper right')\n",
    "        ax6 = ax5.twinx()\n",
    "        ax6.plot(t, realtest_target[ind,:], color = 'black', linestyle = '--', label = 'Target')\n",
    "        ax6.plot(t, realtest_predictions[ind,:], color = 'red', linestyle = '--', label = 'Prediction')\n",
    "        ax6.set_ylim(-0.05,1.05)\n",
    "        ax6.legend(loc = 'upper left')\n",
    "\n",
    "#         plt.show()\n",
    "    #     plt.savefig(figure_save_dir + '16_realtestdata_ex' + str(ind) + '_plot_predictions.png', format = 'PNG')\n",
    "#         plt.savefig(figure_save_dir + 'realtestdata_alltrueeq_wfvplots/conf_over_70/row_' + str(ind) + '_plot_predictions.png', format = 'PNG')\n",
    "        plt.savefig(figure_save_dir + 'realtestdata_alltrueeq_wfvplots/conf_over_10/row_' + str(ind) + '_plot_predictions.png', format = 'PNG')\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266a51bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking confidence distribution of predictions on the earthquake samples\n",
    "\n",
    "peaks = []\n",
    "peaks_above_01 = []\n",
    "\n",
    "for ind in rows_w_eqs:\n",
    "    peak = max(realtest_predictions[ind,:])\n",
    "    peaks.append(peak)\n",
    "    if peak >= 0.1:\n",
    "        peaks_above_01.append(peak)\n",
    "    \n",
    "print(len(peaks))\n",
    "print(len(peaks_above_01))\n",
    "\n",
    "plt.hist(peaks, bins = 50)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(peaks_above_01, bins = 50)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1555dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
