{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7158b1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import h5py\n",
    "from scipy import signal\n",
    "import gnss_unet_tools\n",
    "import argparse\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('white')\n",
    "\n",
    "##### VERSION NAME for figure saving #####\n",
    "\n",
    "name = 'shuffle_trainfull'\n",
    "\n",
    "train = 0 # Do you want to train? 0 = no, 1 = yes\n",
    "drop = 1 # Drop?\n",
    "resume = 0 # Resume training\n",
    "large = 0.5 # Large unet\n",
    "epos = 100 # How many epochs?\n",
    "std = 3 # How long do you want the Gaussian STD to be?\n",
    "sr = 1 # Sample rate (Hz)\n",
    "\n",
    "epsilon = 1e-6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e9bdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### -------------------- LOAD THE DATA -------------------- #####\n",
    "\n",
    "print('LOADING DATA')\n",
    "\n",
    "# Signals of earthquakes\n",
    "x_data = h5py.File('nd3_data.hdf5', 'r')\n",
    "x_data = x_data['nd3_data'][:,:]\n",
    "# print(x_data.shape)\n",
    "\n",
    "# Noise data\n",
    "n_data = h5py.File('729k_noise.hdf5', 'r')\n",
    "n_data = n_data['729k_noise'][:,:]\n",
    "\n",
    "# Metadata with information about earthquakes in x_data\n",
    "meta_data = np.load('nd3_info.npy')\n",
    "# shuffle_meta = meta_data[:] # Initialize for shuffling later\n",
    "# print('Meta shape:')\n",
    "# print(meta_data.shape)\n",
    "\n",
    "# Array of NaNs to use to match added noise in concatenation later\n",
    "nan_array = np.empty((len(x_data), 3))\n",
    "nan_array[:] = np.NaN\n",
    "\n",
    "## Real data things\n",
    "\n",
    "real_data = h5py.File('realdata_data.hdf5', 'r')\n",
    "real_data = real_data['realdata_data'][:,:] # shape: (12240, 384)\n",
    "real_meta_data = np.load('real_metadata_w_gauss_pgd_snr.npy') # shape: (12240, 6). Station name, date, sample start time, end time, counter, and position for Gaussian peak if there should be one\n",
    "real_data_inds = np.arange(real_data.shape[0])\n",
    "\n",
    "## New big set real data things (normed)\n",
    "\n",
    "norm_real_data = h5py.File('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/More_RealData/norm_realdata.hdf5', 'r')\n",
    "norm_real_data = norm_real_data['norm_realdata'][:,:]\n",
    "norm_real_data_inds = np.arange(norm_real_data.shape[0])\n",
    "norm_real_meta_data = np.load('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/More_RealData/real_metadata_w_gauss_pgd_snr.npy')\n",
    "\n",
    "# model_save_file = 'gnssunet_3comp_logfeat_250000_pn_eps_' + str(epos) + '_sr_' + str(sr) + '_std_' + str(std) + '.tf' \n",
    "model_save_file = 'gnssunet_' + name + '.tf' \n",
    "        \n",
    "if large:\n",
    "    fac = large\n",
    "    model_save_file = 'large_' + str(fac) + '_' + model_save_file\n",
    "\n",
    "if drop:\n",
    "    model_save_file = 'drop_' + model_save_file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1afa5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### -------------------- MAKE TRAINING AND TESTING DATA -------------------- #####\n",
    "\n",
    "print('MAKE TRAINING AND TESTING DATA')\n",
    "\n",
    "np.random.seed(0)\n",
    "# print(np.random.seed(0))\n",
    "\n",
    "### Earthquake/signal data ###\n",
    "\n",
    "init_siginds = np.arange(x_data.shape[0]) # Signal indices\n",
    "siginds = np.random.shuffle(init_siginds) # Shuffles the indices\n",
    "sig_train_inds = siginds[:int(0.9*len(siginds))] # Training data separation: grabs the front 90% of the numbers\n",
    "\n",
    "print(init_siginds)\n",
    "print(siginds)\n",
    "print(siginds.shape)\n",
    "print(sig_train_inds)\n",
    "print(sig_train_inds.shape)\n",
    "\n",
    "### Noise data ###\n",
    "\n",
    "init_noiseinds = np.arange(n_data.shape[0]) # Noise indices\n",
    "noiseinds = np.random.shuffle(init_noiseinds) # Shuffles the indices\n",
    "noise_train_inds = noiseinds[:int(0.9*len(noiseinds))] # Training data separation as above\n",
    "\n",
    "## Testing # CHANGE TO VALIDATION\n",
    "sig_test_inds = siginds[int(0.9*len(siginds)):] # Grabs the back 10% (90% through the end)\n",
    "noise_test_inds = noiseinds[int(0.9*len(noiseinds)):]\n",
    "\n",
    "# Some plots to check what we've loaded\n",
    "    \n",
    "# Plot the data (no noise, just earthquakes)\n",
    "plt.figure(figsize = (8,5))   \n",
    "for ii in range(10): # plot 20 of them\n",
    "    plt.plot(x_data[ii,:]/np.max(np.abs(x_data[ii,:]))+ii) # normalized\n",
    "plt.title('Earthquake test')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Normalized amplitude')\n",
    "# plt.savefig(local_dir + 'plots/' + name + '/1_plot_raw_eq_data.png', format = 'PNG')\n",
    "plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/1_2_raw_data_noise/plot_raw_eq_data.png', format = 'PNG') # LAP\n",
    "# plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/1_2_raw_data_noise/plot_raw_eq_data.png', format = 'PNG') # VAL\n",
    "\n",
    "plt.close()\n",
    "\n",
    "# Plot noise to check\n",
    "plt.figure(figsize = (8,5))\n",
    "for ii in range(10):\n",
    "    plt.plot(n_data[ii,:]/np.max(np.abs(n_data[ii,:]))+ii) # normalized?\n",
    "plt.title('Noise test')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Normalized amplitude')\n",
    "# plt.savefig(local_dir + 'plots/' + name + '/2_plot_noise_data.png', format = 'PNG')\n",
    "plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/1_2_raw_data_noise/plot_noise_data.png', format = 'PNG')\n",
    "# plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/1_2_raw_data_noise/plot_noise_data.png', format = 'PNG')\n",
    "plt.close()\n",
    "\n",
    "### Check the random PGD distribution ###\n",
    "\n",
    "testing_data = x_data[sig_test_inds]\n",
    "print(len(testing_data))\n",
    "\n",
    "pgd=np.zeros(testing_data.shape[0])\n",
    "for ii in range(testing_data.shape[0]):\n",
    "    pgd[ii]=np.max(np.sqrt((testing_data[ii,:256])**2+(testing_data[ii,256:512])**2+(testing_data[ii,512:])**2))\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.hist(pgd,bins=np.arange(0,5,0.05), color=(162/256,210/256,255/256),alpha=0.5, edgecolor='black', linewidth=1.2)\n",
    "plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/1_2_raw_data_noise/test_pgd_distrib.png', format = 'PNG') # LAP\n",
    "# plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/1_2_raw_data_noise/test_pgd_distrib.png', format = 'PNG') # LAP\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2ffab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### -------------------- FIRST GENERATOR TEST: generate batch data -------------------- #####\n",
    "\n",
    "print('FIRST PASS WITH DATA GENERATOR')\n",
    "\n",
    "my_data = gnss_unet_tools.my_3comp_data_generator(32, x_data, n_data, meta_data, nan_array, sig_train_inds, noise_train_inds, sr, std, valid = True) # Valid = True to get original data back\n",
    "batch_out, target, origdata, metadata = next(my_data) # batch_out and origdata are the same with GNSS implementation\n",
    "# Shapes:\n",
    "    # batch_out: (batch_size, 128, 3) # N, E, Z\n",
    "    # target: (5000, 128)\n",
    "    # origdata: (5000, 128, 3) # N, E, Z\n",
    "    # metadata: (5000, 3) Rupt name, station name, magnitude\n",
    "\n",
    "# Plot generator results\n",
    "\n",
    "nexamples = 5 # Number of examples to look at \n",
    "  \n",
    "for ind in range(nexamples): \n",
    "    \n",
    "    # fig = plt.subplots(nrows = 1, ncols = 3, figsize = (18,4), dpi = 300)\n",
    "    fig = plt.subplots(nrows = 1, ncols = 3, figsize = (26,4), dpi = 300) # shoter for AGU talk\n",
    "    plt.subplots_adjust(wspace = 0.4)\n",
    "    t = 1/sr * np.arange(batch_out.shape[1])\n",
    "    \n",
    "    ax1 = plt.subplot(131)\n",
    "    ax1.plot(t, origdata[ind,:,0]*100, label = 'N original data', color = 'C0')\n",
    "    ax1.set_ylabel('Displacement (cm)')\n",
    "    ax1.set_xlabel('Time (s)')\n",
    "    ax1.legend(loc = 'upper right')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(t, target[ind,:], color = 'black', linestyle = '--', label = 'Target')\n",
    "    ax2.set_ylabel('Confidence')\n",
    "    ax2.legend(loc = 'lower right')\n",
    "    \n",
    "    ax3 = plt.subplot(132)\n",
    "    ax3.plot(t, origdata[ind,:,1]*100, label = 'E original data', color = 'C1')\n",
    "    ax3.set_ylabel('Displacement (cm)')\n",
    "    ax3.legend(loc = 'upper right')\n",
    "    ax4 = ax3.twinx()\n",
    "    ax4.plot(t, target[ind,:], color = 'black', linestyle = '--', label = 'Target')\n",
    "    ax4.legend(loc = 'lower right')\n",
    "    \n",
    "    ax5 = plt.subplot(133)\n",
    "    ax5.plot(t, origdata[ind,:,2]*100, label = 'Z original data', color = 'C2')\n",
    "    ax5.set_ylabel('Displacement (cm)')\n",
    "    ax5.legend(loc = 'upper right')\n",
    "    ax6 = ax5.twinx()\n",
    "    ax6.plot(t, target[ind,:], color = 'black', linestyle = '--', label = 'Target')\n",
    "    ax6.legend(loc = 'lower right')\n",
    "    \n",
    "    # plt.savefig(local_dir + 'plots/' + name + '/3_ex_' + str(ind) + '_plot_generator_pass.png', format = 'PNG')\n",
    "    plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/3_first_pass_gen/ex_' + str(ind) + '_plot_generator_pass.png', format = 'PNG')\n",
    "    # plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/3_first_pass_gen/ex_' + str(ind) + '_plot_generator_pass.png', format = 'PNG')\n",
    "    plt.close()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de9e3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### -------------------- BUILD THE MODEL -------------------- #####\n",
    "\n",
    "print('BUILD THE MODEL')\n",
    "\n",
    "if drop:\n",
    "    model = gnss_unet_tools.make_large_unet_drop(fac, sr, ncomps = 3)\n",
    "    print('Using drop model')    \n",
    "    \n",
    "else:\n",
    "    model = gnss_unet_tools.make_large_unet(fac, sr, ncomps = 3)  \n",
    "    print('Using large model')\n",
    "        \n",
    "# ##### -------------------- ADD SOME CHECKPOINTS -------------------- #####\n",
    "\n",
    "print('ADDING CHECKPOINTS')\n",
    "\n",
    "checkpoint_filepath = './checks/' + model_save_file + '_{epoch:04d}.ckpt'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpoint_filepath, save_weights_only = True, verbose = 1,\n",
    "    monitor = 'val_accuracy', mode = 'max', save_best_only = True) # rename val_loss to validation_loss, or val_acc to val_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deea7460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### -------------------- TRAIN THE MODEL -------------------- #####\n",
    "\n",
    "if train:\n",
    "    \n",
    "    print('TRAINING!!!')\n",
    "    \n",
    "    batch_size = 32 # Why 32?\n",
    "    \n",
    "    if resume:\n",
    "        print('Resuming training results from ' + model_save_file)\n",
    "        model.load_weights(checkpoint_filepath)\n",
    "        \n",
    "    else:\n",
    "        print('Training model and saving results to ' + model_save_file)\n",
    "        \n",
    "    csv_logger = tf.keras.callbacks.CSVLogger(model_save_file + '.csv', append = True)\n",
    "    \n",
    "    history = model.fit_generator(gnss_unet_tools.my_3comp_data_generator(batch_size, x_data, n_data, meta_data, nan_array, sig_train_inds, noise_train_inds, sr, std), # Valid = False for training; implied\n",
    "                        steps_per_epoch = (len(sig_train_inds) + len(noise_train_inds))//batch_size,\n",
    "                        validation_data = gnss_unet_tools.my_3comp_data_generator(batch_size, x_data, n_data, meta_data, nan_array, sig_test_inds, noise_test_inds, sr, std),\n",
    "                        validation_steps = (len(sig_test_inds) + len(noise_test_inds))//batch_size,\n",
    "                        epochs = epos, callbacks = [model_checkpoint_callback, csv_logger])\n",
    "    \n",
    "    model.save_weights('./' + model_save_file)\n",
    "    \n",
    "else:\n",
    "    print('LOADING TRAINING RESULTS from ' + model_save_file)\n",
    "    model.load_weights('./' + model_save_file)\n",
    "    \n",
    "# Plotting training curves\n",
    "\n",
    "print('RUNNING ANALYSES')\n",
    "\n",
    "training_stats = np.genfromtxt('./' + model_save_file + '.csv', delimiter = ',', skip_header = 1)\n",
    "\n",
    "fig = plt.subplots(nrows = 2, ncols = 1, figsize = (6,8))\n",
    "plt.suptitle('Training curves')\n",
    "\n",
    "ax1 = plt.subplot(211)\n",
    "ax1.plot(training_stats[1:100,0], training_stats[1:100,1], label = 'Accuracy')\n",
    "ax1.plot(training_stats[1:100,0], training_stats[1:100,3], label = 'Validation accuracy') \n",
    "ax1.legend(loc = 'lower right')\n",
    "ax1.set_title(model_save_file)\n",
    "\n",
    "ax2 = plt.subplot(212)\n",
    "ax2.plot(training_stats[1:100,0], training_stats[1:100,2], label = 'Loss') \n",
    "ax2.plot(training_stats[1:100,0], training_stats[1:100,4], label = 'Validation loss') \n",
    "ax2.legend(loc = 'upper right')\n",
    "ax2.set_xlabel('Epoch')\n",
    "\n",
    "# plt.savefig(local_dir + 'plots/' + name + '/4_training_curves.png', format = 'PNG')\n",
    "plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/4_training_curves/training_curves.png', format = 'PNG')\n",
    "# plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/4_training_curves/training_curves.png', format = 'PNG')\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af29b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### -------------------- TEST THE MODEL -------------------- #####\n",
    "\n",
    "print('TESTING!!!')\n",
    "\n",
    "# Number of samples to test with\n",
    "num_test = len(testing_data) - 1\n",
    "# print(num_test)\n",
    "\n",
    "# See how things went with the remaining 10%\n",
    "my_test_data = gnss_unet_tools.my_3comp_data_generator(num_test, x_data, n_data, meta_data, nan_array, sig_test_inds, noise_test_inds, sr, std, valid = True)\n",
    "batch_out, target, origdata, metadata = next(my_test_data)\n",
    "test_predictions = model.predict(batch_out)\n",
    "\n",
    "# print('test_predictions shape:')\n",
    "# print(test_predictions.shape)\n",
    "# print('target shape:')\n",
    "# print(target.shape)\n",
    "# print(target[1])\n",
    "# print(batch_out.shape)\n",
    "# print(origdata.shape)\n",
    "\n",
    "# Calculate PGDs and distribution\n",
    "\n",
    "pgd_1=np.zeros(origdata.shape[0])\n",
    "for ii in range(origdata.shape[0]):\n",
    "    pgd_1[ii]=np.max(np.sqrt((origdata[ii,:,0])**2+(origdata[ii,:,1])**2+(origdata[ii,:,2])**2))\n",
    "\n",
    "plt.figure(figsize=(8,5), dpi=300)\n",
    "plt.hist(pgd_1,bins=np.arange(0,5,0.05), color=(162/256,210/256,255/256),alpha=0.5, edgecolor='black', linewidth=1.2)\n",
    "plt.ylim(0,4000)\n",
    "plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/5_10per_testing/pgd_distrib.png', format = 'PNG') # LAP\n",
    "# plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/5_10per_testing/pgd_distrib.png', format = 'PNG') # LAP\n",
    "plt.close()\n",
    "\n",
    "np.save('origdata_fakequakes_testing.npy', origdata)\n",
    "np.save('target_fakequakes_testing.npy', target)\n",
    "\n",
    "# Plot some data and predictions!\n",
    "\n",
    "nexamples = 20 # Number of examples to look at \n",
    "  \n",
    "for ind in range(nexamples): \n",
    "    \n",
    "    fig = plt.subplots(nrows = 1, ncols = 3, figsize = (18,4), dpi = 300)\n",
    "    plt.subplots_adjust(wspace = 0.4)\n",
    "    t = 1/sr * np.arange(batch_out.shape[1])\n",
    "    # print(t)\n",
    "    \n",
    "    ax1 = plt.subplot(131)\n",
    "    ax1.plot(t, origdata[ind,:,0]*100, label = 'N original data', color = 'C0')\n",
    "    ax1.set_ylabel('Displacement (cm)')\n",
    "    ax1.set_xlabel('Time (s)')\n",
    "    ax1.legend(loc = 'upper right')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(t, target[ind,:], color = 'black', linestyle = '--', label = 'Target')\n",
    "    ax2.plot(t, test_predictions[ind,:], color = 'red', linestyle = '--', label = 'Prediction')\n",
    "    ax2.set_ylabel('Confidence')\n",
    "    ax2.set_ylim(-0.05,1.05)\n",
    "    ax2.legend(loc = 'upper left')\n",
    "    \n",
    "    ax3 = plt.subplot(132)\n",
    "    ax3.plot(t, origdata[ind,:,1]*100, label = 'E original data', color = 'C1')\n",
    "    ax3.set_ylabel('Displacement (cm)')\n",
    "    ax3.legend(loc = 'upper right')\n",
    "    ax4 = ax3.twinx()\n",
    "    ax4.plot(t, target[ind,:], color = 'black', linestyle = '--', label = 'Target')\n",
    "    ax4.plot(t, test_predictions[ind,:], color = 'red', linestyle = '--', label = 'Prediction')\n",
    "    ax4.set_ylim(-0.05,1.05)\n",
    "    ax4.legend(loc = 'upper left')\n",
    "    \n",
    "    ax5 = plt.subplot(133)\n",
    "    ax5.plot(t, origdata[ind,:,2]*100, label = 'Z original data', color = 'C2')\n",
    "    ax5.set_ylabel('Displacement (cm)')\n",
    "    ax5.legend(loc = 'upper right')\n",
    "    ax6 = ax5.twinx()\n",
    "    ax6.plot(t, target[ind,:], color = 'black', linestyle = '--', label = 'Target')\n",
    "    ax6.plot(t, test_predictions[ind,:], color = 'red', linestyle = '--', label = 'Prediction')\n",
    "    ax6.set_ylim(-0.05,1.05)\n",
    "    ax6.legend(loc = 'upper left')\n",
    "    \n",
    "    # plt.savefig(local_dir + 'plots/' + name + '/5_ex_' + str(ind) + '_plot_predictions.png', format = 'PNG')\n",
    "    plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/5_10per_testing/ex_' + str(ind) + '_plot_predictions.png', format = 'PNG')\n",
    "    # plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/5_10per_testing/ex_' + str(ind) + '_plot_predictions.png', format = 'PNG')\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053d421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### -------------------- REAL DATA TESTS -------------------- #####\n",
    "\n",
    "# print('TESTING WITH REAL DATA!!!')\n",
    "\n",
    "# # realtest = gnss_unet_tools.real_data_generator(data = real_data, data_inds = real_data_inds, meta_data = real_meta_data, sr = 1, std = 3, nlen = 128)\n",
    "# realtest = gnss_unet_tools.real_data_generator(data = norm_real_data, data_inds = norm_real_data_inds, meta_data = norm_real_meta_data, sr = 1, std = 3, nlen = 128)\n",
    "# stack_data, gauss_target = next(realtest)\n",
    "# # print(stack_data)\n",
    "# # print(stack_data.shape)\n",
    "# # print(gauss_target)\n",
    "# # print(gauss_target.shape)\n",
    "# realtest_predictions = model.predict(stack_data)\n",
    "\n",
    "# np.save('realtest_predictions.npy', realtest_predictions)\n",
    "# np.save('stack_data.npy', stack_data)\n",
    "# np.save('gauss_target.npy', gauss_target)\n",
    "\n",
    "# # Plot some data and predictions!\n",
    "\n",
    "# # rows_w_eqs = np.load('real_metadata_rowsweqs.npy')\n",
    "# rows_w_eqs = np.load('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/More_RealData/rowsweqs.npy') # More data, normed\n",
    "\n",
    "# nexamples = 5 # Number of examples to look at \n",
    "  \n",
    "# # for ind in range(nexamples): \n",
    "# for ind in rows_w_eqs[43]:\n",
    "    \n",
    "#     fig = plt.subplots(nrows = 1, ncols = 3, figsize = (22,4), dpi = 300)\n",
    "#     plt.subplots_adjust(wspace = 0.4)\n",
    "#     t = 1/sr * np.arange(batch_out.shape[1])\n",
    "    \n",
    "#     ax1 = plt.subplot(131)\n",
    "#     ax1.plot(t, stack_data[ind,:,0]*100, label = 'N original data', color = 'C0')\n",
    "#     ax1.set_ylabel('Displacement (cm)')\n",
    "#     ax1.set_xlabel('Time (s)')\n",
    "#     ax1.legend(loc = 'upper right')\n",
    "#     ax2 = ax1.twinx()\n",
    "#     ax2.plot(t, gauss_target[ind,:], color = 'black', linestyle = '--', label = 'Target')\n",
    "#     ax2.plot(t, realtest_predictions[ind,:], color = 'red', linestyle = '--', label = 'Prediction')\n",
    "#     ax2.set_ylabel('Confidence')\n",
    "#     ax2.set_ylim(-0.05,1.05)\n",
    "#     ax2.legend(loc = 'upper left')\n",
    "    \n",
    "#     ax3 = plt.subplot(132)\n",
    "#     ax3.plot(t, stack_data[ind,:,1]*100, label = 'E original data', color = 'C1')\n",
    "#     ax3.set_ylabel('Displacement (cm)')\n",
    "#     ax3.legend(loc = 'upper right')\n",
    "#     ax4 = ax3.twinx()\n",
    "#     ax4.plot(t, gauss_target[ind,:], color = 'black', linestyle = '--', label = 'Target')\n",
    "#     ax4.plot(t, realtest_predictions[ind,:], color = 'red', linestyle = '--', label = 'Prediction')\n",
    "#     ax4.set_ylim(-0.05,1.05)\n",
    "#     ax4.legend(loc = 'upper left')\n",
    "    \n",
    "#     ax5 = plt.subplot(133)\n",
    "#     ax5.plot(t, stack_data[ind,:,2]*100, label = 'Z original data', color = 'C2')\n",
    "#     ax5.set_ylabel('Displacement (cm)')\n",
    "#     ax5.legend(loc = 'upper right')\n",
    "#     ax6 = ax5.twinx()\n",
    "#     ax6.plot(t, gauss_target[ind,:], color = 'black', linestyle = '--', label = 'Target')\n",
    "#     ax6.plot(t, realtest_predictions[ind,:], color = 'red', linestyle = '--', label = 'Prediction')\n",
    "#     ax6.set_ylim(-0.05,1.05)\n",
    "#     ax6.legend(loc = 'upper left')\n",
    "    \n",
    "#     # plt.show()\n",
    "    \n",
    "#     # plt.savefig(local_dir + 'plots/' + name + '/5_ex_' + str(ind) + '_plot_predictions.png', format = 'PNG')\n",
    "#     plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/6_real_testing/ex_' + str(ind) + '_plot_predictions.png', format = 'PNG') # First small real test\n",
    "#     # plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/newtrain_march/more_realdata_norm_testing/ex_' + str(ind) + '_plot_preds.png', format = 'PNG') # Big real set, normed\n",
    "#     # plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/6_real_testing/ex_' + str(ind) + '_plot_predictions.png', format = 'PNG')\n",
    "#     plt.close()\n",
    "\n",
    "        \n",
    "##### -------------------- CLASSIFICATION TESTS -------------------- #####\n",
    "\n",
    "# print('DOING CLASSIFICATION TESTS ON FAKEQUAKES DATA')\n",
    "\n",
    "# # Decision threshold evaluation\n",
    "\n",
    "# thresholds = np.arange(0, 1.005, 0.005)\n",
    "# # thresholds = np.arange(0, 1, 0.1)\n",
    "# test_thresholds = [0]\n",
    "\n",
    "# # Use np.where to see whether anywhere in test_predictions is > threshold\n",
    "# # If there is a value that's >, the 'result' of the array is 1. If not 0\n",
    "# # Then compare these 1s and 0s to the target array value for PAR\n",
    "\n",
    "# accuracies = []\n",
    "# accuracies_per = []\n",
    "# precisions = []\n",
    "# recalls = []\n",
    "# F1s = []\n",
    "\n",
    "# for threshold in thresholds:\n",
    "    \n",
    "#     # print('-------------------------------------------------------------')\n",
    "#     # print('Threshold: ' + str(threshold))\n",
    "#     # print('-------------------------------------------------------------')\n",
    "#     # print(' ')\n",
    "    \n",
    "#     # Convert the predictions arrays to single ones and zeroes\n",
    "    \n",
    "#     pred_binary = np.zeros(len(test_predictions))\n",
    "#     iterate = np.arange(0,num_test,1)\n",
    "    \n",
    "#     for k in iterate:\n",
    "#         # print('Prediction: ' + str(test_predictions[k]))\n",
    "#         i = np.where(test_predictions[k] >= threshold)[0]\n",
    "#         # print(i)\n",
    "#         if len(i) == 0:\n",
    "#             pred_binary[k] = 0\n",
    "#         elif len(i) > 0:\n",
    "#             pred_binary[k] = 1\n",
    "    \n",
    "#     # print('Predictions: ')\n",
    "#     # print(pred_binary)\n",
    "#     # print(pred_binary.shape)\n",
    "    \n",
    "#     # Convert the target arrays to single ones and zeroes\n",
    "    \n",
    "#     targ_binary = np.zeros(len(target))\n",
    "#     iterate = np.arange(0,num_test,1)\n",
    "    \n",
    "#     for k in iterate:\n",
    "#         # print('Target: ' + str(test_predictions[k]))\n",
    "#         i = np.where(target[k] > 0)[0]\n",
    "#         if len(i) == 0:\n",
    "#             targ_binary[k] = 0\n",
    "#         elif len(i) > 0:\n",
    "#             targ_binary[k] = 1\n",
    "    \n",
    "#     # print('Targets: ')\n",
    "#     # print(targ_binary)\n",
    "    \n",
    "#     # Calculating the accuracy, precision, recall, and F1\n",
    "    \n",
    "#     num_preds = num_test # total number of predictions. Amanda did 50\n",
    "#     correct_preds = []\n",
    "#     wrong_preds = []\n",
    "#     true_pos = []\n",
    "#     true_neg = []\n",
    "#     false_pos = []\n",
    "#     false_neg = []\n",
    "    \n",
    "#     for i in iterate:\n",
    "        \n",
    "#         pred = pred_binary[i]\n",
    "#         targ = targ_binary[i]\n",
    "        \n",
    "#         if pred == targ: # add one to list of correct predictions if matching\n",
    "#             correct_preds.append(1)\n",
    "            \n",
    "#             if pred == 1 and targ == 1:\n",
    "#                 true_pos.append(1)\n",
    "#             elif pred == 0 and targ == 0:\n",
    "#                 true_neg.append(1)\n",
    "            \n",
    "#         elif pred != targ: # add ones to list of incorrect predictions if not matching\n",
    "#             wrong_preds.append(1)\n",
    "            \n",
    "#             if pred == 1 and targ == 0:\n",
    "#                 false_pos.append(1)\n",
    "#             elif pred == 0 and targ == 1:\n",
    "#                 false_neg.append(1)\n",
    "    \n",
    "#     num_correct_preds = len(correct_preds)\n",
    "#     num_wrong_preds = len(wrong_preds)\n",
    "#     num_true_pos = len(true_pos)\n",
    "#     num_true_neg = len(true_neg)\n",
    "#     num_false_pos = len(false_pos)\n",
    "#     num_false_neg = len(false_neg)\n",
    "    \n",
    "#     # print('Correct preds: ' + str(num_correct_preds))\n",
    "#     # print('Wrong preds: ' + str(num_wrong_preds))\n",
    "#     # print('True pos: ' + str(num_true_pos))\n",
    "#     # print('True neg: ' + str(num_true_neg))\n",
    "#     # print('False pos: ' + str(num_false_pos))\n",
    "#     # print('False neg: ' + str(num_false_neg))\n",
    "    \n",
    "#     # print('Threshold: ' + str(threshold))\n",
    "#     # print('Correct preds: ' + str(num_correct_preds))\n",
    "#     # print('Wrong preds: ' + str(num_wrong_preds))\n",
    "#     # print('True pos: ' + str(num_true_pos))\n",
    "#     # print('True neg: ' + str(num_true_neg))\n",
    "#     # print('False pos: ' + str(num_false_pos))\n",
    "#     # print('False neg: ' + str(num_false_neg))\n",
    "    \n",
    "#     accuracy = num_correct_preds / num_preds\n",
    "#     accuracy_per = (num_correct_preds / num_preds) * 100\n",
    "#     # print('Accuracy: ' + str(accuracy_per) + '%')\n",
    "    \n",
    "#     if num_true_pos == 0  and num_false_pos == 0:\n",
    "#         precision = 0\n",
    "#     else:\n",
    "#         precision = num_true_pos / (num_true_pos + num_false_pos)\n",
    "    \n",
    "#     if num_true_pos == 0 and num_false_neg == 0:\n",
    "#         recall = 0\n",
    "#     else:\n",
    "#         recall = num_true_pos / (num_true_pos + num_false_neg)\n",
    "    \n",
    "#     if precision + recall == 0:\n",
    "#         F1 = 0\n",
    "#     else:\n",
    "#         F1 = 2 * ((precision * recall) / (precision + recall))\n",
    "    \n",
    "#     accuracies.append(accuracy)\n",
    "#     accuracies_per.append(accuracy_per)\n",
    "#     precisions.append(precision)\n",
    "#     recalls.append(recall)\n",
    "#     F1s.append(F1)\n",
    "\n",
    "# # print('Accuracies')\n",
    "# # print(accuracies)\n",
    "# # print('Precisions')\n",
    "# # print(precisions)\n",
    "# # print('Recalls')\n",
    "# # print(recalls)\n",
    "# # print('F1s')\n",
    "# # print(F1s)\n",
    "\n",
    "# np.savetxt('accuracies_percentage_txt.txt', accuracies_per)\n",
    "# np.savetxt('thresholds_txt.txt', thresholds)\n",
    "\n",
    "# plt.figure(figsize = (8,5), dpi = 300)\n",
    "# # plt.scatter(thresholds,accuracies)\n",
    "# plt.plot(thresholds, accuracies_per, linewidth = 2)\n",
    "# plt.xlabel('Threshold', fontsize = 18)\n",
    "# plt.ylabel('Accuracy (%)', fontsize = 18)\n",
    "# plt.xlim(0,1)\n",
    "# plt.ylim(0,100)\n",
    "# plt.xticks(fontsize = 15)\n",
    "# plt.yticks(fontsize = 15)\n",
    "# plt.title('Accuracy Percentage', fontsize = 18)\n",
    "# # plt.savefig(local_dir + 'plots/' + name + '/6_accuracies_' + str(num_test) + '.png', format='PNG')\n",
    "# # plt.savefig('/Users/sydneydybing/Documents/AGU_2021/Figures/6_accuracies_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/7_classify_stats/accuracies_' + str(num_test) + '.png', format='PNG')\n",
    "# # plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/7_classify_stats/accuracies_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.close()\n",
    "\n",
    "# plt.figure(figsize = (8,5), dpi = 300)\n",
    "# plt.plot(thresholds, precisions, linewidth = 2)\n",
    "# plt.xlabel('Threshold', fontsize = 18)\n",
    "# plt.ylabel('Precision', fontsize = 18)\n",
    "# plt.xlim(0,1)\n",
    "# plt.ylim(0,1)\n",
    "# plt.xticks(fontsize = 15)\n",
    "# plt.yticks(fontsize = 15)\n",
    "# plt.title('Precision', fontsize = 18)\n",
    "# # plt.savefig(local_dir + 'plots/' + name + '/6_precisions_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/7_classify_stats/precisions_' + str(num_test) + '.png', format='PNG')\n",
    "# # plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/7_classify_stats/precisions_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.close()\n",
    "\n",
    "# plt.figure(figsize = (8,5), dpi = 300)\n",
    "# plt.plot(thresholds, recalls, linewidth = 2)\n",
    "# plt.xlabel('Threshold', fontsize = 18)\n",
    "# plt.ylabel('Recall', fontsize = 18)\n",
    "# plt.xlim(0,1)\n",
    "# plt.ylim(0,1)\n",
    "# plt.xticks(fontsize = 15)\n",
    "# plt.yticks(fontsize = 15)\n",
    "# plt.title('Recall', fontsize = 18)\n",
    "# # plt.savefig(local_dir + 'plots/' + name + '/6_recalls_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/7_classify_stats/recalls_' + str(num_test) + '.png', format='PNG')\n",
    "# # plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/7_classify_stats/recalls_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.close()\n",
    "\n",
    "# plt.figure(figsize = (8,5), dpi = 300)\n",
    "# plt.plot(thresholds, F1s, linewidth = 2)\n",
    "# plt.xlabel('Threshold', fontsize = 18)\n",
    "# plt.ylabel('F1', fontsize = 18)\n",
    "# plt.xlim(0,1)\n",
    "# plt.ylim(0,1)\n",
    "# plt.xticks(fontsize = 15)\n",
    "# plt.yticks(fontsize = 15)\n",
    "# plt.title('F1', fontsize = 18)\n",
    "# # plt.savefig(local_dir + 'plots/' + name + '/6_F1s_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/7_classify_stats/F1s_' + str(num_test) + '.png', format='PNG')\n",
    "# # plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/7_classify_stats/F1s_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.close()\n",
    "\n",
    "# ##### -------------------- GAUSSIAN PEAK POSITION TEST -------------------- #####\n",
    "\n",
    "# print('DOING PEAK POSITION TESTS')\n",
    "\n",
    "# # print(target[4])\n",
    "# # print(test_predictions[4])\n",
    "\n",
    "# thresholds = np.array([0.01,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.99])\n",
    "\n",
    "# # threshold = 0.2\n",
    "\n",
    "# iterate = np.arange(0,num_test,1)\n",
    "# s = 0\n",
    "\n",
    "# fig = plt.subplots(nrows = 3, ncols = 4, figsize = (18,14), dpi = 400)\n",
    "# # fig = plt.subplots(nrows = 3, ncols = 4, figsize = (18,14))\n",
    "# plt.suptitle('Target vs. Prediction Samples Off per Threshold', fontsize = 20)\n",
    "\n",
    "# for idx in range(len(thresholds)):\n",
    "    \n",
    "#     threshold = thresholds[idx]\n",
    "\n",
    "#     pred_binary = np.zeros(len(test_predictions))\n",
    "#     iterate = np.arange(0,num_test,1)\n",
    "    \n",
    "#     for k in iterate:\n",
    "#         i = np.where(test_predictions[k] >= threshold)[0]\n",
    "#         if len(i) == 0:\n",
    "#             pred_binary[k] = 0\n",
    "#         elif len(i) > 0:\n",
    "#             pred_binary[k] = 1\n",
    "    \n",
    "#     # print('Predictions: ')\n",
    "#     # print(pred_binary)\n",
    "    \n",
    "#     # Convert the target arrays to single ones and zeroes\n",
    "    \n",
    "#     targ_binary = np.zeros(len(target))\n",
    "#     iterate = np.arange(0,num_test,1)\n",
    "    \n",
    "#     for k in iterate:\n",
    "#         i = np.where(target[k] > 0)[0]\n",
    "#         if len(i) == 0:\n",
    "#             targ_binary[k] = 0\n",
    "#         elif len(i) > 0:\n",
    "#             targ_binary[k] = 1\n",
    "    \n",
    "#     # print('Targets: ')\n",
    "#     # print(targ_binary)\n",
    "    \n",
    "#     signals = []\n",
    "    \n",
    "#     for i in iterate:\n",
    "#         pred = pred_binary[i]\n",
    "#         targ = targ_binary[i]\n",
    "        \n",
    "#         # print(pred)\n",
    "#         # print(targ)\n",
    "        \n",
    "#         if pred == 1 and targ == 1: # True positive, there was a signal and it found it\n",
    "#             signals.append(i) # Grab index from list of events that are correct and have a pick\n",
    "#         else:\n",
    "#             pass\n",
    "    \n",
    "#     # print(signals)\n",
    "    \n",
    "#     samples_off_list = []\n",
    "    \n",
    "#     for index in signals:\n",
    "        \n",
    "#         # Find the peak and then the index where that peak is and compare \n",
    "        \n",
    "#         # print('----------------------')\n",
    "#         # print('Signal number: ' + str(index))\n",
    "        \n",
    "#         target_max_idx = np.argmax(target[index])\n",
    "#         # print('Target: ' + str(target_max_idx))\n",
    "        \n",
    "#         pred_max_idx = np.argmax(test_predictions[index])\n",
    "#         # print('Prediction: ' + str(pred_max_idx))\n",
    "        \n",
    "#         samples_off = np.abs(pred_max_idx - target_max_idx)\n",
    "#         # print('Samples off: ' + str(samples_off))\n",
    "#         samples_off_list.append(samples_off)\n",
    "        \n",
    "#     # print(samples_off_list)\n",
    "    \n",
    "#     plt.subplot(3,4,idx+1)\n",
    "#     plt.hist(samples_off_list, bins=128, range=(0,128), label = 'Threshold: ' + str(threshold))\n",
    "#     plt.xlim(0,128)\n",
    "#     plt.ylim(0,300)\n",
    "#     plt.legend()\n",
    "#     plt.grid(which = 'major', color = 'lightgray')\n",
    "#     plt.subplots_adjust(hspace = 0, wspace = 0)\n",
    "\n",
    "#     if idx == 0:\n",
    "#         plt.tick_params(axis = 'x', which = 'both', bottom = False, labelbottom = False)\n",
    "    \n",
    "#     elif idx == 4:\n",
    "#         plt.ylabel('Number of examples in bin')\n",
    "#         plt.tick_params(axis = 'x', which = 'both', bottom = False, labelbottom = False)\n",
    "#         plt.yticks([0, 50, 100, 150, 200, 250])\n",
    "        \n",
    "#     elif idx == 8:\n",
    "#         plt.yticks([0, 50, 100, 150, 200, 250])\n",
    "        \n",
    "#     elif idx == 9:\n",
    "#         plt.xlabel('Numbers of samples off target position')\n",
    "#         plt.tick_params(axis = 'y', which = 'both', left = False, labelleft = False)\n",
    "        \n",
    "#     elif idx == 10:     \n",
    "#         plt.tick_params(axis = 'y', which = 'both', left = False, labelleft = False)\n",
    "        \n",
    "#     else:\n",
    "#         plt.tick_params(axis = 'x', which = 'both', bottom = False, labelbottom = False)\n",
    "#         plt.tick_params(axis = 'y', which = 'both', left = False, labelleft = False)\n",
    "    \n",
    "#     plt.subplot(3,4,12)\n",
    "#     plt.tick_params(axis = 'x', which = 'both', bottom = False, labelbottom = False)\n",
    "#     plt.tick_params(axis = 'y', which = 'both', left = False, labelleft = False)\n",
    "\n",
    "# # plt.savefig(local_dir + 'plots/' + name + '/7_histogram.png', format='PNG')\n",
    "# plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/8_peakpos_stats/histogram.png', format='PNG')\n",
    "# # plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/8_peakpos_stats/histogram.png', format='PNG')\n",
    "# plt.close()\n",
    "\n",
    "# ##### -------------------- METADATA ANALYSIS -------------------- #####\n",
    "\n",
    "# print('DOING METADATA ANALYSIS')\n",
    "\n",
    "# print(batch_out.shape) # the data\n",
    "# print(metadata.shape) # the metadata\n",
    "# print(test_predictions.shape) # the model's predictions about the data\n",
    "\n",
    "# # np.save('batch_out_11_10_21.npy', batch_out)  \n",
    "# # np.save('test_preds_11_10_21.npy', test_predictions)  \n",
    "# # np.save('target_11_10_21.npy', target)\n",
    "\n",
    "# # print(batch_out[0])\n",
    "# # print(metadata[0][0])\n",
    "# # print(test_predictions[0])\n",
    "\n",
    "# # print(metadata)\n",
    "\n",
    "# zeros = np.zeros((test_predictions.shape[0],1))\n",
    "# analysis_array = np.c_[metadata,zeros]\n",
    "# # print(analysis_array.shape)\n",
    "\n",
    "# for i in range(len(batch_out)):\n",
    "    \n",
    "#     # print(i)\n",
    "    \n",
    "#     # print(metadata[i])\n",
    "\n",
    "#     if metadata[i][0] == 'nan':\n",
    "#         # print(str(i) + ' is not an earthquake')\n",
    "#         # analysis_array[i][3] = 'nan'\n",
    "        \n",
    "#         threshold = 0.615\n",
    "        \n",
    "#         # True positive, true negative, false positive, false negative\n",
    "        \n",
    "#         # print('Threshold: ' + str(threshold))\n",
    "    \n",
    "#         # Convert the predictions arrays to single ones and zeroes\n",
    "        \n",
    "#         p = np.where(test_predictions[i] >= threshold)[0]\n",
    "#         if len(p) == 0:\n",
    "#             pred_binary = 0\n",
    "#         elif len(p) > 0:\n",
    "#             pred_binary = 1\n",
    "        \n",
    "#         # if i == 0:\n",
    "#         #     print('Prediction: ')\n",
    "#         #     print(pred_binary)\n",
    "        \n",
    "#         # # Convert the target arrays to single ones and zeroes\n",
    "        \n",
    "#         t = np.where(target[i] > 0)[0]\n",
    "#         if len(t) == 0:\n",
    "#             targ_binary = 0\n",
    "#         elif len(t) > 0:\n",
    "#             targ_binary = 1\n",
    "        \n",
    "#         # if i == 0:\n",
    "#         #     print('Target: ')\n",
    "#         #     print(targ_binary)\n",
    "        \n",
    "#         pred = pred_binary\n",
    "#         targ = targ_binary\n",
    "        \n",
    "#         if pred == targ: # add one to list of correct predictions if matching\n",
    "#             # correct_preds.append(1)\n",
    "            \n",
    "#             if pred == 1 and targ == 1:\n",
    "#                 result = 'true pos'\n",
    "#             elif pred == 0 and targ == 0:\n",
    "#                 result = 'true neg'\n",
    "            \n",
    "#         elif pred != targ: # add ones to list of incorrect predictions if not matching\n",
    "#             # wrong_preds.append(1)\n",
    "            \n",
    "#             if pred == 1 and targ == 0:\n",
    "#                 result = 'false pos'\n",
    "#             elif pred == 0 and targ == 1:\n",
    "#                 result = 'false neg'\n",
    "        \n",
    "#         analysis_array[i][3] = result\n",
    "    \n",
    "#     else:\n",
    "#         # print(str(i) + ' is an earthquake')\n",
    "        \n",
    "#         rupt_num = metadata[i][0]\n",
    "#         station = metadata[i][1]\n",
    "#         mag = metadata[i][2]\n",
    "        \n",
    "#         # print(rupt_num)\n",
    "#         # print(station)\n",
    "#         # print(mag)\n",
    "        \n",
    "#         # print(batch_out[i])\n",
    "#         # print(test_predictions[i])\n",
    "#         # plt.plot(test_predictions[i])\n",
    "#         # plt.show()\n",
    "        \n",
    "#         threshold = 0.2\n",
    "        \n",
    "#         # True positive, true negative, false positive, false negative\n",
    "        \n",
    "#         # print('Threshold: ' + str(threshold))\n",
    "    \n",
    "#         # Convert the predictions arrays to single ones and zeroes\n",
    "        \n",
    "#         p = np.where(test_predictions[i] >= threshold)[0]\n",
    "#         if len(p) == 0:\n",
    "#             pred_binary = 0\n",
    "#         elif len(p) > 0:\n",
    "#             pred_binary = 1\n",
    "        \n",
    "#         # if i == 0:\n",
    "#         #     print('Prediction: ')\n",
    "#         #     print(pred_binary)\n",
    "        \n",
    "#         # # Convert the target arrays to single ones and zeroes\n",
    "        \n",
    "#         t = np.where(target[i] > 0)[0]\n",
    "#         if len(t) == 0:\n",
    "#             targ_binary = 0\n",
    "#         elif len(t) > 0:\n",
    "#             targ_binary = 1\n",
    "        \n",
    "#         # if i == 0:\n",
    "#         #     print('Target: ')\n",
    "#         #     print(targ_binary)\n",
    "        \n",
    "#         pred = pred_binary\n",
    "#         targ = targ_binary\n",
    "        \n",
    "#         if pred == targ: # add one to list of correct predictions if matching\n",
    "#             # correct_preds.append(1)\n",
    "            \n",
    "#             if pred == 1 and targ == 1:\n",
    "#                 result = 'true pos'\n",
    "#             elif pred == 0 and targ == 0:\n",
    "#                 result = 'true neg'\n",
    "            \n",
    "#         elif pred != targ: # add ones to list of incorrect predictions if not matching\n",
    "#             # wrong_preds.append(1)\n",
    "            \n",
    "#             if pred == 1 and targ == 0:\n",
    "#                 result = 'false pos'\n",
    "#             elif pred == 0 and targ == 1:\n",
    "#                 result = 'false neg'\n",
    "        \n",
    "#         analysis_array[i][3] = result\n",
    "    \n",
    "# print(analysis_array)\n",
    "# print(analysis_array.shape)\n",
    "            \n",
    "# # np.save('/home/sdybing/GNSS_project/' + name + 'testing_for_analysis.npy', analysis_array) # VAL\n",
    "# np.save('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/testing_for_analysis.npy', analysis_array) # LAP        \n",
    "\n",
    "# # ##### -------------------- CLASSIFICATION TESTS -------------------- #####\n",
    "\n",
    "# print('DOING CLASSIFICATION TESTS ON REAL DATA')\n",
    "\n",
    "# # Decision threshold evaluation\n",
    "\n",
    "# thresholds = np.arange(0, 1.005, 0.005)\n",
    "# # thresholds = np.arange(0, 1, 0.1)\n",
    "# test_thresholds = [0]\n",
    "\n",
    "# # Use np.where to see whether anywhere in test_predictions is > threshold\n",
    "# # If there is a value that's >, the 'result' of the array is 1. If not 0\n",
    "# # Then compare these 1s and 0s to the target array value for PAR\n",
    "\n",
    "# accuracies = []\n",
    "# accuracies_per = []\n",
    "# precisions = []\n",
    "# recalls = []\n",
    "# F1s = []\n",
    "\n",
    "# for threshold in thresholds:\n",
    "    \n",
    "#     # print('-------------------------------------------------------------')\n",
    "#     # print('Threshold: ' + str(threshold))\n",
    "#     # print('-------------------------------------------------------------')\n",
    "#     # print(' ')\n",
    "    \n",
    "#     # Convert the predictions arrays to single ones and zeroes\n",
    "    \n",
    "#     pred_binary = np.zeros(len(realtest_predictions))\n",
    "#     iterate = np.arange(0,len(realtest_predictions),1)\n",
    "    \n",
    "#     for k in iterate:\n",
    "#         # print('Prediction: ' + str(test_predictions[k]))\n",
    "#         i = np.where(realtest_predictions[k] >= threshold)[0]\n",
    "#         # print(i)\n",
    "#         if len(i) == 0:\n",
    "#             pred_binary[k] = 0\n",
    "#         elif len(i) > 0:\n",
    "#             pred_binary[k] = 1\n",
    "    \n",
    "#     # print('Predictions: ')\n",
    "#     # print(pred_binary)\n",
    "#     # print(pred_binary.shape)\n",
    "    \n",
    "#     # Convert the target arrays to single ones and zeroes\n",
    "    \n",
    "#     targ_binary = np.zeros(len(gauss_target)) # Need to make this ones at indices in rows_w_eqs\n",
    "    \n",
    "#     for idx in range(len(targ_binary)):\n",
    "        \n",
    "#         if idx in rows_w_eqs:\n",
    "            \n",
    "#             targ_binary[idx] = 1\n",
    "    \n",
    "#     # print('Targets: ')\n",
    "#     # print(targ_binary)\n",
    "    \n",
    "#     # Calculating the accuracy, precision, recall, and F1\n",
    "    \n",
    "#     num_preds = len(realtest_predictions) # total number of predictions. Amanda did 50\n",
    "#     correct_preds = []\n",
    "#     wrong_preds = []\n",
    "#     true_pos = []\n",
    "#     true_neg = []\n",
    "#     false_pos = []\n",
    "#     false_neg = []\n",
    "    \n",
    "#     for i in iterate:\n",
    "        \n",
    "#         pred = pred_binary[i]\n",
    "#         targ = targ_binary[i]\n",
    "        \n",
    "#         if pred == targ: # add one to list of correct predictions if matching\n",
    "#             correct_preds.append(1)\n",
    "            \n",
    "#             if pred == 1 and targ == 1:\n",
    "#                 true_pos.append(1)\n",
    "#             elif pred == 0 and targ == 0:\n",
    "#                 true_neg.append(1)\n",
    "            \n",
    "#         elif pred != targ: # add ones to list of incorrect predictions if not matching\n",
    "#             wrong_preds.append(1)\n",
    "            \n",
    "#             if pred == 1 and targ == 0:\n",
    "#                 false_pos.append(1)\n",
    "#             elif pred == 0 and targ == 1:\n",
    "#                 false_neg.append(1)\n",
    "    \n",
    "#     num_correct_preds = len(correct_preds)\n",
    "#     num_wrong_preds = len(wrong_preds)\n",
    "#     num_true_pos = len(true_pos)\n",
    "#     num_true_neg = len(true_neg)\n",
    "#     num_false_pos = len(false_pos)\n",
    "#     num_false_neg = len(false_neg)\n",
    "    \n",
    "#     # print('Correct preds: ' + str(num_correct_preds))\n",
    "#     # print('Wrong preds: ' + str(num_wrong_preds))\n",
    "#     # print('True pos: ' + str(num_true_pos))\n",
    "#     # print('True neg: ' + str(num_true_neg))\n",
    "#     # print('False pos: ' + str(num_false_pos))\n",
    "#     # print('False neg: ' + str(num_false_neg))\n",
    "    \n",
    "#     # print('Threshold: ' + str(threshold))\n",
    "#     # print('Correct preds: ' + str(num_correct_preds))\n",
    "#     # print('Wrong preds: ' + str(num_wrong_preds))\n",
    "#     # print('True pos: ' + str(num_true_pos))\n",
    "#     # print('True neg: ' + str(num_true_neg))\n",
    "#     # print('False pos: ' + str(num_false_pos))\n",
    "#     # print('False neg: ' + str(num_false_neg))\n",
    "    \n",
    "#     accuracy = num_correct_preds / num_preds\n",
    "#     accuracy_per = (num_correct_preds / num_preds) * 100\n",
    "#     # print('Accuracy: ' + str(accuracy_per) + '%')\n",
    "    \n",
    "#     if num_true_pos == 0  and num_false_pos == 0:\n",
    "#         precision = 0\n",
    "#     else:\n",
    "#         precision = num_true_pos / (num_true_pos + num_false_pos)\n",
    "    \n",
    "#     if num_true_pos == 0 and num_false_neg == 0:\n",
    "#         recall = 0\n",
    "#     else:\n",
    "#         recall = num_true_pos / (num_true_pos + num_false_neg)\n",
    "    \n",
    "#     if precision + recall == 0:\n",
    "#         F1 = 0\n",
    "#     else:\n",
    "#         F1 = 2 * ((precision * recall) / (precision + recall))\n",
    "    \n",
    "#     accuracies.append(accuracy)\n",
    "#     accuracies_per.append(accuracy_per)\n",
    "#     precisions.append(precision)\n",
    "#     recalls.append(recall)\n",
    "#     F1s.append(F1)\n",
    "\n",
    "# # print('Accuracies')\n",
    "# # print(accuracies)\n",
    "# # print('Precisions')\n",
    "# # print(precisions)\n",
    "# # print('Recalls')\n",
    "# # print(recalls)\n",
    "# # print('F1s')\n",
    "# # print(F1s)\n",
    "\n",
    "# np.savetxt('realdata_accuracies_percentage_txt.txt', accuracies_per)\n",
    "# np.savetxt('realdata_thresholds_txt.txt', thresholds)\n",
    "\n",
    "# plt.figure(figsize = (8,5), dpi = 300)\n",
    "# # plt.scatter(thresholds,accuracies)\n",
    "# plt.plot(thresholds, accuracies_per, linewidth = 2)\n",
    "# plt.xlabel('Threshold', fontsize = 18)\n",
    "# plt.ylabel('Accuracy (%)', fontsize = 18)\n",
    "# plt.xlim(0,1)\n",
    "# plt.ylim(0,100)\n",
    "# plt.xticks(fontsize = 15)\n",
    "# plt.yticks(fontsize = 15)\n",
    "# plt.title('Accuracy Percentage', fontsize = 18)\n",
    "# # plt.savefig(local_dir + 'plots/' + name + '/6_accuracies_' + str(num_test) + '.png', format='PNG')\n",
    "# # plt.savefig('/Users/sydneydybing/Documents/AGU_2021/Figures/6_accuracies_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/9_realdata_classify_stats/accuracies_realdata.png', format='PNG')\n",
    "# # plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/7_classify_stats/accuracies_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.close()\n",
    "\n",
    "# plt.figure(figsize = (8,5), dpi = 300)\n",
    "# plt.plot(thresholds, precisions, linewidth = 2)\n",
    "# plt.xlabel('Threshold', fontsize = 18)\n",
    "# plt.ylabel('Precision', fontsize = 18)\n",
    "# plt.xlim(0,1)\n",
    "# plt.ylim(0,1)\n",
    "# plt.xticks(fontsize = 15)\n",
    "# plt.yticks(fontsize = 15)\n",
    "# plt.title('Precision', fontsize = 18)\n",
    "# # plt.savefig(local_dir + 'plots/' + name + '/6_precisions_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/9_realdata_classify_stats/precisions_realdata.png', format='PNG')\n",
    "# # plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/7_classify_stats/precisions_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.close()\n",
    "\n",
    "# plt.figure(figsize = (8,5), dpi = 300)\n",
    "# plt.plot(thresholds, recalls, linewidth = 2)\n",
    "# plt.xlabel('Threshold', fontsize = 18)\n",
    "# plt.ylabel('Recall', fontsize = 18)\n",
    "# plt.xlim(0,1)\n",
    "# plt.ylim(0,1)\n",
    "# plt.xticks(fontsize = 15)\n",
    "# plt.yticks(fontsize = 15)\n",
    "# plt.title('Recall', fontsize = 18)\n",
    "# # plt.savefig(local_dir + 'plots/' + name + '/6_recalls_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/9_realdata_classify_stats/recalls_realdata.png', format='PNG')\n",
    "# # plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/7_classify_stats/recalls_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.close()\n",
    "\n",
    "# plt.figure(figsize = (8,5), dpi = 300)\n",
    "# plt.plot(thresholds, F1s, linewidth = 2)\n",
    "# plt.xlabel('Threshold', fontsize = 18)\n",
    "# plt.ylabel('F1', fontsize = 18)\n",
    "# plt.xlim(0,1)\n",
    "# plt.ylim(0,1)\n",
    "# plt.xticks(fontsize = 15)\n",
    "# plt.yticks(fontsize = 15)\n",
    "# plt.title('F1', fontsize = 18)\n",
    "# # plt.savefig(local_dir + 'plots/' + name + '/6_F1s_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/9_realdata_classify_stats/F1s_realdata.png', format='PNG')\n",
    "# # plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/7_classify_stats/F1s_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.close()\n",
    "\n",
    "# # ##### -------------------- GAUSSIAN PEAK POSITION TEST -------------------- #####\n",
    "\n",
    "# # print('DOING PEAK POSITION TESTS')\n",
    "\n",
    "# # # print(target[4])\n",
    "# # # print(test_predictions[4])\n",
    "\n",
    "# # thresholds = np.array([0.01,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.99])\n",
    "\n",
    "# # # threshold = 0.2\n",
    "\n",
    "# # iterate = np.arange(0,len(realtest_predictions),1)\n",
    "# # s = 0\n",
    "\n",
    "# # fig = plt.subplots(nrows = 3, ncols = 4, figsize = (18,14), dpi = 400)\n",
    "# # # fig = plt.subplots(nrows = 3, ncols = 4, figsize = (18,14))\n",
    "# # plt.suptitle('Target vs. Prediction Samples Off per Threshold', fontsize = 20)\n",
    "\n",
    "# # for idx in range(len(thresholds)):\n",
    "    \n",
    "# #     threshold = thresholds[idx]\n",
    "\n",
    "# #     pred_binary = np.zeros(len(realtest_predictions))\n",
    "# #     iterate = np.arange(0,len(realtest_predictions),1)\n",
    "    \n",
    "# #     for k in iterate:\n",
    "# #         i = np.where(realtest_predictions[k] >= threshold)[0]\n",
    "# #         if len(i) == 0:\n",
    "# #             pred_binary[k] = 0\n",
    "# #         elif len(i) > 0:\n",
    "# #             pred_binary[k] = 1\n",
    "    \n",
    "# #     # print('Predictions: ')\n",
    "# #     # print(pred_binary)\n",
    "    \n",
    "# #     # Convert the target arrays to single ones and zeroes\n",
    "    \n",
    "# #     targ_binary = np.zeros(len(gauss_target)) # Need to make this ones at indices in rows_w_eqs\n",
    "    \n",
    "# #     for idx in range(len(targ_binary)):\n",
    "        \n",
    "# #         if idx in rows_w_eqs:\n",
    "            \n",
    "# #             targ_binary[idx] = 1\n",
    "    \n",
    "# #     # print('Targets: ')\n",
    "# #     # print(targ_binary)\n",
    "    \n",
    "# #     signals = []\n",
    "    \n",
    "# #     for i in iterate:\n",
    "# #         pred = pred_binary[i]\n",
    "# #         targ = targ_binary[i]\n",
    "        \n",
    "# #         # print(pred)\n",
    "# #         # print(targ)\n",
    "        \n",
    "# #         if pred == 1 and targ == 1: # True positive, there was a signal and it found it\n",
    "# #             signals.append(i) # Grab index from list of events that are correct and have a pick\n",
    "# #         else:\n",
    "# #             pass\n",
    "    \n",
    "# #     # print(signals)\n",
    "    \n",
    "# #     samples_off_list = []\n",
    "    \n",
    "# #     for index in signals:\n",
    "        \n",
    "# #         # Find the peak and then the index where that peak is and compare \n",
    "        \n",
    "# #         # print('----------------------')\n",
    "# #         # print('Signal number: ' + str(index))\n",
    "        \n",
    "# #         target_max_idx = np.argmax(gauss_target[index])\n",
    "# #         # print('Target: ' + str(target_max_idx))\n",
    "        \n",
    "# #         pred_max_idx = np.argmax(realtest_predictions[index])\n",
    "# #         # print('Prediction: ' + str(pred_max_idx))\n",
    "        \n",
    "# #         samples_off = np.abs(pred_max_idx - target_max_idx)\n",
    "# #         # print('Samples off: ' + str(samples_off))\n",
    "# #         samples_off_list.append(samples_off)\n",
    "        \n",
    "# #     # print(samples_off_list)\n",
    "    \n",
    "# #     plt.subplot(3,4,idx+1)\n",
    "# #     plt.hist(samples_off_list, bins=128, range=(0,128), label = 'Threshold: ' + str(threshold))\n",
    "# #     plt.xlim(0,128)\n",
    "# #     plt.ylim(0,300)\n",
    "# #     plt.legend()\n",
    "# #     plt.grid(which = 'major', color = 'lightgray')\n",
    "# #     plt.subplots_adjust(hspace = 0, wspace = 0)\n",
    "\n",
    "# #     if idx == 0:\n",
    "# #         plt.tick_params(axis = 'x', which = 'both', bottom = False, labelbottom = False)\n",
    "    \n",
    "# #     elif idx == 4:\n",
    "# #         plt.ylabel('Number of examples in bin')\n",
    "# #         plt.tick_params(axis = 'x', which = 'both', bottom = False, labelbottom = False)\n",
    "# #         plt.yticks([0, 50, 100, 150, 200, 250])\n",
    "        \n",
    "# #     elif idx == 8:\n",
    "# #         plt.yticks([0, 50, 100, 150, 200, 250])\n",
    "        \n",
    "# #     elif idx == 9:\n",
    "# #         plt.xlabel('Numbers of samples off target position')\n",
    "# #         plt.tick_params(axis = 'y', which = 'both', left = False, labelleft = False)\n",
    "        \n",
    "# #     elif idx == 10:     \n",
    "# #         plt.tick_params(axis = 'y', which = 'both', left = False, labelleft = False)\n",
    "        \n",
    "# #     else:\n",
    "# #         plt.tick_params(axis = 'x', which = 'both', bottom = False, labelbottom = False)\n",
    "# #         plt.tick_params(axis = 'y', which = 'both', left = False, labelleft = False)\n",
    "    \n",
    "# #     plt.subplot(3,4,12)\n",
    "# #     plt.tick_params(axis = 'x', which = 'both', bottom = False, labelbottom = False)\n",
    "# #     plt.tick_params(axis = 'y', which = 'both', left = False, labelleft = False)\n",
    "\n",
    "# # # plt.savefig(local_dir + 'plots/' + name + '/7_histogram.png', format='PNG')\n",
    "# # plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/10_realdata_peakpos_stats/histogram.png', format='PNG')\n",
    "# # # plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/8_peakpos_stats/histogram.png', format='PNG')\n",
    "# # plt.close()\n",
    "\n",
    "# # ##### -------------------- METADATA ANALYSIS -------------------- #####\n",
    "\n",
    "# # print('DOING REAL METADATA ANALYSIS')\n",
    "\n",
    "# # print(stack_data.shape) # the data\n",
    "# # print(norm_real_meta_data.shape) # the metadata\n",
    "# # print(realtest_predictions.shape) # the model's predictions about the data\n",
    "\n",
    "# # # np.save('batch_out_11_10_21.npy', batch_out)  \n",
    "# # # np.save('test_preds_11_10_21.npy', test_predictions)  \n",
    "# # # np.save('target_11_10_21.npy', target)\n",
    "\n",
    "# # # print(batch_out[0])\n",
    "# # # print(metadata[0][0])\n",
    "# # # print(test_predictions[0])\n",
    "\n",
    "# # # print(metadata)\n",
    "\n",
    "# # zeros = np.zeros((realtest_predictions.shape[0],1))\n",
    "# # analysis_array = np.c_[norm_real_meta_data,zeros]\n",
    "\n",
    "# # # Metadata columns: station, date, start time, end time, counter, gauss position, pgd, SNR N component, SNR E, SNR Z\n",
    "\n",
    "# # # print(analysis_array.shape)\n",
    "\n",
    "# # for i in range(len(stack_data)):\n",
    "    \n",
    "# #     # print(i)\n",
    "    \n",
    "# #     # print(metadata[i])\n",
    "\n",
    "# #     if norm_real_meta_data[i][5] == 'nan':\n",
    "# #         # print(str(i) + ' is not an earthquake')\n",
    "# #         # analysis_array[i][3] = 'nan'\n",
    "        \n",
    "# #         threshold = 0.16\n",
    "        \n",
    "# #         # True positive, true negative, false positive, false negative\n",
    "        \n",
    "# #         # print('Threshold: ' + str(threshold))\n",
    "    \n",
    "# #         # Convert the predictions arrays to single ones and zeroes\n",
    "        \n",
    "# #         p = np.where(test_predictions[i] >= threshold)[0]\n",
    "# #         if len(p) == 0:\n",
    "# #             pred_binary = 0\n",
    "# #         elif len(p) > 0:\n",
    "# #             pred_binary = 1\n",
    "        \n",
    "# #         # if i == 0:\n",
    "# #         #     print('Prediction: ')\n",
    "# #         #     print(pred_binary)\n",
    "        \n",
    "# #         # # Convert the target arrays to single ones and zeroes\n",
    "        \n",
    "# #         t = np.where(target[i] > 0)[0]\n",
    "# #         if len(t) == 0:\n",
    "# #             targ_binary = 0\n",
    "# #         elif len(t) > 0:\n",
    "# #             targ_binary = 1\n",
    "        \n",
    "# #         # if i == 0:\n",
    "# #         #     print('Target: ')\n",
    "# #         #     print(targ_binary)\n",
    "        \n",
    "# #         pred = pred_binary\n",
    "# #         targ = targ_binary\n",
    "        \n",
    "# #         if pred == targ: # add one to list of correct predictions if matching\n",
    "# #             # correct_preds.append(1)\n",
    "            \n",
    "# #             if pred == 1 and targ == 1:\n",
    "# #                 result = 'true pos'\n",
    "# #             elif pred == 0 and targ == 0:\n",
    "# #                 result = 'true neg'\n",
    "            \n",
    "# #         elif pred != targ: # add ones to list of incorrect predictions if not matching\n",
    "# #             # wrong_preds.append(1)\n",
    "            \n",
    "# #             if pred == 1 and targ == 0:\n",
    "# #                 result = 'false pos'\n",
    "# #             elif pred == 0 and targ == 1:\n",
    "# #                 result = 'false neg'\n",
    "        \n",
    "# #         analysis_array[i][3] = result\n",
    "    \n",
    "# #     else:\n",
    "# #         # print(str(i) + ' is an earthquake')\n",
    "        \n",
    "# #         rupt_num = metadata[i][0]\n",
    "# #         station = metadata[i][1]\n",
    "# #         mag = metadata[i][2]\n",
    "        \n",
    "# #         # print(rupt_num)\n",
    "# #         # print(station)\n",
    "# #         # print(mag)\n",
    "        \n",
    "# #         # print(batch_out[i])\n",
    "# #         # print(test_predictions[i])\n",
    "# #         # plt.plot(test_predictions[i])\n",
    "# #         # plt.show()\n",
    "        \n",
    "# #         threshold = 0.2\n",
    "        \n",
    "# #         # True positive, true negative, false positive, false negative\n",
    "        \n",
    "# #         # print('Threshold: ' + str(threshold))\n",
    "    \n",
    "# #         # Convert the predictions arrays to single ones and zeroes\n",
    "        \n",
    "# #         p = np.where(test_predictions[i] >= threshold)[0]\n",
    "# #         if len(p) == 0:\n",
    "# #             pred_binary = 0\n",
    "# #         elif len(p) > 0:\n",
    "# #             pred_binary = 1\n",
    "        \n",
    "# #         # if i == 0:\n",
    "# #         #     print('Prediction: ')\n",
    "# #         #     print(pred_binary)\n",
    "        \n",
    "# #         # # Convert the target arrays to single ones and zeroes\n",
    "        \n",
    "# #         t = np.where(target[i] > 0)[0]\n",
    "# #         if len(t) == 0:\n",
    "# #             targ_binary = 0\n",
    "# #         elif len(t) > 0:\n",
    "# #             targ_binary = 1\n",
    "        \n",
    "# #         # if i == 0:\n",
    "# #         #     print('Target: ')\n",
    "# #         #     print(targ_binary)\n",
    "        \n",
    "# #         pred = pred_binary\n",
    "# #         targ = targ_binary\n",
    "        \n",
    "# #         if pred == targ: # add one to list of correct predictions if matching\n",
    "# #             # correct_preds.append(1)\n",
    "            \n",
    "# #             if pred == 1 and targ == 1:\n",
    "# #                 result = 'true pos'\n",
    "# #             elif pred == 0 and targ == 0:\n",
    "# #                 result = 'true neg'\n",
    "            \n",
    "# #         elif pred != targ: # add ones to list of incorrect predictions if not matching\n",
    "# #             # wrong_preds.append(1)\n",
    "            \n",
    "# #             if pred == 1 and targ == 0:\n",
    "# #                 result = 'false pos'\n",
    "# #             elif pred == 0 and targ == 1:\n",
    "# #                 result = 'false neg'\n",
    "        \n",
    "# #         analysis_array[i][3] = result\n",
    "    \n",
    "# # print(analysis_array)\n",
    "# # print(analysis_array.shape)\n",
    "            \n",
    "# # # # np.save('/home/sdybing/GNSS_project/' + name + 'testing_for_analysis.npy', analysis_array) # VAL\n",
    "# # np.save('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/testing_for_analysis.npy', analysis_array) # LAP        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
