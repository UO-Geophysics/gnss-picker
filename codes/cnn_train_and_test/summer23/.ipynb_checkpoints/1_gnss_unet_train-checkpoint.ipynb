{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "375a8a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import h5py\n",
    "from scipy import signal\n",
    "import X_gnss_unet_datagen_fn6\n",
    "import argparse\n",
    "import seaborn as sns\n",
    "from datetime import date\n",
    "import os\n",
    "\n",
    "date = date.today()\n",
    "sns.set_style('white')\n",
    "\n",
    "project_name = 'july6' # Based on the name of the FakeQuakes project\n",
    "fq_dir = '/hdd/rc_fq/summer23/'\n",
    "noise_dir = '/hdd/gnss_noise_samples/'\n",
    "cnn_save_dir = '/home/sdybing/gnss-picker/cnn_models_outputs/'\n",
    "project_save_dir = cnn_save_dir + project_name + '_fq_train/'\n",
    "if os.path.isdir(run_save_dir):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(run_save_dir)\n",
    "model_save_dir = project_save_dir + 'models/'\n",
    "model_save_file = model_save_dir + 'traindate_' + str(date) + '.tf' # Alter this to chosen date to load an older model\n",
    "figure_save_dir = project_save_dir + 'figures/'\n",
    "\n",
    "train = 0 # Do you want to train? 0 = no, 1 = yes\n",
    "drop = 1 # Drop?\n",
    "resume = 0 # Resume training\n",
    "large = 0.5 # Large unet\n",
    "fac = large\n",
    "epos = 100 # How many epochs?\n",
    "std = 3 # How long do you want the Gaussian STD to be?\n",
    "sr = 1 # Sample rate (Hz)\n",
    "epsilon = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4326f08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FakeQuakes...\n",
      "Loading FakeQuakes metadata...\n",
      "Loading noise...\n",
      "FakeQuakes shape: (917400, 771)\n",
      "Noise data shape: (917400, 771)\n"
     ]
    }
   ],
   "source": [
    "##### -------------------- LOAD THE DATA -------------------- #####\n",
    "\n",
    "# FakeQuakes waveform data\n",
    "print('Loading FakeQuakes...')\n",
    "fq_data = h5py.File(fq_dir + 'july6_128samps_fq_wvfm_data_formatted.hdf5', 'r')\n",
    "fq_data = fq_data['data'][:,:]\n",
    "# print(x_data.shape)\n",
    "\n",
    "# FakeQuakes metadata\n",
    "print('Loading FakeQuakes metadata...')\n",
    "fq_metadata = np.load(fq_dir + 'july6_128samps_fq_wvfm_info.npy')\n",
    "\n",
    "# Noise data\n",
    "print('Loading noise...')\n",
    "all_noise_data = h5py.File(noise_dir + 'summer23_all_noise_samples.hdf5', 'r')\n",
    "all_noise_data = all_noise_data['all_noise_samples'][:,:]\n",
    "\n",
    "# Trim noise data to match length of FakeQuakes data\n",
    "noise_data = all_noise_data[:len(fq_data)]\n",
    "\n",
    "# Array of NaNs to use to match added noise in concatenation later\n",
    "nan_array = np.empty((len(fq_data), 3))\n",
    "nan_array[:] = np.NaN\n",
    "\n",
    "# Check shapes\n",
    "print('FakeQuakes shape: ' + str(fq_data.shape))\n",
    "print('Noise data shape: ' + str(noise_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2fe8f0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FakeQuakes training data shape: (825660,)\n",
      "FakeQuakes testing data shape: (91740,)\n",
      "Noise training data shape: (825660,)\n",
      "Noise testing data shape: (91740,)\n"
     ]
    }
   ],
   "source": [
    "##### -------------------- MAKE TRAINING AND TESTING DATA -------------------- #####\n",
    "\n",
    "np.random.seed(27)\n",
    "\n",
    "# Earthquake/signal data\n",
    "fqinds = np.arange(fq_data.shape[0]) # Signal indices\n",
    "np.random.shuffle(fqinds) # Shuffles the indices\n",
    "train_fqinds = fqinds[:int(0.9*len(fqinds))] # Training data separation: grabs the front 90% of the numbers\n",
    "test_fqinds = fqinds[int(0.9*len(fqinds)):] # Grabs the back 10% (90% through the end)\n",
    "\n",
    "# Noise data\n",
    "noiseinds = np.arange(noise_data.shape[0]) # Noise indices\n",
    "np.random.shuffle(noiseinds) # Shuffles the indices\n",
    "train_noiseinds = noiseinds[:int(0.9*len(noiseinds))] # Training data separation as above\n",
    "test_noiseinds = noiseinds[int(0.9*len(noiseinds)):]\n",
    "\n",
    "# Check shapes to confirm compatability\n",
    "print('FakeQuakes training data shape: ' + str(train_fqinds.shape))\n",
    "print('FakeQuakes testing data shape: ' + str(test_fqinds.shape))\n",
    "print('Noise training data shape: ' + str(train_noiseinds.shape))\n",
    "print('Noise testing data shape: ' + str(test_noiseinds.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "33cd3a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some plots to check what we've loaded\n",
    "    \n",
    "# Plot the FakeQuakes data\n",
    "plt.figure(figsize = (8,5))   \n",
    "plt.title('Earthquake test', fontsize = 14)\n",
    "for idx in range(10): # plot 10 of them\n",
    "    plt.plot(fq_data[idx,:] / np.max(np.abs(fq_data[idx,:])) + idx) # Normalized and offset for each idx\n",
    "plt.axvline(256.5, linestyle = '--', color = 'lightgray')\n",
    "plt.axvline(513.5, linestyle = '--', color = 'lightgray')\n",
    "plt.xlabel('Time (s)', fontsize = 12)\n",
    "plt.ylabel('Normalized amplitude', fontsize = 12)\n",
    "plt.xlim(0,770)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.text(x = 5, y = -0.75, s = 'N', fontsize = 20)\n",
    "plt.text(x = 261, y = -0.75, s = 'E', fontsize = 20)\n",
    "plt.text(x = 518, y = -0.75, s = 'Z', fontsize = 20)\n",
    "# plt.show()\n",
    "plt.savefig(figure_save_dir + '1_plot_raw_eq_data.png', format = 'PNG')\n",
    "plt.close()\n",
    "\n",
    "# Plot noise to check\n",
    "plt.figure(figsize = (8,5))\n",
    "plt.title('Noise test', fontsize = 14)\n",
    "for idx in range(10):\n",
    "    plt.plot(noise_data[idx,:] / np.max(np.abs(noise_data[idx,:])) + idx)\n",
    "plt.axvline(256.5, linestyle = '--', color = 'lightgray')\n",
    "plt.axvline(513.5, linestyle = '--', color = 'lightgray')\n",
    "plt.xlabel('Time (s)', fontsize = 12)\n",
    "plt.ylabel('Normalized amplitude', fontsize = 12)\n",
    "plt.xlim(0,770)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.text(x = 5, y = -1.25, s = 'N', fontsize = 20)\n",
    "plt.text(x = 261, y = -1.25, s = 'E', fontsize = 20)\n",
    "plt.text(x = 518, y = -1.25, s = 'Z', fontsize = 20)\n",
    "# plt.show()\n",
    "plt.savefig(figure_save_dir + '2_plot_noise_data.png', format = 'PNG')\n",
    "plt.close()\n",
    "\n",
    "# Check the PGD distribution\n",
    "\n",
    "# testing_data = fq_data[test_fqinds]\n",
    "\n",
    "# pgd = np.zeros(testing_data.shape[0]) # Reminder - FQ data is in meters\n",
    "# for idx in range(testing_data.shape[0]):\n",
    "#     pgd[idx] = np.max(np.sqrt((testing_data[idx,:257])**2 + (testing_data[idx,257:514])**2 + (testing_data[idx,514:])**2))\n",
    "\n",
    "# plt.figure(figsize = (8,5))\n",
    "# plt.hist(pgd, bins = 30, alpha = 0.5, edgecolor = 'black', linewidth = 1.2)\n",
    "# plt.ylim(0,10000)\n",
    "# plt.show()\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d2411cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 129, 3)\n",
      "(32, 129)\n",
      "(32, 3)\n"
     ]
    }
   ],
   "source": [
    "# ##### -------------------- FIRST GENERATOR TEST: generate batch data -------------------- #####\n",
    "\n",
    "my_data = X_gnss_unet_datagen_fn6.my_3comp_data_generator(32, fq_data, noise_data, fq_metadata, nan_array, train_fqinds, train_noiseinds, sr, std, valid = True) # Valid = True to get original data back\n",
    "origdata, target, metadata = next(my_data) \n",
    "\n",
    "print(origdata.shape)\n",
    "print(target.shape)\n",
    "print(metadata.shape)\n",
    "\n",
    "# Shapes:\n",
    "    # origdata: (batch_size, 128, 3) # N, E, Z\n",
    "    # target: (batch_size, 128)\n",
    "    # metadata: (batch_size, 3) Rupt name, station name, magnitude\n",
    "\n",
    "# Plot generator results\n",
    "\n",
    "nexamples = 5 # Number of examples to look at \n",
    "  \n",
    "for ind in range(nexamples): \n",
    "    \n",
    "#     print('Magnitude: ' + str(metadata[ind,2]))\n",
    "\n",
    "    fig = plt.subplots(nrows = 1, ncols = 3, figsize = (26,4), dpi = 300) # shoter for AGU talk\n",
    "    plt.subplots_adjust(wspace = 0.4)\n",
    "    t = 1/sr * np.arange(origdata.shape[1])\n",
    "    \n",
    "    ax1 = plt.subplot(131)\n",
    "    ax1.plot(t, origdata[ind,:,0]*100, label = 'N original data', color = 'C0')\n",
    "    ax1.set_ylabel('Displacement (cm)')\n",
    "    ax1.set_xlabel('Time (s)')\n",
    "    ax1.legend(loc = 'upper right')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(t, target[ind,:], color = 'black', linestyle = '--', label = 'Target')\n",
    "    ax2.set_ylabel('Confidence')\n",
    "    ax2.legend(loc = 'lower right')\n",
    "    \n",
    "    ax3 = plt.subplot(132)\n",
    "    ax3.plot(t, origdata[ind,:,1]*100, label = 'E original data', color = 'C1')\n",
    "    ax3.set_ylabel('Displacement (cm)')\n",
    "    ax3.legend(loc = 'upper right')\n",
    "    ax4 = ax3.twinx()\n",
    "    ax4.plot(t, target[ind,:], color = 'black', linestyle = '--', label = 'Target')\n",
    "    ax4.legend(loc = 'lower right')\n",
    "    \n",
    "    ax5 = plt.subplot(133)\n",
    "    ax5.plot(t, origdata[ind,:,2]*100, label = 'Z original data', color = 'C2')\n",
    "    ax5.set_ylabel('Displacement (cm)')\n",
    "    ax5.legend(loc = 'upper right')\n",
    "    ax6 = ax5.twinx()\n",
    "    ax6.plot(t, target[ind,:], color = 'black', linestyle = '--', label = 'Target')\n",
    "    ax6.legend(loc = 'lower right')\n",
    "    \n",
    "#     plt.show()\n",
    "    plt.savefig(figure_save_dir + '/3_ex_' + str(ind) + '_plot_generator_pass.png', format = 'PNG')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5d3beea4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 128, 16), (None, 129, 16)]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m##### -------------------- BUILD THE MODEL -------------------- #####\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m drop:\n\u001b[0;32m----> 4\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mX_gnss_unet_datagen_fn6\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_large_unet_drop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncomps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwinsize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m129\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsing model with dropout\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/gnss-picker/gnss-picker-repo/codes/cnn_train_and_test/summer23/X_gnss_unet_datagen_fn6.py:41\u001b[0m, in \u001b[0;36mmake_large_unet_drop\u001b[0;34m(fac, sr, ncomps, winsize)\u001b[0m\n\u001b[1;32m     38\u001b[0m network \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv1D(\u001b[38;5;28mint\u001b[39m(fac\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m32\u001b[39m), \u001b[38;5;241m21\u001b[39m, activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m)(level2)\n\u001b[1;32m     39\u001b[0m network \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mUpSampling1D()(network)\n\u001b[0;32m---> 41\u001b[0m level1 \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# End of network\u001b[39;00m\n\u001b[1;32m     44\u001b[0m network \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m2\u001b[39m)(level1)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/layers/merge.py:528\u001b[0m, in \u001b[0;36mConcatenate.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    525\u001b[0m unique_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\n\u001b[1;32m    526\u001b[0m     shape[axis] \u001b[38;5;28;01mfor\u001b[39;00m shape \u001b[38;5;129;01min\u001b[39;00m shape_set \u001b[38;5;28;01mif\u001b[39;00m shape[axis] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dims) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 528\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err_msg)\n",
      "\u001b[0;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 128, 16), (None, 129, 16)]"
     ]
    }
   ],
   "source": [
    "##### -------------------- BUILD THE MODEL -------------------- #####\n",
    "\n",
    "if drop:\n",
    "    model = X_gnss_unet_datagen_fn6.make_large_unet_drop(fac, sr, ncomps = 3, winsize = 129)\n",
    "    print('Using model with dropout')\n",
    "else:\n",
    "    model = X_gnss_unet_datagen_fn6.make_large_unet(fac, sr, ncomps = 3)  \n",
    "    print('Using large model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9984ace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### -------------------- TRAIN THE MODEL -------------------- #####\n",
    "\n",
    "if train:\n",
    "    \n",
    "    print('Training model and saving results to ' + model_save_file)\n",
    "        \n",
    "    csv_logger = tf.keras.callbacks.CSVLogger(model_save_file + '.csv', append = True)\n",
    "    \n",
    "    history = model.fit_generator(gnss_unet_tools.my_3comp_data_generator(batch_size, x_data, n_data, meta_data, nan_array, sig_train_inds, noise_train_inds, sr, std), # Valid = False for training; implied\n",
    "                        steps_per_epoch = (len(sig_train_inds) + len(noise_train_inds))//batch_size,\n",
    "                        validation_data = gnss_unet_tools.my_3comp_data_generator(batch_size, x_data, n_data, meta_data, nan_array, sig_test_inds, noise_test_inds, sr, std),\n",
    "                        validation_steps = (len(sig_test_inds) + len(noise_test_inds))//batch_size,\n",
    "                        epochs = epos, callbacks = [model_checkpoint_callback, csv_logger])\n",
    "    \n",
    "    model.save_weights(model_save_file)\n",
    "    \n",
    "else:\n",
    "    print('Loading training results from ' + model_save_file)\n",
    "    model.load_weights(model_save_file)\n",
    "    \n",
    "# Plotting training curves\n",
    "\n",
    "training_stats = np.genfromtxt(model_save_file + '.csv', delimiter = ',', skip_header = 1)\n",
    "\n",
    "fig = plt.subplots(nrows = 2, ncols = 1, figsize = (6,8))\n",
    "plt.suptitle('Training curves')\n",
    "\n",
    "ax1 = plt.subplot(211)\n",
    "ax1.plot(training_stats[1:100,0], training_stats[1:100,1], label = 'Accuracy')\n",
    "ax1.plot(training_stats[1:100,0], training_stats[1:100,3], label = 'Validation accuracy') \n",
    "ax1.legend(loc = 'lower right')\n",
    "ax1.set_title(model_save_file)\n",
    "\n",
    "ax2 = plt.subplot(212)\n",
    "ax2.plot(training_stats[1:100,0], training_stats[1:100,2], label = 'Loss') \n",
    "ax2.plot(training_stats[1:100,0], training_stats[1:100,4], label = 'Validation loss') \n",
    "ax2.legend(loc = 'upper right')\n",
    "ax2.set_xlabel('Epoch')\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig(local_dir + 'plots/' + name + '/4_training_curves.png', format = 'PNG')\n",
    "# plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30867c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### -------------------- TEST THE MODEL -------------------- #####\n",
    "\n",
    "# Number of samples to test with\n",
    "num_test = len(testing_data) - 1\n",
    "# print(num_test)\n",
    "\n",
    "# See how things went with the remaining 10%\n",
    "my_test_data = gnss_unet_tools.my_3comp_data_generator(num_test, x_data, n_data, meta_data, nan_array, sig_test_inds, noise_test_inds, sr, std, valid = True)\n",
    "batch_out, target, origdata, metadata = next(my_test_data)\n",
    "test_predictions = model.predict(batch_out)\n",
    "\n",
    "# print('test_predictions shape:')\n",
    "# print(test_predictions.shape)\n",
    "# print('target shape:')\n",
    "# print(target.shape)\n",
    "# print(target[1])\n",
    "# print(batch_out.shape)\n",
    "# print(origdata.shape)\n",
    "\n",
    "# Calculate PGDs and distribution\n",
    "\n",
    "pgd_1=np.zeros(origdata.shape[0])\n",
    "for ii in range(origdata.shape[0]):\n",
    "    pgd_1[ii]=np.max(np.sqrt((origdata[ii,:,0])**2+(origdata[ii,:,1])**2+(origdata[ii,:,2])**2))\n",
    "\n",
    "plt.figure(figsize=(8,5), dpi=300)\n",
    "plt.hist(pgd_1,bins=np.arange(0,5,0.05), color=(162/256,210/256,255/256),alpha=0.5, edgecolor='black', linewidth=1.2)\n",
    "plt.ylim(0,4000)\n",
    "plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/5_10per_testing/pgd_distrib.png', format = 'PNG') # LAP\n",
    "# plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/5_10per_testing/pgd_distrib.png', format = 'PNG') # LAP\n",
    "plt.close()\n",
    "\n",
    "np.save('origdata_fakequakes_testing.npy', origdata)\n",
    "np.save('target_fakequakes_testing.npy', target)\n",
    "\n",
    "# Plot some data and predictions!\n",
    "\n",
    "nexamples = 20 # Number of examples to look at \n",
    "  \n",
    "for ind in range(nexamples): \n",
    "    \n",
    "    fig = plt.subplots(nrows = 1, ncols = 3, figsize = (18,4), dpi = 300)\n",
    "    plt.subplots_adjust(wspace = 0.4)\n",
    "    t = 1/sr * np.arange(batch_out.shape[1])\n",
    "    # print(t)\n",
    "    \n",
    "    ax1 = plt.subplot(131)\n",
    "    ax1.plot(t, origdata[ind,:,0]*100, label = 'N original data', color = 'C0')\n",
    "    ax1.set_ylabel('Displacement (cm)')\n",
    "    ax1.set_xlabel('Time (s)')\n",
    "    ax1.legend(loc = 'upper right')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(t, target[ind,:], color = 'black', linestyle = '--', label = 'Target')\n",
    "    ax2.plot(t, test_predictions[ind,:], color = 'red', linestyle = '--', label = 'Prediction')\n",
    "    ax2.set_ylabel('Confidence')\n",
    "    ax2.set_ylim(-0.05,1.05)\n",
    "    ax2.legend(loc = 'upper left')\n",
    "    \n",
    "    ax3 = plt.subplot(132)\n",
    "    ax3.plot(t, origdata[ind,:,1]*100, label = 'E original data', color = 'C1')\n",
    "    ax3.set_ylabel('Displacement (cm)')\n",
    "    ax3.legend(loc = 'upper right')\n",
    "    ax4 = ax3.twinx()\n",
    "    ax4.plot(t, target[ind,:], color = 'black', linestyle = '--', label = 'Target')\n",
    "    ax4.plot(t, test_predictions[ind,:], color = 'red', linestyle = '--', label = 'Prediction')\n",
    "    ax4.set_ylim(-0.05,1.05)\n",
    "    ax4.legend(loc = 'upper left')\n",
    "    \n",
    "    ax5 = plt.subplot(133)\n",
    "    ax5.plot(t, origdata[ind,:,2]*100, label = 'Z original data', color = 'C2')\n",
    "    ax5.set_ylabel('Displacement (cm)')\n",
    "    ax5.legend(loc = 'upper right')\n",
    "    ax6 = ax5.twinx()\n",
    "    ax6.plot(t, target[ind,:], color = 'black', linestyle = '--', label = 'Target')\n",
    "    ax6.plot(t, test_predictions[ind,:], color = 'red', linestyle = '--', label = 'Prediction')\n",
    "    ax6.set_ylim(-0.05,1.05)\n",
    "    ax6.legend(loc = 'upper left')\n",
    "    \n",
    "    # plt.savefig(local_dir + 'plots/' + name + '/5_ex_' + str(ind) + '_plot_predictions.png', format = 'PNG')\n",
    "    plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/5_10per_testing/ex_' + str(ind) + '_plot_predictions.png', format = 'PNG')\n",
    "    # plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/5_10per_testing/ex_' + str(ind) + '_plot_predictions.png', format = 'PNG')\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fd1b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### -------------------- REAL DATA TESTS -------------------- #####\n",
    "\n",
    "# print('TESTING WITH REAL DATA!!!')\n",
    "\n",
    "# # realtest = gnss_unet_tools.real_data_generator(data = real_data, data_inds = real_data_inds, meta_data = real_meta_data, sr = 1, std = 3, nlen = 128)\n",
    "# realtest = gnss_unet_tools.real_data_generator(data = norm_real_data, data_inds = norm_real_data_inds, meta_data = norm_real_meta_data, sr = 1, std = 3, nlen = 128)\n",
    "# stack_data, gauss_target = next(realtest)\n",
    "# # print(stack_data)\n",
    "# # print(stack_data.shape)\n",
    "# # print(gauss_target)\n",
    "# # print(gauss_target.shape)\n",
    "# realtest_predictions = model.predict(stack_data)\n",
    "\n",
    "# np.save('realtest_predictions.npy', realtest_predictions)\n",
    "# np.save('stack_data.npy', stack_data)\n",
    "# np.save('gauss_target.npy', gauss_target)\n",
    "\n",
    "# # Plot some data and predictions!\n",
    "\n",
    "# # rows_w_eqs = np.load('real_metadata_rowsweqs.npy')\n",
    "# rows_w_eqs = np.load('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/More_RealData/rowsweqs.npy') # More data, normed\n",
    "\n",
    "# nexamples = 5 # Number of examples to look at \n",
    "  \n",
    "# # for ind in range(nexamples): \n",
    "# for ind in rows_w_eqs[43]:\n",
    "    \n",
    "#     fig = plt.subplots(nrows = 1, ncols = 3, figsize = (22,4), dpi = 300)\n",
    "#     plt.subplots_adjust(wspace = 0.4)\n",
    "#     t = 1/sr * np.arange(batch_out.shape[1])\n",
    "    \n",
    "#     ax1 = plt.subplot(131)\n",
    "#     ax1.plot(t, stack_data[ind,:,0]*100, label = 'N original data', color = 'C0')\n",
    "#     ax1.set_ylabel('Displacement (cm)')\n",
    "#     ax1.set_xlabel('Time (s)')\n",
    "#     ax1.legend(loc = 'upper right')\n",
    "#     ax2 = ax1.twinx()\n",
    "#     ax2.plot(t, gauss_target[ind,:], color = 'black', linestyle = '--', label = 'Target')\n",
    "#     ax2.plot(t, realtest_predictions[ind,:], color = 'red', linestyle = '--', label = 'Prediction')\n",
    "#     ax2.set_ylabel('Confidence')\n",
    "#     ax2.set_ylim(-0.05,1.05)\n",
    "#     ax2.legend(loc = 'upper left')\n",
    "    \n",
    "#     ax3 = plt.subplot(132)\n",
    "#     ax3.plot(t, stack_data[ind,:,1]*100, label = 'E original data', color = 'C1')\n",
    "#     ax3.set_ylabel('Displacement (cm)')\n",
    "#     ax3.legend(loc = 'upper right')\n",
    "#     ax4 = ax3.twinx()\n",
    "#     ax4.plot(t, gauss_target[ind,:], color = 'black', linestyle = '--', label = 'Target')\n",
    "#     ax4.plot(t, realtest_predictions[ind,:], color = 'red', linestyle = '--', label = 'Prediction')\n",
    "#     ax4.set_ylim(-0.05,1.05)\n",
    "#     ax4.legend(loc = 'upper left')\n",
    "    \n",
    "#     ax5 = plt.subplot(133)\n",
    "#     ax5.plot(t, stack_data[ind,:,2]*100, label = 'Z original data', color = 'C2')\n",
    "#     ax5.set_ylabel('Displacement (cm)')\n",
    "#     ax5.legend(loc = 'upper right')\n",
    "#     ax6 = ax5.twinx()\n",
    "#     ax6.plot(t, gauss_target[ind,:], color = 'black', linestyle = '--', label = 'Target')\n",
    "#     ax6.plot(t, realtest_predictions[ind,:], color = 'red', linestyle = '--', label = 'Prediction')\n",
    "#     ax6.set_ylim(-0.05,1.05)\n",
    "#     ax6.legend(loc = 'upper left')\n",
    "    \n",
    "#     # plt.show()\n",
    "    \n",
    "#     # plt.savefig(local_dir + 'plots/' + name + '/5_ex_' + str(ind) + '_plot_predictions.png', format = 'PNG')\n",
    "#     plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/6_real_testing/ex_' + str(ind) + '_plot_predictions.png', format = 'PNG') # First small real test\n",
    "#     # plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/newtrain_march/more_realdata_norm_testing/ex_' + str(ind) + '_plot_preds.png', format = 'PNG') # Big real set, normed\n",
    "#     # plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/6_real_testing/ex_' + str(ind) + '_plot_predictions.png', format = 'PNG')\n",
    "#     plt.close()\n",
    "\n",
    "        \n",
    "##### -------------------- CLASSIFICATION TESTS -------------------- #####\n",
    "\n",
    "# print('DOING CLASSIFICATION TESTS ON FAKEQUAKES DATA')\n",
    "\n",
    "# # Decision threshold evaluation\n",
    "\n",
    "# thresholds = np.arange(0, 1.005, 0.005)\n",
    "# # thresholds = np.arange(0, 1, 0.1)\n",
    "# test_thresholds = [0]\n",
    "\n",
    "# # Use np.where to see whether anywhere in test_predictions is > threshold\n",
    "# # If there is a value that's >, the 'result' of the array is 1. If not 0\n",
    "# # Then compare these 1s and 0s to the target array value for PAR\n",
    "\n",
    "# accuracies = []\n",
    "# accuracies_per = []\n",
    "# precisions = []\n",
    "# recalls = []\n",
    "# F1s = []\n",
    "\n",
    "# for threshold in thresholds:\n",
    "    \n",
    "#     # print('-------------------------------------------------------------')\n",
    "#     # print('Threshold: ' + str(threshold))\n",
    "#     # print('-------------------------------------------------------------')\n",
    "#     # print(' ')\n",
    "    \n",
    "#     # Convert the predictions arrays to single ones and zeroes\n",
    "    \n",
    "#     pred_binary = np.zeros(len(test_predictions))\n",
    "#     iterate = np.arange(0,num_test,1)\n",
    "    \n",
    "#     for k in iterate:\n",
    "#         # print('Prediction: ' + str(test_predictions[k]))\n",
    "#         i = np.where(test_predictions[k] >= threshold)[0]\n",
    "#         # print(i)\n",
    "#         if len(i) == 0:\n",
    "#             pred_binary[k] = 0\n",
    "#         elif len(i) > 0:\n",
    "#             pred_binary[k] = 1\n",
    "    \n",
    "#     # print('Predictions: ')\n",
    "#     # print(pred_binary)\n",
    "#     # print(pred_binary.shape)\n",
    "    \n",
    "#     # Convert the target arrays to single ones and zeroes\n",
    "    \n",
    "#     targ_binary = np.zeros(len(target))\n",
    "#     iterate = np.arange(0,num_test,1)\n",
    "    \n",
    "#     for k in iterate:\n",
    "#         # print('Target: ' + str(test_predictions[k]))\n",
    "#         i = np.where(target[k] > 0)[0]\n",
    "#         if len(i) == 0:\n",
    "#             targ_binary[k] = 0\n",
    "#         elif len(i) > 0:\n",
    "#             targ_binary[k] = 1\n",
    "    \n",
    "#     # print('Targets: ')\n",
    "#     # print(targ_binary)\n",
    "    \n",
    "#     # Calculating the accuracy, precision, recall, and F1\n",
    "    \n",
    "#     num_preds = num_test # total number of predictions. Amanda did 50\n",
    "#     correct_preds = []\n",
    "#     wrong_preds = []\n",
    "#     true_pos = []\n",
    "#     true_neg = []\n",
    "#     false_pos = []\n",
    "#     false_neg = []\n",
    "    \n",
    "#     for i in iterate:\n",
    "        \n",
    "#         pred = pred_binary[i]\n",
    "#         targ = targ_binary[i]\n",
    "        \n",
    "#         if pred == targ: # add one to list of correct predictions if matching\n",
    "#             correct_preds.append(1)\n",
    "            \n",
    "#             if pred == 1 and targ == 1:\n",
    "#                 true_pos.append(1)\n",
    "#             elif pred == 0 and targ == 0:\n",
    "#                 true_neg.append(1)\n",
    "            \n",
    "#         elif pred != targ: # add ones to list of incorrect predictions if not matching\n",
    "#             wrong_preds.append(1)\n",
    "            \n",
    "#             if pred == 1 and targ == 0:\n",
    "#                 false_pos.append(1)\n",
    "#             elif pred == 0 and targ == 1:\n",
    "#                 false_neg.append(1)\n",
    "    \n",
    "#     num_correct_preds = len(correct_preds)\n",
    "#     num_wrong_preds = len(wrong_preds)\n",
    "#     num_true_pos = len(true_pos)\n",
    "#     num_true_neg = len(true_neg)\n",
    "#     num_false_pos = len(false_pos)\n",
    "#     num_false_neg = len(false_neg)\n",
    "    \n",
    "#     # print('Correct preds: ' + str(num_correct_preds))\n",
    "#     # print('Wrong preds: ' + str(num_wrong_preds))\n",
    "#     # print('True pos: ' + str(num_true_pos))\n",
    "#     # print('True neg: ' + str(num_true_neg))\n",
    "#     # print('False pos: ' + str(num_false_pos))\n",
    "#     # print('False neg: ' + str(num_false_neg))\n",
    "    \n",
    "#     # print('Threshold: ' + str(threshold))\n",
    "#     # print('Correct preds: ' + str(num_correct_preds))\n",
    "#     # print('Wrong preds: ' + str(num_wrong_preds))\n",
    "#     # print('True pos: ' + str(num_true_pos))\n",
    "#     # print('True neg: ' + str(num_true_neg))\n",
    "#     # print('False pos: ' + str(num_false_pos))\n",
    "#     # print('False neg: ' + str(num_false_neg))\n",
    "    \n",
    "#     accuracy = num_correct_preds / num_preds\n",
    "#     accuracy_per = (num_correct_preds / num_preds) * 100\n",
    "#     # print('Accuracy: ' + str(accuracy_per) + '%')\n",
    "    \n",
    "#     if num_true_pos == 0  and num_false_pos == 0:\n",
    "#         precision = 0\n",
    "#     else:\n",
    "#         precision = num_true_pos / (num_true_pos + num_false_pos)\n",
    "    \n",
    "#     if num_true_pos == 0 and num_false_neg == 0:\n",
    "#         recall = 0\n",
    "#     else:\n",
    "#         recall = num_true_pos / (num_true_pos + num_false_neg)\n",
    "    \n",
    "#     if precision + recall == 0:\n",
    "#         F1 = 0\n",
    "#     else:\n",
    "#         F1 = 2 * ((precision * recall) / (precision + recall))\n",
    "    \n",
    "#     accuracies.append(accuracy)\n",
    "#     accuracies_per.append(accuracy_per)\n",
    "#     precisions.append(precision)\n",
    "#     recalls.append(recall)\n",
    "#     F1s.append(F1)\n",
    "\n",
    "# # print('Accuracies')\n",
    "# # print(accuracies)\n",
    "# # print('Precisions')\n",
    "# # print(precisions)\n",
    "# # print('Recalls')\n",
    "# # print(recalls)\n",
    "# # print('F1s')\n",
    "# # print(F1s)\n",
    "\n",
    "# np.savetxt('accuracies_percentage_txt.txt', accuracies_per)\n",
    "# np.savetxt('thresholds_txt.txt', thresholds)\n",
    "\n",
    "# plt.figure(figsize = (8,5), dpi = 300)\n",
    "# # plt.scatter(thresholds,accuracies)\n",
    "# plt.plot(thresholds, accuracies_per, linewidth = 2)\n",
    "# plt.xlabel('Threshold', fontsize = 18)\n",
    "# plt.ylabel('Accuracy (%)', fontsize = 18)\n",
    "# plt.xlim(0,1)\n",
    "# plt.ylim(0,100)\n",
    "# plt.xticks(fontsize = 15)\n",
    "# plt.yticks(fontsize = 15)\n",
    "# plt.title('Accuracy Percentage', fontsize = 18)\n",
    "# # plt.savefig(local_dir + 'plots/' + name + '/6_accuracies_' + str(num_test) + '.png', format='PNG')\n",
    "# # plt.savefig('/Users/sydneydybing/Documents/AGU_2021/Figures/6_accuracies_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/7_classify_stats/accuracies_' + str(num_test) + '.png', format='PNG')\n",
    "# # plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/7_classify_stats/accuracies_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.close()\n",
    "\n",
    "# plt.figure(figsize = (8,5), dpi = 300)\n",
    "# plt.plot(thresholds, precisions, linewidth = 2)\n",
    "# plt.xlabel('Threshold', fontsize = 18)\n",
    "# plt.ylabel('Precision', fontsize = 18)\n",
    "# plt.xlim(0,1)\n",
    "# plt.ylim(0,1)\n",
    "# plt.xticks(fontsize = 15)\n",
    "# plt.yticks(fontsize = 15)\n",
    "# plt.title('Precision', fontsize = 18)\n",
    "# # plt.savefig(local_dir + 'plots/' + name + '/6_precisions_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/7_classify_stats/precisions_' + str(num_test) + '.png', format='PNG')\n",
    "# # plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/7_classify_stats/precisions_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.close()\n",
    "\n",
    "# plt.figure(figsize = (8,5), dpi = 300)\n",
    "# plt.plot(thresholds, recalls, linewidth = 2)\n",
    "# plt.xlabel('Threshold', fontsize = 18)\n",
    "# plt.ylabel('Recall', fontsize = 18)\n",
    "# plt.xlim(0,1)\n",
    "# plt.ylim(0,1)\n",
    "# plt.xticks(fontsize = 15)\n",
    "# plt.yticks(fontsize = 15)\n",
    "# plt.title('Recall', fontsize = 18)\n",
    "# # plt.savefig(local_dir + 'plots/' + name + '/6_recalls_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/7_classify_stats/recalls_' + str(num_test) + '.png', format='PNG')\n",
    "# # plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/7_classify_stats/recalls_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.close()\n",
    "\n",
    "# plt.figure(figsize = (8,5), dpi = 300)\n",
    "# plt.plot(thresholds, F1s, linewidth = 2)\n",
    "# plt.xlabel('Threshold', fontsize = 18)\n",
    "# plt.ylabel('F1', fontsize = 18)\n",
    "# plt.xlim(0,1)\n",
    "# plt.ylim(0,1)\n",
    "# plt.xticks(fontsize = 15)\n",
    "# plt.yticks(fontsize = 15)\n",
    "# plt.title('F1', fontsize = 18)\n",
    "# # plt.savefig(local_dir + 'plots/' + name + '/6_F1s_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/7_classify_stats/F1s_' + str(num_test) + '.png', format='PNG')\n",
    "# # plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/7_classify_stats/F1s_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.close()\n",
    "\n",
    "# ##### -------------------- GAUSSIAN PEAK POSITION TEST -------------------- #####\n",
    "\n",
    "# print('DOING PEAK POSITION TESTS')\n",
    "\n",
    "# # print(target[4])\n",
    "# # print(test_predictions[4])\n",
    "\n",
    "# thresholds = np.array([0.01,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.99])\n",
    "\n",
    "# # threshold = 0.2\n",
    "\n",
    "# iterate = np.arange(0,num_test,1)\n",
    "# s = 0\n",
    "\n",
    "# fig = plt.subplots(nrows = 3, ncols = 4, figsize = (18,14), dpi = 400)\n",
    "# # fig = plt.subplots(nrows = 3, ncols = 4, figsize = (18,14))\n",
    "# plt.suptitle('Target vs. Prediction Samples Off per Threshold', fontsize = 20)\n",
    "\n",
    "# for idx in range(len(thresholds)):\n",
    "    \n",
    "#     threshold = thresholds[idx]\n",
    "\n",
    "#     pred_binary = np.zeros(len(test_predictions))\n",
    "#     iterate = np.arange(0,num_test,1)\n",
    "    \n",
    "#     for k in iterate:\n",
    "#         i = np.where(test_predictions[k] >= threshold)[0]\n",
    "#         if len(i) == 0:\n",
    "#             pred_binary[k] = 0\n",
    "#         elif len(i) > 0:\n",
    "#             pred_binary[k] = 1\n",
    "    \n",
    "#     # print('Predictions: ')\n",
    "#     # print(pred_binary)\n",
    "    \n",
    "#     # Convert the target arrays to single ones and zeroes\n",
    "    \n",
    "#     targ_binary = np.zeros(len(target))\n",
    "#     iterate = np.arange(0,num_test,1)\n",
    "    \n",
    "#     for k in iterate:\n",
    "#         i = np.where(target[k] > 0)[0]\n",
    "#         if len(i) == 0:\n",
    "#             targ_binary[k] = 0\n",
    "#         elif len(i) > 0:\n",
    "#             targ_binary[k] = 1\n",
    "    \n",
    "#     # print('Targets: ')\n",
    "#     # print(targ_binary)\n",
    "    \n",
    "#     signals = []\n",
    "    \n",
    "#     for i in iterate:\n",
    "#         pred = pred_binary[i]\n",
    "#         targ = targ_binary[i]\n",
    "        \n",
    "#         # print(pred)\n",
    "#         # print(targ)\n",
    "        \n",
    "#         if pred == 1 and targ == 1: # True positive, there was a signal and it found it\n",
    "#             signals.append(i) # Grab index from list of events that are correct and have a pick\n",
    "#         else:\n",
    "#             pass\n",
    "    \n",
    "#     # print(signals)\n",
    "    \n",
    "#     samples_off_list = []\n",
    "    \n",
    "#     for index in signals:\n",
    "        \n",
    "#         # Find the peak and then the index where that peak is and compare \n",
    "        \n",
    "#         # print('----------------------')\n",
    "#         # print('Signal number: ' + str(index))\n",
    "        \n",
    "#         target_max_idx = np.argmax(target[index])\n",
    "#         # print('Target: ' + str(target_max_idx))\n",
    "        \n",
    "#         pred_max_idx = np.argmax(test_predictions[index])\n",
    "#         # print('Prediction: ' + str(pred_max_idx))\n",
    "        \n",
    "#         samples_off = np.abs(pred_max_idx - target_max_idx)\n",
    "#         # print('Samples off: ' + str(samples_off))\n",
    "#         samples_off_list.append(samples_off)\n",
    "        \n",
    "#     # print(samples_off_list)\n",
    "    \n",
    "#     plt.subplot(3,4,idx+1)\n",
    "#     plt.hist(samples_off_list, bins=128, range=(0,128), label = 'Threshold: ' + str(threshold))\n",
    "#     plt.xlim(0,128)\n",
    "#     plt.ylim(0,300)\n",
    "#     plt.legend()\n",
    "#     plt.grid(which = 'major', color = 'lightgray')\n",
    "#     plt.subplots_adjust(hspace = 0, wspace = 0)\n",
    "\n",
    "#     if idx == 0:\n",
    "#         plt.tick_params(axis = 'x', which = 'both', bottom = False, labelbottom = False)\n",
    "    \n",
    "#     elif idx == 4:\n",
    "#         plt.ylabel('Number of examples in bin')\n",
    "#         plt.tick_params(axis = 'x', which = 'both', bottom = False, labelbottom = False)\n",
    "#         plt.yticks([0, 50, 100, 150, 200, 250])\n",
    "        \n",
    "#     elif idx == 8:\n",
    "#         plt.yticks([0, 50, 100, 150, 200, 250])\n",
    "        \n",
    "#     elif idx == 9:\n",
    "#         plt.xlabel('Numbers of samples off target position')\n",
    "#         plt.tick_params(axis = 'y', which = 'both', left = False, labelleft = False)\n",
    "        \n",
    "#     elif idx == 10:     \n",
    "#         plt.tick_params(axis = 'y', which = 'both', left = False, labelleft = False)\n",
    "        \n",
    "#     else:\n",
    "#         plt.tick_params(axis = 'x', which = 'both', bottom = False, labelbottom = False)\n",
    "#         plt.tick_params(axis = 'y', which = 'both', left = False, labelleft = False)\n",
    "    \n",
    "#     plt.subplot(3,4,12)\n",
    "#     plt.tick_params(axis = 'x', which = 'both', bottom = False, labelbottom = False)\n",
    "#     plt.tick_params(axis = 'y', which = 'both', left = False, labelleft = False)\n",
    "\n",
    "# # plt.savefig(local_dir + 'plots/' + name + '/7_histogram.png', format='PNG')\n",
    "# plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/8_peakpos_stats/histogram.png', format='PNG')\n",
    "# # plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/8_peakpos_stats/histogram.png', format='PNG')\n",
    "# plt.close()\n",
    "\n",
    "# ##### -------------------- METADATA ANALYSIS -------------------- #####\n",
    "\n",
    "# print('DOING METADATA ANALYSIS')\n",
    "\n",
    "# print(batch_out.shape) # the data\n",
    "# print(metadata.shape) # the metadata\n",
    "# print(test_predictions.shape) # the model's predictions about the data\n",
    "\n",
    "# # np.save('batch_out_11_10_21.npy', batch_out)  \n",
    "# # np.save('test_preds_11_10_21.npy', test_predictions)  \n",
    "# # np.save('target_11_10_21.npy', target)\n",
    "\n",
    "# # print(batch_out[0])\n",
    "# # print(metadata[0][0])\n",
    "# # print(test_predictions[0])\n",
    "\n",
    "# # print(metadata)\n",
    "\n",
    "# zeros = np.zeros((test_predictions.shape[0],1))\n",
    "# analysis_array = np.c_[metadata,zeros]\n",
    "# # print(analysis_array.shape)\n",
    "\n",
    "# for i in range(len(batch_out)):\n",
    "    \n",
    "#     # print(i)\n",
    "    \n",
    "#     # print(metadata[i])\n",
    "\n",
    "#     if metadata[i][0] == 'nan':\n",
    "#         # print(str(i) + ' is not an earthquake')\n",
    "#         # analysis_array[i][3] = 'nan'\n",
    "        \n",
    "#         threshold = 0.615\n",
    "        \n",
    "#         # True positive, true negative, false positive, false negative\n",
    "        \n",
    "#         # print('Threshold: ' + str(threshold))\n",
    "    \n",
    "#         # Convert the predictions arrays to single ones and zeroes\n",
    "        \n",
    "#         p = np.where(test_predictions[i] >= threshold)[0]\n",
    "#         if len(p) == 0:\n",
    "#             pred_binary = 0\n",
    "#         elif len(p) > 0:\n",
    "#             pred_binary = 1\n",
    "        \n",
    "#         # if i == 0:\n",
    "#         #     print('Prediction: ')\n",
    "#         #     print(pred_binary)\n",
    "        \n",
    "#         # # Convert the target arrays to single ones and zeroes\n",
    "        \n",
    "#         t = np.where(target[i] > 0)[0]\n",
    "#         if len(t) == 0:\n",
    "#             targ_binary = 0\n",
    "#         elif len(t) > 0:\n",
    "#             targ_binary = 1\n",
    "        \n",
    "#         # if i == 0:\n",
    "#         #     print('Target: ')\n",
    "#         #     print(targ_binary)\n",
    "        \n",
    "#         pred = pred_binary\n",
    "#         targ = targ_binary\n",
    "        \n",
    "#         if pred == targ: # add one to list of correct predictions if matching\n",
    "#             # correct_preds.append(1)\n",
    "            \n",
    "#             if pred == 1 and targ == 1:\n",
    "#                 result = 'true pos'\n",
    "#             elif pred == 0 and targ == 0:\n",
    "#                 result = 'true neg'\n",
    "            \n",
    "#         elif pred != targ: # add ones to list of incorrect predictions if not matching\n",
    "#             # wrong_preds.append(1)\n",
    "            \n",
    "#             if pred == 1 and targ == 0:\n",
    "#                 result = 'false pos'\n",
    "#             elif pred == 0 and targ == 1:\n",
    "#                 result = 'false neg'\n",
    "        \n",
    "#         analysis_array[i][3] = result\n",
    "    \n",
    "#     else:\n",
    "#         # print(str(i) + ' is an earthquake')\n",
    "        \n",
    "#         rupt_num = metadata[i][0]\n",
    "#         station = metadata[i][1]\n",
    "#         mag = metadata[i][2]\n",
    "        \n",
    "#         # print(rupt_num)\n",
    "#         # print(station)\n",
    "#         # print(mag)\n",
    "        \n",
    "#         # print(batch_out[i])\n",
    "#         # print(test_predictions[i])\n",
    "#         # plt.plot(test_predictions[i])\n",
    "#         # plt.show()\n",
    "        \n",
    "#         threshold = 0.2\n",
    "        \n",
    "#         # True positive, true negative, false positive, false negative\n",
    "        \n",
    "#         # print('Threshold: ' + str(threshold))\n",
    "    \n",
    "#         # Convert the predictions arrays to single ones and zeroes\n",
    "        \n",
    "#         p = np.where(test_predictions[i] >= threshold)[0]\n",
    "#         if len(p) == 0:\n",
    "#             pred_binary = 0\n",
    "#         elif len(p) > 0:\n",
    "#             pred_binary = 1\n",
    "        \n",
    "#         # if i == 0:\n",
    "#         #     print('Prediction: ')\n",
    "#         #     print(pred_binary)\n",
    "        \n",
    "#         # # Convert the target arrays to single ones and zeroes\n",
    "        \n",
    "#         t = np.where(target[i] > 0)[0]\n",
    "#         if len(t) == 0:\n",
    "#             targ_binary = 0\n",
    "#         elif len(t) > 0:\n",
    "#             targ_binary = 1\n",
    "        \n",
    "#         # if i == 0:\n",
    "#         #     print('Target: ')\n",
    "#         #     print(targ_binary)\n",
    "        \n",
    "#         pred = pred_binary\n",
    "#         targ = targ_binary\n",
    "        \n",
    "#         if pred == targ: # add one to list of correct predictions if matching\n",
    "#             # correct_preds.append(1)\n",
    "            \n",
    "#             if pred == 1 and targ == 1:\n",
    "#                 result = 'true pos'\n",
    "#             elif pred == 0 and targ == 0:\n",
    "#                 result = 'true neg'\n",
    "            \n",
    "#         elif pred != targ: # add ones to list of incorrect predictions if not matching\n",
    "#             # wrong_preds.append(1)\n",
    "            \n",
    "#             if pred == 1 and targ == 0:\n",
    "#                 result = 'false pos'\n",
    "#             elif pred == 0 and targ == 1:\n",
    "#                 result = 'false neg'\n",
    "        \n",
    "#         analysis_array[i][3] = result\n",
    "    \n",
    "# print(analysis_array)\n",
    "# print(analysis_array.shape)\n",
    "            \n",
    "# # np.save('/home/sdybing/GNSS_project/' + name + 'testing_for_analysis.npy', analysis_array) # VAL\n",
    "# np.save('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/testing_for_analysis.npy', analysis_array) # LAP        \n",
    "\n",
    "# # ##### -------------------- CLASSIFICATION TESTS -------------------- #####\n",
    "\n",
    "# print('DOING CLASSIFICATION TESTS ON REAL DATA')\n",
    "\n",
    "# # Decision threshold evaluation\n",
    "\n",
    "# thresholds = np.arange(0, 1.005, 0.005)\n",
    "# # thresholds = np.arange(0, 1, 0.1)\n",
    "# test_thresholds = [0]\n",
    "\n",
    "# # Use np.where to see whether anywhere in test_predictions is > threshold\n",
    "# # If there is a value that's >, the 'result' of the array is 1. If not 0\n",
    "# # Then compare these 1s and 0s to the target array value for PAR\n",
    "\n",
    "# accuracies = []\n",
    "# accuracies_per = []\n",
    "# precisions = []\n",
    "# recalls = []\n",
    "# F1s = []\n",
    "\n",
    "# for threshold in thresholds:\n",
    "    \n",
    "#     # print('-------------------------------------------------------------')\n",
    "#     # print('Threshold: ' + str(threshold))\n",
    "#     # print('-------------------------------------------------------------')\n",
    "#     # print(' ')\n",
    "    \n",
    "#     # Convert the predictions arrays to single ones and zeroes\n",
    "    \n",
    "#     pred_binary = np.zeros(len(realtest_predictions))\n",
    "#     iterate = np.arange(0,len(realtest_predictions),1)\n",
    "    \n",
    "#     for k in iterate:\n",
    "#         # print('Prediction: ' + str(test_predictions[k]))\n",
    "#         i = np.where(realtest_predictions[k] >= threshold)[0]\n",
    "#         # print(i)\n",
    "#         if len(i) == 0:\n",
    "#             pred_binary[k] = 0\n",
    "#         elif len(i) > 0:\n",
    "#             pred_binary[k] = 1\n",
    "    \n",
    "#     # print('Predictions: ')\n",
    "#     # print(pred_binary)\n",
    "#     # print(pred_binary.shape)\n",
    "    \n",
    "#     # Convert the target arrays to single ones and zeroes\n",
    "    \n",
    "#     targ_binary = np.zeros(len(gauss_target)) # Need to make this ones at indices in rows_w_eqs\n",
    "    \n",
    "#     for idx in range(len(targ_binary)):\n",
    "        \n",
    "#         if idx in rows_w_eqs:\n",
    "            \n",
    "#             targ_binary[idx] = 1\n",
    "    \n",
    "#     # print('Targets: ')\n",
    "#     # print(targ_binary)\n",
    "    \n",
    "#     # Calculating the accuracy, precision, recall, and F1\n",
    "    \n",
    "#     num_preds = len(realtest_predictions) # total number of predictions. Amanda did 50\n",
    "#     correct_preds = []\n",
    "#     wrong_preds = []\n",
    "#     true_pos = []\n",
    "#     true_neg = []\n",
    "#     false_pos = []\n",
    "#     false_neg = []\n",
    "    \n",
    "#     for i in iterate:\n",
    "        \n",
    "#         pred = pred_binary[i]\n",
    "#         targ = targ_binary[i]\n",
    "        \n",
    "#         if pred == targ: # add one to list of correct predictions if matching\n",
    "#             correct_preds.append(1)\n",
    "            \n",
    "#             if pred == 1 and targ == 1:\n",
    "#                 true_pos.append(1)\n",
    "#             elif pred == 0 and targ == 0:\n",
    "#                 true_neg.append(1)\n",
    "            \n",
    "#         elif pred != targ: # add ones to list of incorrect predictions if not matching\n",
    "#             wrong_preds.append(1)\n",
    "            \n",
    "#             if pred == 1 and targ == 0:\n",
    "#                 false_pos.append(1)\n",
    "#             elif pred == 0 and targ == 1:\n",
    "#                 false_neg.append(1)\n",
    "    \n",
    "#     num_correct_preds = len(correct_preds)\n",
    "#     num_wrong_preds = len(wrong_preds)\n",
    "#     num_true_pos = len(true_pos)\n",
    "#     num_true_neg = len(true_neg)\n",
    "#     num_false_pos = len(false_pos)\n",
    "#     num_false_neg = len(false_neg)\n",
    "    \n",
    "#     # print('Correct preds: ' + str(num_correct_preds))\n",
    "#     # print('Wrong preds: ' + str(num_wrong_preds))\n",
    "#     # print('True pos: ' + str(num_true_pos))\n",
    "#     # print('True neg: ' + str(num_true_neg))\n",
    "#     # print('False pos: ' + str(num_false_pos))\n",
    "#     # print('False neg: ' + str(num_false_neg))\n",
    "    \n",
    "#     # print('Threshold: ' + str(threshold))\n",
    "#     # print('Correct preds: ' + str(num_correct_preds))\n",
    "#     # print('Wrong preds: ' + str(num_wrong_preds))\n",
    "#     # print('True pos: ' + str(num_true_pos))\n",
    "#     # print('True neg: ' + str(num_true_neg))\n",
    "#     # print('False pos: ' + str(num_false_pos))\n",
    "#     # print('False neg: ' + str(num_false_neg))\n",
    "    \n",
    "#     accuracy = num_correct_preds / num_preds\n",
    "#     accuracy_per = (num_correct_preds / num_preds) * 100\n",
    "#     # print('Accuracy: ' + str(accuracy_per) + '%')\n",
    "    \n",
    "#     if num_true_pos == 0  and num_false_pos == 0:\n",
    "#         precision = 0\n",
    "#     else:\n",
    "#         precision = num_true_pos / (num_true_pos + num_false_pos)\n",
    "    \n",
    "#     if num_true_pos == 0 and num_false_neg == 0:\n",
    "#         recall = 0\n",
    "#     else:\n",
    "#         recall = num_true_pos / (num_true_pos + num_false_neg)\n",
    "    \n",
    "#     if precision + recall == 0:\n",
    "#         F1 = 0\n",
    "#     else:\n",
    "#         F1 = 2 * ((precision * recall) / (precision + recall))\n",
    "    \n",
    "#     accuracies.append(accuracy)\n",
    "#     accuracies_per.append(accuracy_per)\n",
    "#     precisions.append(precision)\n",
    "#     recalls.append(recall)\n",
    "#     F1s.append(F1)\n",
    "\n",
    "# # print('Accuracies')\n",
    "# # print(accuracies)\n",
    "# # print('Precisions')\n",
    "# # print(precisions)\n",
    "# # print('Recalls')\n",
    "# # print(recalls)\n",
    "# # print('F1s')\n",
    "# # print(F1s)\n",
    "\n",
    "# np.savetxt('realdata_accuracies_percentage_txt.txt', accuracies_per)\n",
    "# np.savetxt('realdata_thresholds_txt.txt', thresholds)\n",
    "\n",
    "# plt.figure(figsize = (8,5), dpi = 300)\n",
    "# # plt.scatter(thresholds,accuracies)\n",
    "# plt.plot(thresholds, accuracies_per, linewidth = 2)\n",
    "# plt.xlabel('Threshold', fontsize = 18)\n",
    "# plt.ylabel('Accuracy (%)', fontsize = 18)\n",
    "# plt.xlim(0,1)\n",
    "# plt.ylim(0,100)\n",
    "# plt.xticks(fontsize = 15)\n",
    "# plt.yticks(fontsize = 15)\n",
    "# plt.title('Accuracy Percentage', fontsize = 18)\n",
    "# # plt.savefig(local_dir + 'plots/' + name + '/6_accuracies_' + str(num_test) + '.png', format='PNG')\n",
    "# # plt.savefig('/Users/sydneydybing/Documents/AGU_2021/Figures/6_accuracies_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/9_realdata_classify_stats/accuracies_realdata.png', format='PNG')\n",
    "# # plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/7_classify_stats/accuracies_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.close()\n",
    "\n",
    "# plt.figure(figsize = (8,5), dpi = 300)\n",
    "# plt.plot(thresholds, precisions, linewidth = 2)\n",
    "# plt.xlabel('Threshold', fontsize = 18)\n",
    "# plt.ylabel('Precision', fontsize = 18)\n",
    "# plt.xlim(0,1)\n",
    "# plt.ylim(0,1)\n",
    "# plt.xticks(fontsize = 15)\n",
    "# plt.yticks(fontsize = 15)\n",
    "# plt.title('Precision', fontsize = 18)\n",
    "# # plt.savefig(local_dir + 'plots/' + name + '/6_precisions_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/9_realdata_classify_stats/precisions_realdata.png', format='PNG')\n",
    "# # plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/7_classify_stats/precisions_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.close()\n",
    "\n",
    "# plt.figure(figsize = (8,5), dpi = 300)\n",
    "# plt.plot(thresholds, recalls, linewidth = 2)\n",
    "# plt.xlabel('Threshold', fontsize = 18)\n",
    "# plt.ylabel('Recall', fontsize = 18)\n",
    "# plt.xlim(0,1)\n",
    "# plt.ylim(0,1)\n",
    "# plt.xticks(fontsize = 15)\n",
    "# plt.yticks(fontsize = 15)\n",
    "# plt.title('Recall', fontsize = 18)\n",
    "# # plt.savefig(local_dir + 'plots/' + name + '/6_recalls_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/9_realdata_classify_stats/recalls_realdata.png', format='PNG')\n",
    "# # plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/7_classify_stats/recalls_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.close()\n",
    "\n",
    "# plt.figure(figsize = (8,5), dpi = 300)\n",
    "# plt.plot(thresholds, F1s, linewidth = 2)\n",
    "# plt.xlabel('Threshold', fontsize = 18)\n",
    "# plt.ylabel('F1', fontsize = 18)\n",
    "# plt.xlim(0,1)\n",
    "# plt.ylim(0,1)\n",
    "# plt.xticks(fontsize = 15)\n",
    "# plt.yticks(fontsize = 15)\n",
    "# plt.title('F1', fontsize = 18)\n",
    "# # plt.savefig(local_dir + 'plots/' + name + '/6_F1s_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/9_realdata_classify_stats/F1s_realdata.png', format='PNG')\n",
    "# # plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/7_classify_stats/F1s_' + str(num_test) + '.png', format='PNG')\n",
    "# plt.close()\n",
    "\n",
    "# # ##### -------------------- GAUSSIAN PEAK POSITION TEST -------------------- #####\n",
    "\n",
    "# # print('DOING PEAK POSITION TESTS')\n",
    "\n",
    "# # # print(target[4])\n",
    "# # # print(test_predictions[4])\n",
    "\n",
    "# # thresholds = np.array([0.01,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.99])\n",
    "\n",
    "# # # threshold = 0.2\n",
    "\n",
    "# # iterate = np.arange(0,len(realtest_predictions),1)\n",
    "# # s = 0\n",
    "\n",
    "# # fig = plt.subplots(nrows = 3, ncols = 4, figsize = (18,14), dpi = 400)\n",
    "# # # fig = plt.subplots(nrows = 3, ncols = 4, figsize = (18,14))\n",
    "# # plt.suptitle('Target vs. Prediction Samples Off per Threshold', fontsize = 20)\n",
    "\n",
    "# # for idx in range(len(thresholds)):\n",
    "    \n",
    "# #     threshold = thresholds[idx]\n",
    "\n",
    "# #     pred_binary = np.zeros(len(realtest_predictions))\n",
    "# #     iterate = np.arange(0,len(realtest_predictions),1)\n",
    "    \n",
    "# #     for k in iterate:\n",
    "# #         i = np.where(realtest_predictions[k] >= threshold)[0]\n",
    "# #         if len(i) == 0:\n",
    "# #             pred_binary[k] = 0\n",
    "# #         elif len(i) > 0:\n",
    "# #             pred_binary[k] = 1\n",
    "    \n",
    "# #     # print('Predictions: ')\n",
    "# #     # print(pred_binary)\n",
    "    \n",
    "# #     # Convert the target arrays to single ones and zeroes\n",
    "    \n",
    "# #     targ_binary = np.zeros(len(gauss_target)) # Need to make this ones at indices in rows_w_eqs\n",
    "    \n",
    "# #     for idx in range(len(targ_binary)):\n",
    "        \n",
    "# #         if idx in rows_w_eqs:\n",
    "            \n",
    "# #             targ_binary[idx] = 1\n",
    "    \n",
    "# #     # print('Targets: ')\n",
    "# #     # print(targ_binary)\n",
    "    \n",
    "# #     signals = []\n",
    "    \n",
    "# #     for i in iterate:\n",
    "# #         pred = pred_binary[i]\n",
    "# #         targ = targ_binary[i]\n",
    "        \n",
    "# #         # print(pred)\n",
    "# #         # print(targ)\n",
    "        \n",
    "# #         if pred == 1 and targ == 1: # True positive, there was a signal and it found it\n",
    "# #             signals.append(i) # Grab index from list of events that are correct and have a pick\n",
    "# #         else:\n",
    "# #             pass\n",
    "    \n",
    "# #     # print(signals)\n",
    "    \n",
    "# #     samples_off_list = []\n",
    "    \n",
    "# #     for index in signals:\n",
    "        \n",
    "# #         # Find the peak and then the index where that peak is and compare \n",
    "        \n",
    "# #         # print('----------------------')\n",
    "# #         # print('Signal number: ' + str(index))\n",
    "        \n",
    "# #         target_max_idx = np.argmax(gauss_target[index])\n",
    "# #         # print('Target: ' + str(target_max_idx))\n",
    "        \n",
    "# #         pred_max_idx = np.argmax(realtest_predictions[index])\n",
    "# #         # print('Prediction: ' + str(pred_max_idx))\n",
    "        \n",
    "# #         samples_off = np.abs(pred_max_idx - target_max_idx)\n",
    "# #         # print('Samples off: ' + str(samples_off))\n",
    "# #         samples_off_list.append(samples_off)\n",
    "        \n",
    "# #     # print(samples_off_list)\n",
    "    \n",
    "# #     plt.subplot(3,4,idx+1)\n",
    "# #     plt.hist(samples_off_list, bins=128, range=(0,128), label = 'Threshold: ' + str(threshold))\n",
    "# #     plt.xlim(0,128)\n",
    "# #     plt.ylim(0,300)\n",
    "# #     plt.legend()\n",
    "# #     plt.grid(which = 'major', color = 'lightgray')\n",
    "# #     plt.subplots_adjust(hspace = 0, wspace = 0)\n",
    "\n",
    "# #     if idx == 0:\n",
    "# #         plt.tick_params(axis = 'x', which = 'both', bottom = False, labelbottom = False)\n",
    "    \n",
    "# #     elif idx == 4:\n",
    "# #         plt.ylabel('Number of examples in bin')\n",
    "# #         plt.tick_params(axis = 'x', which = 'both', bottom = False, labelbottom = False)\n",
    "# #         plt.yticks([0, 50, 100, 150, 200, 250])\n",
    "        \n",
    "# #     elif idx == 8:\n",
    "# #         plt.yticks([0, 50, 100, 150, 200, 250])\n",
    "        \n",
    "# #     elif idx == 9:\n",
    "# #         plt.xlabel('Numbers of samples off target position')\n",
    "# #         plt.tick_params(axis = 'y', which = 'both', left = False, labelleft = False)\n",
    "        \n",
    "# #     elif idx == 10:     \n",
    "# #         plt.tick_params(axis = 'y', which = 'both', left = False, labelleft = False)\n",
    "        \n",
    "# #     else:\n",
    "# #         plt.tick_params(axis = 'x', which = 'both', bottom = False, labelbottom = False)\n",
    "# #         plt.tick_params(axis = 'y', which = 'both', left = False, labelleft = False)\n",
    "    \n",
    "# #     plt.subplot(3,4,12)\n",
    "# #     plt.tick_params(axis = 'x', which = 'both', bottom = False, labelbottom = False)\n",
    "# #     plt.tick_params(axis = 'y', which = 'both', left = False, labelleft = False)\n",
    "\n",
    "# # # plt.savefig(local_dir + 'plots/' + name + '/7_histogram.png', format='PNG')\n",
    "# # plt.savefig('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/figures/10_realdata_peakpos_stats/histogram.png', format='PNG')\n",
    "# # # plt.savefig('/home/sdybing/GNSS_project/' + name + '/figures/8_peakpos_stats/histogram.png', format='PNG')\n",
    "# # plt.close()\n",
    "\n",
    "# # ##### -------------------- METADATA ANALYSIS -------------------- #####\n",
    "\n",
    "# # print('DOING REAL METADATA ANALYSIS')\n",
    "\n",
    "# # print(stack_data.shape) # the data\n",
    "# # print(norm_real_meta_data.shape) # the metadata\n",
    "# # print(realtest_predictions.shape) # the model's predictions about the data\n",
    "\n",
    "# # # np.save('batch_out_11_10_21.npy', batch_out)  \n",
    "# # # np.save('test_preds_11_10_21.npy', test_predictions)  \n",
    "# # # np.save('target_11_10_21.npy', target)\n",
    "\n",
    "# # # print(batch_out[0])\n",
    "# # # print(metadata[0][0])\n",
    "# # # print(test_predictions[0])\n",
    "\n",
    "# # # print(metadata)\n",
    "\n",
    "# # zeros = np.zeros((realtest_predictions.shape[0],1))\n",
    "# # analysis_array = np.c_[norm_real_meta_data,zeros]\n",
    "\n",
    "# # # Metadata columns: station, date, start time, end time, counter, gauss position, pgd, SNR N component, SNR E, SNR Z\n",
    "\n",
    "# # # print(analysis_array.shape)\n",
    "\n",
    "# # for i in range(len(stack_data)):\n",
    "    \n",
    "# #     # print(i)\n",
    "    \n",
    "# #     # print(metadata[i])\n",
    "\n",
    "# #     if norm_real_meta_data[i][5] == 'nan':\n",
    "# #         # print(str(i) + ' is not an earthquake')\n",
    "# #         # analysis_array[i][3] = 'nan'\n",
    "        \n",
    "# #         threshold = 0.16\n",
    "        \n",
    "# #         # True positive, true negative, false positive, false negative\n",
    "        \n",
    "# #         # print('Threshold: ' + str(threshold))\n",
    "    \n",
    "# #         # Convert the predictions arrays to single ones and zeroes\n",
    "        \n",
    "# #         p = np.where(test_predictions[i] >= threshold)[0]\n",
    "# #         if len(p) == 0:\n",
    "# #             pred_binary = 0\n",
    "# #         elif len(p) > 0:\n",
    "# #             pred_binary = 1\n",
    "        \n",
    "# #         # if i == 0:\n",
    "# #         #     print('Prediction: ')\n",
    "# #         #     print(pred_binary)\n",
    "        \n",
    "# #         # # Convert the target arrays to single ones and zeroes\n",
    "        \n",
    "# #         t = np.where(target[i] > 0)[0]\n",
    "# #         if len(t) == 0:\n",
    "# #             targ_binary = 0\n",
    "# #         elif len(t) > 0:\n",
    "# #             targ_binary = 1\n",
    "        \n",
    "# #         # if i == 0:\n",
    "# #         #     print('Target: ')\n",
    "# #         #     print(targ_binary)\n",
    "        \n",
    "# #         pred = pred_binary\n",
    "# #         targ = targ_binary\n",
    "        \n",
    "# #         if pred == targ: # add one to list of correct predictions if matching\n",
    "# #             # correct_preds.append(1)\n",
    "            \n",
    "# #             if pred == 1 and targ == 1:\n",
    "# #                 result = 'true pos'\n",
    "# #             elif pred == 0 and targ == 0:\n",
    "# #                 result = 'true neg'\n",
    "            \n",
    "# #         elif pred != targ: # add ones to list of incorrect predictions if not matching\n",
    "# #             # wrong_preds.append(1)\n",
    "            \n",
    "# #             if pred == 1 and targ == 0:\n",
    "# #                 result = 'false pos'\n",
    "# #             elif pred == 0 and targ == 1:\n",
    "# #                 result = 'false neg'\n",
    "        \n",
    "# #         analysis_array[i][3] = result\n",
    "    \n",
    "# #     else:\n",
    "# #         # print(str(i) + ' is an earthquake')\n",
    "        \n",
    "# #         rupt_num = metadata[i][0]\n",
    "# #         station = metadata[i][1]\n",
    "# #         mag = metadata[i][2]\n",
    "        \n",
    "# #         # print(rupt_num)\n",
    "# #         # print(station)\n",
    "# #         # print(mag)\n",
    "        \n",
    "# #         # print(batch_out[i])\n",
    "# #         # print(test_predictions[i])\n",
    "# #         # plt.plot(test_predictions[i])\n",
    "# #         # plt.show()\n",
    "        \n",
    "# #         threshold = 0.2\n",
    "        \n",
    "# #         # True positive, true negative, false positive, false negative\n",
    "        \n",
    "# #         # print('Threshold: ' + str(threshold))\n",
    "    \n",
    "# #         # Convert the predictions arrays to single ones and zeroes\n",
    "        \n",
    "# #         p = np.where(test_predictions[i] >= threshold)[0]\n",
    "# #         if len(p) == 0:\n",
    "# #             pred_binary = 0\n",
    "# #         elif len(p) > 0:\n",
    "# #             pred_binary = 1\n",
    "        \n",
    "# #         # if i == 0:\n",
    "# #         #     print('Prediction: ')\n",
    "# #         #     print(pred_binary)\n",
    "        \n",
    "# #         # # Convert the target arrays to single ones and zeroes\n",
    "        \n",
    "# #         t = np.where(target[i] > 0)[0]\n",
    "# #         if len(t) == 0:\n",
    "# #             targ_binary = 0\n",
    "# #         elif len(t) > 0:\n",
    "# #             targ_binary = 1\n",
    "        \n",
    "# #         # if i == 0:\n",
    "# #         #     print('Target: ')\n",
    "# #         #     print(targ_binary)\n",
    "        \n",
    "# #         pred = pred_binary\n",
    "# #         targ = targ_binary\n",
    "        \n",
    "# #         if pred == targ: # add one to list of correct predictions if matching\n",
    "# #             # correct_preds.append(1)\n",
    "            \n",
    "# #             if pred == 1 and targ == 1:\n",
    "# #                 result = 'true pos'\n",
    "# #             elif pred == 0 and targ == 0:\n",
    "# #                 result = 'true neg'\n",
    "            \n",
    "# #         elif pred != targ: # add ones to list of incorrect predictions if not matching\n",
    "# #             # wrong_preds.append(1)\n",
    "            \n",
    "# #             if pred == 1 and targ == 0:\n",
    "# #                 result = 'false pos'\n",
    "# #             elif pred == 0 and targ == 1:\n",
    "# #                 result = 'false neg'\n",
    "        \n",
    "# #         analysis_array[i][3] = result\n",
    "    \n",
    "# # print(analysis_array)\n",
    "# # print(analysis_array.shape)\n",
    "            \n",
    "# # # # np.save('/home/sdybing/GNSS_project/' + name + 'testing_for_analysis.npy', analysis_array) # VAL\n",
    "# # np.save('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/' + name + '/testing_for_analysis.npy', analysis_array) # LAP        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
