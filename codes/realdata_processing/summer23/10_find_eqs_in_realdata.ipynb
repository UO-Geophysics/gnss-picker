{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from obspy.core import UTCDateTime\n",
    "\n",
    "real_meta_data = np.load('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/More_RealData/realdata_info.npy')\n",
    "\n",
    "#print(real_meta_data)\n",
    "# print(len(real_meta_data))\n",
    "\n",
    "# print(real_data.shape[0])\n",
    "# print(real_meta_data)   # Need to associate each row in this with a 1 or a 0 if\n",
    "                        # an earthquake is supposed to be found there\n",
    "                        \n",
    "test_meta_data = real_meta_data[1489:4102,:] # BEPK 7/04 17 hrs to 7/07 6 hrs. Indices 1100 to 2900\n",
    "# print(test_meta_data)\n",
    "\n",
    "# print(real_meta_data.shape)\n",
    "\n",
    "event_catalog = np.genfromtxt('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/More_RealData/events.txt', dtype = 'U')\n",
    "# print(event_catalog)\n",
    "\n",
    "arrivaltimes = np.load('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/More_RealData/GNSS_arrival_times.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(arrivaltimes)\n",
    "# print(len(arrivaltimes))\n",
    "# print('-----------------------------')\n",
    "\n",
    "# i = np.where(arrivaltimes[:,2] == 'BEPK')[0]\n",
    "# print(i)\n",
    "\n",
    "# for ki in i:\n",
    "    \n",
    "#     print(arrivaltimes[ki,:])\n",
    "\n",
    "# target_list = []\n",
    "# target_wavetype_list = []\n",
    "\n",
    "rows_with_eqs = []\n",
    "rwe_mags = []\n",
    "rows_without_eqs = []\n",
    "p_count_info = []\n",
    "gauss_positions = []\n",
    "\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for krow in range(len(real_meta_data)):\n",
    "# for krow in range(len(test_meta_data)):\n",
    "    \n",
    "    # print('-----------------------------')\n",
    "    \n",
    "    # sta = real_meta_data[krow,0]\n",
    "    # date = real_meta_data[krow,1]\n",
    "    # starttime = UTCDateTime(real_meta_data[krow,2])\n",
    "    # # endtime = UTCDateTime(real_meta_data[krow,3])\n",
    "    \n",
    "    sta = test_meta_data[krow,0]\n",
    "    date = test_meta_data[krow,1]\n",
    "    starttime = UTCDateTime(test_meta_data[krow,2])\n",
    "    endtime = UTCDateTime(test_meta_data[krow,3])\n",
    "    \n",
    "    # print(sta)\n",
    "    # print(date)\n",
    "    # print(starttime)\n",
    "    # print(endtime)\n",
    "    \n",
    "    # arrival_stas = arrivaltimes[:,2]\n",
    "    # p_arrivals = arrivaltimes[:,3]\n",
    "    # s_arrivals = arrivaltimes[:,4]\n",
    "    \n",
    "    arrival_stas = arrivaltimes[:,2]\n",
    "    # print(arrival_stas)\n",
    "        \n",
    "    i = np.where(arrival_stas == sta)[0]\n",
    "    # print(i)\n",
    "    \n",
    "    p_pick_count = 0\n",
    "    \n",
    "    for index in i:\n",
    "        \n",
    "        # print('-----------------------------')\n",
    "        \n",
    "        mag = arrivaltimes[index,1]\n",
    "        arrival_sta = arrivaltimes[index,2]\n",
    "        p_arrival = arrivaltimes[index,3]\n",
    "        s_arrival = arrivaltimes[index,4]\n",
    "        \n",
    "        # print(mag)\n",
    "        # print(arrival_sta)\n",
    "        # print(p_arrival)\n",
    "        # print(s_arrival)\n",
    "        \n",
    "        if p_pick_count == 0: # If we haven't found any P waves yet in the metadata row:\n",
    "        \n",
    "            if p_arrival != 'nan': # If the P wave arrival time in the arrivaltimes array is not 'nan' (aka it exists):\n",
    "                \n",
    "                # print('-----------------------------')\n",
    "                # print('Good P-wave')\n",
    "                \n",
    "                p_arrival = UTCDateTime(p_arrival) # Convert the P arrival time from the array to a UTCDateTime object\n",
    "                # print('P-arrival: ' + str(p_arrival))\n",
    "                # print('Start time: ' + str(starttime))\n",
    "                # print('End time: ' + str(endtime))\n",
    "                \n",
    "                p_start_delta = p_arrival - starttime # If the P arrival minus the metadata row start time is greater than or equal to 0 but less than 128, the p_arrival is in the sample\n",
    "                # print(p_start_delta)\n",
    "                \n",
    "                if p_start_delta >= 0 and p_start_delta < 128: # If the delta is 0, the Gaussian should be positioned at the first sample (index 0).\n",
    "                    \n",
    "                    gauss_position = round(p_start_delta) # Rounded to the nearest whole index\n",
    "                    p_pick_count += 1 # Since we found an arrival in this metadata row, add one to the pick count\n",
    "                    \n",
    "                    print('Index ' + str(index) + ': P in this sample!')\n",
    "                    # print(krow)\n",
    "                    # print(mag)\n",
    "                    rwe_mags.append(mag)\n",
    "                    # print(index) # this is the index in arrival_times where the eq is\n",
    "                \n",
    "                else: # If the delta is greater than 128, the arrival time is not in the metadata array. Skip it.\n",
    "                    \n",
    "                    pass\n",
    "            \n",
    "            elif p_arrival == 'nan': # If there isn't a calculated arrival time for this row in the arrivaltimes array, skip it.\n",
    "                \n",
    "                gauss_position = 'nan' # If there is no p arrival in the sample, the gaussian will not exist so the position is 'nan'.\n",
    "                pass\n",
    "        \n",
    "        elif p_pick_count > 0: # If the count is already greater than 1 because we've found a p wave in this row of the metadata array, we'll skip any extras for making gaussian positions (but still add them to the count so we know they exist).\n",
    "            \n",
    "            if p_arrival != 'nan': \n",
    "                p_arrival = UTCDateTime(p_arrival) \n",
    "                p_start_delta = p_arrival - starttime \n",
    "\n",
    "                if p_start_delta >= 0 and p_start_delta < 128:  \n",
    "                    p_pick_count += 1\n",
    "                \n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "            elif p_arrival == 'nan': \n",
    "                pass\n",
    "    \n",
    "    if p_pick_count == 0:\n",
    "        \n",
    "        rows_without_eqs.append(krow) # Add the index of the row in the metadata array that doesn't have an earthquake to the list of indices that don't have earthquakes.\n",
    "        p_count_info.append(p_pick_count) # Add the number of p picks in the metadata array row (zero) to the p_count list.\n",
    "        gauss_positions.append(gauss_position) # Add the gauss position (in this case 'nan' because there are no picks in this row of the metadata array) to the list of positions.\n",
    "        \n",
    "        # These might be VERY WRONG - need to be inside the index loop to not just have only the last value!\n",
    "        \n",
    "    elif p_pick_count != 0:\n",
    "        \n",
    "        rows_with_eqs.append(krow) # Add the index of the row in the metadata array that does have an earthquake to the list of indices that do have earthquakes.\n",
    "        p_count_info.append(p_pick_count) # Add the number of p picks in the metadata array row to the p_count list.\n",
    "        gauss_positions.append(gauss_position) # Add the index of the sample that should have the gaussian peak to the list of gaussian positions.\n",
    "\n",
    "    counter += 1\n",
    "    # print(counter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checks to make sure things add up correctly\n",
    "\n",
    "# print(gauss_positions)\n",
    "print(rwe_mags)\n",
    "\n",
    "# print(len(real_meta_data))\n",
    "# print(len(rows_without_eqs) + len(rows_with_eqs))\n",
    "# print(len(p_count_info))\n",
    "# print(len(gauss_positions)) # All four of these should match\n",
    "\n",
    "# print(len(rows_with_eqs))\n",
    "# a = np.where(np.array(gauss_positions) != 'nan')[0]\n",
    "# print(len(a)) # This should match len(rows_with_eqs)\n",
    "\n",
    "# ### Adding gauss position column to metadata array\n",
    "\n",
    "# gauss_pos_vector = np.array(gauss_positions).reshape(len(gauss_positions),1)\n",
    "\n",
    "# new_meta_array = np.append(real_meta_data, gauss_pos_vector, axis = 1)\n",
    "# print(real_meta_data.shape)\n",
    "# print(new_meta_array.shape)\n",
    "# print(new_meta_array)\n",
    "\n",
    "# # Checking rows that should have the gaussian position added\n",
    "\n",
    "# print(new_meta_array[rows_with_eqs])\n",
    "# print(len(new_meta_array[rows_with_eqs]))\n",
    "\n",
    "# # Checking rows with eqs and mags are same length\n",
    "\n",
    "# print('November 2022 checks')\n",
    "# print(len(rows_with_eqs))\n",
    "# print(len(rwe_mags))\n",
    "# print(rwe_mags)\n",
    "\n",
    "# np.save('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/More_RealData/real_metadata_w_gauss_pos.npy', new_meta_array)\n",
    "# np.save('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/More_RealData/rowsweqs.npy', np.array(rows_with_eqs))\n",
    "# np.save('/Users/sydneydybing/GNSS-CNN_repo/GNSS-CNN/More_RealData/rwe_mags.npy', np.array(rwe_mags))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
